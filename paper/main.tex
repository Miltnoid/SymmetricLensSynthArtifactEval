\newif\ifdraft\draftfalse  % set true to show comments
% \newif\ifdraft\draftfalse  % set true to show comments
\newif\ifanon\anontrue    % set true to suppress names, etc.
\newif\ifappendices\appendicesfalse

\PassOptionsToPackage{usenames,dvipsnames,svgnames,table}{xcolor}
%\documentclass[acmsmall,review,screen,anonymous]{acmart}
\documentclass[acmsmall,review,screen,anonymous]{acmart}
\settopmatter{printacmref=false,printccs=false}

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[capitalise]{cleveref}
\usepackage{amsmath}
\usepackage{makecell}%To keep spacing of text in tables
\usepackage{nccmath}
\usepackage{mathtools}
\usepackage{bussproofs}
\usepackage{varwidth}
\usepackage{amsthm}
\usepackage{csvsimple}
\usepackage{thmtools,thm-restate}
\usepackage{changepage}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multirow,bigdelim}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{listings}
\usepackage{letltxmacro}
\usepackage{sansmath}
\usepackage{url}
\usepackage{flushend}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage{mathpartir}
\usepackage{empheq}
\usepackage{array}
\usepackage{pgfplots}
\usepackage{stmaryrd}
\usepackage{courier}
\usepackage{qtree}
\usepackage[normalem]{ulem}
\usepackage{relsize}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{stackengine}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{remreset}
\usepackage{tabulary}
\usepackage{xspace}
\usepackage{bbm}

\newtheorem*{theorem*}{Theorem}
\newenvironment{centermath}
 {\begin{center}$\displaystyle}
 {$\end{center}}
\setcellgapes{4pt}%parameter for the spacing

\lstset{ language=Caml, basicstyle=\upshape\sffamily,
keywordstyle=\upshape\sffamily\color{dkpurple}, keepspaces=true,
framexleftmargin=1ex, framexrightmargin=1ex, showstringspaces=true,
commentstyle=\itshape\rmfamily,
emph={rep,iterate,synth,collapse,perm,squash,normalize,using,ins,del,lens,let,get,put,rquot,lquot,id,swap,concat,or,disconnect,merge_left,merge_right,const,skip,require},
emphstyle=\upshape\sffamily\color{dkpurple}, 
columns=fullflexible,
mathescape, 
xleftmargin=1.5em,
% BCP: I find this distracting:
stringstyle=\sffamily\color{dkblue},
aboveskip=.3em,
belowskip=.3em,
}
\makeatletter
     \let\lst@oldvisiblespace\lst@visiblespace
     \def\lst@visiblespace{\,\lst@oldvisiblespace\,}
\makeatother

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

\usetikzlibrary{
  er,
  matrix,
  shapes,
  arrows,
  positioning,
  fit,
  calc,
  pgfplots.groupplots,
  arrows.meta
}
\tikzset{>={Latex}}

%%%% Hyperlinks â€“ must come late!
%\usepackage[pdftex,%
%            pdfpagelabels,%
%            linkcolor=blue,%
%            citecolor=blue,%
%            filecolor=blue,%
%            urlcolor=blue]
%           {hyperref}

\input{macros}


\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000

%\setlength{\belowcaptionskip}{-5pt}
%\setlength{\textfloatsep}{15pt}

% Creates a display mode for code in sans serif font
% end

% Macros
  \newcommand{\NameOf}[1]{\CF{#1}}

%%% If you see 'ACMUNKNOWN' in the 'setcopyright' statement below,
%%% please first submit your publishing-rights agreement with ACM (follow link on submission page).
%%% Then please update our instructions page and copy-and-paste the NEW commands into your article.
%%% Please contact us in case of questions; allow up to 10 min for the system to propagate the information.
%%%
%%% The following is specific to POPL'18 and the paper
%%% 'Synthesizing Bijective Lenses'
%%% by Anders Miltner, Kathleen Fisher, Benjamin C. Pierce, David Walker, and Steve Zdancewic.
%%%

  \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
%\setcopyright{rightsretained}
%\acmPrice{}
%\acmDOI{10.1145/3158089}
%\acmYear{2019}
%\copyrightyear{2019}
%\acmJournal{PACMPL}
%\acmVolume{3}
%\acmNumber{POPL}
%\acmArticle{1}
%\acmMonth{1}
%\startPage{1}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}

  \begin{document}

  %%% The following is specific to POPL'18 and the paper
%%% 'Synthesizing Bijective Lenses'
%%% by Anders Miltner, Kathleen Fisher, Benjamin C. Pierce, David Walker, and Steve Zdancewic.
%%%

%\toappear{}

%\conferenceinfo{POPL '16}{January 20--22, 2016, St. Petersburg, FL, USA} 
%\copyrightyear{2016} 
%\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

%\titlebanner{DRAFT---do not distribute}        % These are ignored unless
%\preprintfooter{DRAFT---do not distribute}   % 'preprint' option specified.

\title{Synthesizing Symmetric Lenses}

\begin{abstract}
%% \saz{This abstract too long and doesn't get to the point quickly enough. We
%%   should tighten it up considerably.}\bcp{+1.  But not just tighten ---
%%   the whole story doesn't feel very compelling.}
%%   Users commonly need to synchronize the data shared between formats, so edits
%%   to the data in one format gets propagated to the data in the other format.
%%   Manually writing the functions for these data synchronizers is tedious and
%%   error prone. Instead of manually writing these synchronizers, bidirectional
%%   languages can be used to express \emph{lenses}, groups of synchronization
%%   functions with guarantees about round-trip behavior. While these bidirectional
%%   languages help make programming these synthesizers less error-prone, they
%%   remain difficult to program in. Synthesizing bidirectional languages allows
%%   users to use lenses without manually programming them. Current
%%   synthesizers work only on the simplest types of lenses, when the two formats
%%   describe exactly the same data; this is often not the case.

%%   Oftentimes, each format may contain information the other lacks. Such
%%   synchronization tasks are described by one of the richest classes of lenses,
%%   symmetric lenses. However, symmetric lenses in their current formulation
%%   require external\bcp{why not ``internal''?} state in the form of a \emph{complement}. This statefulness
%%   makes symmetric lenses both difficult to use and difficult to
%%   synthesize. \bcp{This paragraph seems too dense.}

%%   In this work, we reformulate\bcp{More a restriction than a reformulation.}
%%   symmetric lenses as \emph{simple symmetric 
%%     lenses}. While this formulation is less expressive than symmetric lenses, it
%%   expresses many\bcp{weak} symmetric lenses while requiring \emph{no external state}. We
%%   provide combinators for simple symmetric lenses on string data, and integrate
%%   these combinators into Boomerang\bcp{undefined} while providing full backwards compatibility.

%% \bcp{This bit feels more detailed / technical than needed for an abstract.}
%%   We develop a type-directed synthesis algorithm for generating lenses in this
%%   language from regular expressions describing the data formats. A significant
%%   technical challenge in this work arises from the fact that our target language
%%   permits synchronization between formats that don't have exactly the same data
%%   -- data in one format need not be present in the other format. This gives the
%%   synthesis algorithm much more freedom, as data can be completely unaligned
%%   (edits in one format are never propagated), completely aligned (the formats
%%   are in bijective correspondence), or anywhere in between. Under the assumption
%%   that users typically want to align as much data as possible, we provide an
%%   information theoretic metric for how much data is left unaligned based on the
%%   theory of \emph{stochastic regular expressions}. Furthermore, we use this
%%   metric to develop a greedy synthesis algorithm that tries to minimize
%%   unaligned data. We experimentally demonstrate that our algorithm can
%%   efficiently synthesize simple symmetric lenses on a variety of benchmark
%%   suites consisting of synchronizing file formats from configuration files,
%%   application-specific data storage files, and data cleaning tasks.

{\em Lenses} are programs that can be run both ``front to back'' and ``back
to front,'' allowing updates to either their source or their target data to be
transferred in both directions. 
Since their introduction by Foster \ETAL, lenses have been extensively
studied, extended, and applied.  Recent work has also demonstrated how
techniques from {\em type-directed program synthesis} can be used to
efficiently synthesize a simple class of lenses---so-called {\em
  bijective lenses} over string data---given a pair of types (regular
expressions) and a small number of examples.

\hspace*{1em}We extend this synthesis algorithm to a much broader class of
lenses, called {\em simple symmetric lenses}, including all
bijective lenses, all of the popular category of ``asymmetric''
lenses, and a rich subset of the more powerful
``symmetric lenses'' proposed by Hofmann \ETAL  
Intuitively, simple symmetric lenses allow some information to be present
on one side but not the other and vice versa.
They are of independent theoretical interest, being
the largest class of symmetric lenses that do not rely on persistent
internal state.  

Synthesizing simple symmetric lenses is substantially more challenging than
synthesizing bijective lenses: Since some of the information on each side
can be ``disconnected'' from the other side, there will, in general, be {\em
  many} lenses that agree with a given example. To guide the search process,
we use {\em stochastic regular expressions} and ideas from information
theory to estimate the amount of information propagated by a candidate
lens, generally preferring lenses that propagate more information, 
as well as user annotations marking parts of the source and
target data structures as either {\em irrelevant} or {\em essential}.


We describe an implementation of simple symmetric lenses and our synthesis
procedure as extensions to the Boomerang language. We evaluate its performance
on 48 benchmark examples drawn from Flash Fill, Augeas, the bidirectional
programming literature, and electronic file format synchronization tasks. Our
implementation can synthesize each of these lenses in under 30 seconds.
\end{abstract}

%\begin{CCSXML}
%<ccs2012>
%<concept>
%<concept_id>10011007.10011006.10011050.10011017</concept_id>
%<concept_desc>Software and its engineering~Domain specific languages</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%<concept>
%<concept_id>10011007.10011006.10011066.10011070</concept_id>
%<concept_desc>Software and its engineering~Application specific development environments</concept_desc>
%<concept_significance>300</concept_significance>
%</concept>
%</ccs2012>
%\end{CCSXML}
%
%\ccsdesc[500]{Software and its engineering~Domain specific languages}
%\ccsdesc[300]{Software and its engineering~Application specific development environments}

%\ifanon
%\authorinfo{}
%           {}
%           {}
%\maketitle
% \vspace*{-6cm}
%\else
\author{Anders Miltner}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{amiltner@cs.princeton.edu}

\author{Solomon Maina}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{smaina@cis.upenn.edu}

\author{Kathleen Fisher}
\affiliation{
  \institution{Tufts University}
  \country{USA}
}
\email{kfisher@eecs.tufts.edu}

\author{Benjamin C. Pierce}
\affiliation{
  \institution{University of Pennsylvania}
  \country{USA}
}
\email{bcpierce@cis.upenn.edu}

\author{David Walker}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{dpw@cs.princeton.edu}

\author{Steve Zdancewic}
\affiliation{
  \institution{University of Pennsylvania}
  \country{USA}
}
\email{stevez@cis.upenn.edu}

%\keywords{Bidirectional Programming, Program Synthesis, Type-Directed Synthesis,
%Type Systems}

\maketitle
%\fi

% \category{D.3.1}
% {Programming Languages}
% {Formal Definitions and Theory}
% [Semantics]
\ifanon\else
\fi

% begin introduction
\section{Introduction}

\noindent
In today's data-rich world, similar information is often stored in different
places and in different formats. For instance, electronic calendars come in
iCalendar, vCalendar, and h-event formats~\cite{calendar-formats}; US taxation
data can be transmitted via Tax XML (used by the US government for e-filing) or
TXF (used by TurboTax)~\cite{tax-formats}; configuration files can be stored in
ad-hoc or structured file formats~\cite{augeas} (for example, scheduled commands
can be stored in a crontab or as Windows's Scheduled Tasks xml).


One convenient way to maintain consistency between such varied data formats
is to use a \emph{lens}~\cite{Focal2005-long}---a bidirectional program that
can transform updates to data represented in a format $S$ to another format
$T$ and vice versa, providing round-tripping guarantees that help ensure
information is not lost or corrupted as it is transformed back and forth
between different representations.
Domain-specific languages for writing lenses can facilitate generation of
principled data transformations.  For example, Boomerang~\cite{boomerang} is a
language for expressing bidirectional string transformations.

\textit{Synthesizing} lenses can make the task even easier. Indeed, lens
languages like Boomerang are excellent targets for search-based synthesis,
since their 
specialized, sub-Turing-complete syntax and their expressive type systems
drastically limit the space of possible programs.
%
The recent Optician synthesizer for Boomerang~\cite{optician} has
demonstrated the feasibility of synthesizing quite complex examples, albeit
only for a restricted class of lenses---so-called bijective lenses.
Given source and target formats plus a small number of examples of
corresponding data, Optician's synthesis algorithm is guaranteed to find a
bijective lens matching the examples, if one exists. Indeed, it can often find
an appropriate lens in less than a second with no examples at all.
%, with just types describing the source and target formats.
% \dpw{I would cite the ICFP paper (cite string:
%   maina+:quotient-synthesis) as to appear but I'm not sure how to do that
%   without possibly violating the spirit of double-blind reviewing. ie, if it
%   hasn't appeared yet, how could we know the content if we aren't the authors?
%   Mentioning it in the 3rd person does not seem to suffice ...} \ksf{The ICFP
%   2018 website lists the paper; I think it is okay to cite it. The reviewer can
%   assume we contacted the authors for a copy. We could ask Stephanie for a
%   ruling if we want to be sure. One of the principles of double blind as adopted
%   by SIGPLAN is not to reduce the quality of the paper; omitting this citation
%   would have that affect.}\bcp{+1}\saz{Stephanie says we should cite it in the
%   third person, even if that's a bit awkward, but otherwise citing it is OK.}
One reason that bijective lens synthesis can be so effective, even relative to
successful synthesis tools in other domains, is that there are typically not
very many bijections between a given pair of data formats. 
If the synthesis algorithm finds any bijection, it is fairly likely to be
the intended one. 

However, the set of real-world use cases for bijective lenses, where two
data formats contain different arrangements of precisely the same
information, is  
limited.  Oftentimes, two data
formats share just {\em some} of their information content.  For instance,
one ad-hoc system-configuration
file might include some format-specific metadata, such as a date or a
reference number, while the same configuration file on another operating
system does not.  Indeed among the benchmark problems described in
Section \ref{sec:evaluation}, all of the benchmarks taken from Flash
Fill~\cite{flashfill} and many of the benchmarks that synchronize between
two ad hoc file formats have this characteristic.

Can Optician's basic synthesis procedure be extended to a richer class of
lenses? Could we even imagine synthesizing all \emph{symmetric
  lenses}~\cite{symmetric-lenses}---a much larger class that includes
bijective lenses, ``asymmetric'' lenses (where the transformation from a
source structure to a target can throw away information that must
then be restored when transferring from target to source), and even more flexible
transformations that allow each side to throw away information?

% A symmetric lens between $S$ and $T$ represents a pair of functions, $\PutR$
% and $\PutL$.  The $\PutR$ component has type
% $S \times T \rightarrow T$---that is, it takes a ``new'' $S$ and an ``old''
% $T$ and builds a ``new'' $T$ using its first argument for the shared
% information and its second argument for information that is only available
% on the $T$ side.  Conversely, the $\PutL$ component has type
% $T \times S \rightarrow S$.

% If $\ell$ is a symmetric lens between formats $S$ and
% $T$, then $\ell$  can transform data from $S$ to $T$ or vice versa
% equally well.  A user would typically 
% run $\ell$ in the forwards direction (from $S$ to $T$) when a user updates
% a string $s \in S$ to propagate those updates to $T$.
% However, because data in format $S$ may contain some information not present in format $T$,
% the $S \rightarrow T$ transformation takes
% \emph{both} the edited string $s \in S$ and a string $t \in T$ as arguments.
% Inuitively, the lens extracts the data ``shared'' between the two
% formats from $s$
% and uses $t$ to supply any missing information.
%
% required by $T$ that is missing
%as it generates an output $t'$.  If $s$ is missing information, the
%transformation should 
%extract the missing components from $t$.

One might first hope that extending the algorithms from \citet{optician} to
synthesize symmetric rather than bijective lenses would be relatively
straightforward: Simply replace the bijective combinators with symmetric
ones and search using similar heuristics.  However, this na\"ive approach
encounters two difficulties.

The first of these is pragmatic.  Symmetric lenses as presented
by~\citet{symmetric-lenses} operate
over three structures: a ``left'' structure $X$, a ``right'' structure
$Y$ and a ``complement'' 
$C$ that contains the information not
present in either $X$ or $Y$. These complements must be stored
and managed somehow.  More fundamentally, complements complicate
synthesis {\em specifications}---instead of just giving single examples of
source and target 
pairings, users would have to give longer ``interaction sequences'' to 
show how a lens should behave. To avoid these complexities, we define a
restricted variant 
of symmetric lenses,  called \emph{simple symmetric lenses}. 
%only the usual source and target.
%
%, which we define in Section~\ref{sec:relationship}.
Intuitively, simple symmetric lenses are symmetric
lenses that do not require external ``memory'' to recover data from past
instances of $X$ or $Y$ when making a round trip. They only need the most
recent instance.

Formally, we characterize the expressiveness of simple symmetric lenses by
proving that they are exactly the symmetric lenses
that satisfy an intuitive property called \emph{forgetfulness}.  We also show
they are expressive enough for many practical uses by adding simple
symmetric lenses to 
the Boomerang language~\cite{boomerang} and applying them to a range of
real-world applications.  This exercise also demonstrates that simple
symmetric lenses can coexist with, and be extended by, other advanced lens features
provided by Boomerang, including {\em quotient
  lenses}~\cite{quotientlenses,maina+:quotient-synthesis} and {\em matching
  lenses}~\cite{matchinglenses}.

This leaves us with the second difficulty in synthesizing symmetric
lenses: Whereas the number of bijective lenses between two given formats is
typically tiny, the number of simple symmetric lenses is typically enormous.
If a na\"ive search algorithm just selects the first simple symmetric lens
it finds, the returned lens will generally \emph{not} be the one the user wanted.  We
need a new principle for identifying ``more likely'' lenses and a more
sophisticated synthesis algorithm that uses this principle to search the
space more intelligently. 

For these, we turn to information theory. We consider ``likely'' lenses to
be ones that propagate ``a lot'' of information 
from the left data format to the right and vice versa. Conversely, ``unlikely''
lenses are ones that require a large amount of additional information to recover
one of the formats given the other. By default, our synthesis algorithm prefers
the lenses that propagate more information.
This preference is formalized using \emph{stochastic regular expressions}
(SREs)~\cite{stoch-rnn,stoch-def}, which simultaneously define a set of
strings and a probability distribution over those strings.  Using this
probability distribution, we can calculate the likelihood of a given lens.

\begin{figure}
  \includegraphics[width=.63\textwidth]{high-level-algorithm.pdf}
  \vspace{-2ex}
  \caption{Schematic diagram for the simple symmetric lens synthesis algorithm.
    The user provides regular expressions \BRegex and \BRegexAlt and a set of
    examples \Examples{} as input. \Expand first converts \BRegex and \BRegexAlt
    to stochastic regular expressions \Regex and \RegexAlt with default
    probabilities. It then finds pairs of stochastic regular expressions
    equivalent to \Regex and \RegexAlt and iteratively proposes them to
    \GreedySynth. \GreedySynth finds a lens typed between the supplied SREs.
    When the algorithm finds a likely lens, it returns it.}
  \label{fig:high-level-algorithm}
\end{figure}

With simple symmetric lenses and this SRE-based likelihood measure in hand, we
propose a new algorithm for synthesizing likely lenses. At its core, the
algorithm performs a type-directed search between descriptions of the data
formats, measuring success using the likelihood measure.

Interesting complications arise from the need to deal with regular-expression
equivalences. There are infinitely many regular expressions equivalent to a
given one, and the lens returned by a type-directed search will in general
depend on which of the possible representations are chosen for its source and
target formats. Moreover, certain lenses may not be well-typed unless the
format representations are replaced by equivalent ones:
in general, the synthesis algorithm has to search through
equivalent regular expression types to find the most likely lens. To tame
this complexity, we divide the synthesis algorithm into two communicating search
procedures (Figure~\ref{fig:high-level-algorithm}), following~\citet{optician}.
The first, \Expand, uses rewriting rules to propose new pairs of
stochastic regular expressions equivalent to the original pair. The second,
\GreedySynth, uses a greedy, type-directed
algorithm to find a simple symmetric lens between input SRE pairs, returning the lens and
its likelihood score to \Expand. The whole synthesis algorithm heuristically
terminates when a sufficiently likely lens is found.

%%
%%searches for two \emph{related} SREs $S'$ and $T'$ that are
%%\emph{compatible} (a heuristic that estimates the likelihood our second
%%algorithm will succeed). $S'$ and $T'$ are related in the sense that they define
%%the same regular sets as $\BRegex$ and $\BRegexAlt$ (respectively) and the distribution of
%%strings is identical. Indeed, we guarantee these two properties by implementing
%%a search procedure that obeys the star-semiring axioms of regular expression
%%equivalence, and which we show does not alter the probability distributions of
%%the languages.

%%Given the two compatible SREs, \GreedySynth uses a greedy, type-directed
%%algorithm find a likely lens between them. If algorithm estimates that the lens
%%it has discovered is more likely than any future lens it can possibly find, the
%%search terminates. Otherwise, this lens is stored away (if it is the best found
%%so far) and the search continues with \Expand again.

We added this synthesis procedure to the Boomerang system and explored its
effectiveness on a range of applications. Users set up a Boomerang synthesis
task by providing two regular expressions and optionally supplying input-output
examples. Users can also override the default mechanism for
calculating the information content of a SRE by
asserting that certain strings are \emph{essential} or \emph{irrelevant},
forcing certain data to either be retained or discarded during the
transformations.

We evaluate our implementation, the effects of optimizations, and our inclusion
of relevance annotations on a set of 48 lens synthesis benchmarks drawn from
data cleaning, view maintenance, and file synchronization tasks. We find the
system can synthesize simple symmetric lenses for all of the benchmarks in under
30 seconds (\S\ref{sec:evaluation}).

In summary, our contributions are as follows:
\begin{itemize}
%
\item We define {\em simple symmetric lenses}, a subclass of symmetric
lenses with no hidden state,
%
we propose a syntax for them---a collection
of combinators for building simple symmetric lenses---and we
describe how to calculate their likelihoods
(\S\ref{sec:overview}--\S\ref{sec:ssl}).  
\item We give an algorithm for synthesizing lenses built from these combinators,
  using a novel application of stochastic regular expressions to guide the
  search process (\S\ref{sec:synthesis}) and prove that our metrics correspond
  to the information loss of a given lens.
%
\item We extend the Boomerang implementation with simple symmetric lenses
and lens synthesis specifications, 
  including types, examples, and relevance annotations. We evaluate our
  implementation, the effects of
  optimizations, and our inclusion of relevance annotations on a set of
  48 lens synthesis benchmarks drawn from data cleaning, view maintenance, and
  file synchronization tasks. The system can synthesize simple symmetric lenses
  for all of the benchmarks in under 30 seconds (\S\ref{sec:evaluation}).
%
\item We prove that simple symmetric lenses fall between asymmetric
lenses~\cite{Focal2005-long} and full symmetric
lenses~\cite{symmetric-lenses} in expressiveness.  Indeed, the
class of simple lenses can be characterized semantically as the subset of
full symmetric lenses for which a simple ``forgetfulness'' property holds
(\S\ref{sec:related}).
\end{itemize}
Along the
way, we show that {\em star-semiring equivalences}~\cite{starsemiring} on regular
expressions 
remain valid when extended to stochastic regular expressions, preserving
probability distributions as well as languages (\S\ref{sec:sre}).
We close with related work (\S\ref{sec:related}) and
concluding thoughts (\S\ref{sec:conc}).
Elided proofs can be found in the appendices
\ifappendices\else included with the supplemental material\fi.

%Such synthesis efforts
%make it easier to use lenses as programmers do not need to be familiar with the syntax
%of a new language, and even advanced users can benefit from the productivity boost.

\noindent

% state of the world
% end introduction

% begin overview
\section{Overview}
\label{sec:overview}

\begin{figure}
  % https://tex.stackexchange.com/questions/168741/showing-two-listings-in-a-table-side-by-side
  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}[
stringstyle=\upshape\sffamily
]
Jane Doe: 38000
John Public: 37500
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingA}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}[
stringstyle=\upshape\sffamily
]
FirstLast,Company
Jane Doe,Healthcare Inc.
John Public,Insurance Co.
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingB}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}
let salary = number | "unk"
let emp_salary = name . " " . name . ": " salary
let emp_salaries = "" | emp_salary . ("\n" emp_salary)$^*$
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingC}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}
let company = (co_name . ("Co." | "Inc." | "Ltd.")) | "UNK" in
let emp_ins = name . " " . name "," company in
let header = "FirstLast,Company" in
let emp_insurance = header . ("\n" . emp_ins)$^*$
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingD}{\box0}
  
  \centering
  \resizebox{\columnwidth}{!}{%
    \begin{tabular}{|>{\columncolor{vlightyellow}}c|>{\columncolor{vlightblue}}c|}
      \hline
      Management's data & HR's data \\
      \hline
      \listingA & \listingB \\
      \hline
      \cellcolor{lightyellow}Management's type & 
      \cellcolor{lightblue} HR's type\\
      \hline
      \cellcolor{lightyellow}\listingC & \cellcolor{lightblue}\listingD \\
      \hline
    \end{tabular}
  }
  \caption{Hypothetical example data files and corresponding regular expressions
  used by management and HR at a US company to represent employee salaries and health
  insurance providers, respectively.
  }
  \label{fig:minimized-representations}
\end{figure}

We begin with an overview of simple symmetric lenses and our
synthesis algorithm, using a simplified example drawn from a hypothetical
U.S. company. In this company, management and human resources (HR) store
information about employees in separate text files: management stores the
names of 
employees and their salaries while HR stores the names of employees and their
health insurance providers. Figure~\ref{fig:minimized-representations} gives
examples of the two file formats and regular expressions describing them. 

The company uses a simple symmetric lens to keep these files
synchronized. When management adds a new employee, say ``Chris Roe: 32500'',
this lens 
adds the corresponding entry ``Chris Roe, UNK'' to HR's file. The default value
``UNK'' represents the fact that the employee's insurance company is currently
unknown. A similar update happens if HR adds a new employee before
management knows about them,
in which case the sentinel value ``unk'' reflects unknown salary information
on management's side.
Furthermore, if HR corrects an error in an employee's name, say changing ``John
Public'' to ``Jon Public'', the lens mirrors this change into management's
file. Not all the data is mirrored, however: management's file is not updated
in response to insurance changes, and HR's is oblivious to salary
changes. Simple symmetric lenses are appropriate for keeping these two files
synchronized because they contain a mix of shared and unshared information.

%Consider the previously
%described goal of keeping Linux cron jobs (crontab) and Windows Scheduled Tasks
%(scheduled.job) synchronized. These are each formats specifying when to run
%recurring tasks. For the sake of exposition, we use simplified versions crontab
%and scheduled.job formats, with examples and corresponding regular expressions
%shown in Figure~\ref{fig:minimized-representations}. Each file contains a list
%of tasks set to run at specific times every hour. In both formats, users
%can either provide specific minutes at which they want the program to run, or they
%can specify that the program should run at every minute.
%
%We wish for the jobs to be synchronized across our Windows and Linux devices.
%However, the commands that need to be run are typically different for each
%device. Paths are different in Windows and Linux, and, while there is typically a
%Windows equvialent for a Linux command, that equivalent command is not always
%named the same thing. So, while we want to be able to have the same number of
%commands, with the commands running at the same times, we don't want to
%align the actual commands that are run.

\subsection{Simple Symmetric Lenses}
Semantically, a simple symmetric lens (we will just say ``lens'' when clear
from context) between 
sets $X$ and $Y$ comprises four functions subject to four round-tripping
laws.
\vspace*{.7ex}
\begin{trivlist}
\item 
%\begin{enumerate}
%\item $\CreateR \OfType \Regex \rightarrow \RegexAlt$
%\item $\CreateL \OfType \RegexAlt \rightarrow \Regex$
%\item $\PutR \OfType \Regex \rightarrow \RegexAlt \rightarrow \RegexAlt$
%\item $\PutL \OfType \RegexAlt \rightarrow \Regex \rightarrow \Regex$
%\end{enumerate}
\begin{center}
\begin{minipage}[c]{.3\textwidth}
\begin{gather}
 \mbox{$\CreateR \OfType X \rightarrow Y$} \nonumber \\
 \mbox{$\CreateL \OfType Y \rightarrow X$} \nonumber \\
 \mbox{$\PutR \OfType X \rightarrow Y \rightarrow Y$} \nonumber \\
 \mbox{$\PutL \OfType Y \rightarrow X \rightarrow X$} \nonumber
\end{gather} 
\end{minipage} 
\hspace{.4in}
\begin{minipage}[c]{.5\textwidth}
\begin{align}
  \tag{\CreatePutRL}
  \PutLOf{(\CreateROf{x})}{x} = x\\
  \tag{\CreatePutLR}
  \PutROf{(\CreateLOf{y})}{y} = y\\
  \tag{\PutRL}
  \PutLOf{(\PutROf{x}{y})}{x} = x\\
  \tag{\PutLR}
  \PutROf{(\PutLOf{y}{x})}{y} = y
\end{align}
\end{minipage} 
\end{center}
\end{trivlist}
The two \KW{create} functions are used to fill 
in default values when introducing new data (\EG, on \KW{create} the ``unk''
salary entry is added alongside the name to the management file when HR inserts
a new employee). The two \KW{put} functions propagate edits from one format to
the other by combining a new value from one with an old value from the other.
The record projection notation $\Lens.\PutR$ extracts the \PutR function
from the 
lens $\Lens$. These four functions can be used to keep the
common information between two file types in sync. For example, if a new file
of the left-hand format is created, the \CreateR function will build a new
file in the 
right-hand format. If the right-hand file is then edited, the \PutL function can
update the left-hand file with the changed information.

The round-tripping laws guarantee that pushing an ``unedited'' value from one
side (the result of a put or create) back through a lens in the other direction
will get back to exactly where we began. For example, consider a lens
synchronizing the employee data formats in
Figure~\ref{fig:minimized-representations}. Applying the \CreateR function to a
salary file creates a insurance file with the same employee names in the file,
with
\lstinline{"UNK"} for each insurance company. The round-tripping
laws guarantees that applying the \PutL function to the generated insurance file
and the original salary file will return the original salary file, unmodified.

Simple symmetric lenses differ from ''classical'' symmetric lenses in that
they do not involve a \emph{complement}. We give a detailed comparison in
\S\ref{sec:relationship}.

%%For synchronization, when the original company.hr or company.mgmt
%%file is created, a synchronized file of the other form is created
%%from it with $\CreateR$ or $\CreateL$ (depending on which file was
%%initially created). On future edits, changes are made with the puts,
%%a \PutR would propagate the shared information from the company.hr
%%file, and knit it together with the information specific to the company.mgmt file.


\subsection{Simple Symmetric Lens Combinators}

In principle, programmers can define lenses just by writing
four arbitrary functions by hand and showing they satisfy the round-tripping
laws, but this can be tedious and error prone.  A better idea is to provide
a set of combinators---a domain-specific language---for building complex,
law-abiding 
lenses from simpler ones. Such bidirectional languages have been given for
many different kinds of data, including database
relations~\cite{BohannonPierceVaughan} algebraic data
types~\cite{symmetric-lenses}, graphs~\cite{tgg}, and more.
We focus here on combinators for defining lenses between string data formats
described by regular expressions.

If $\BRegex$ and $\BRegexAlt$ are regular expressions, then
\lstinline{$\Lens$ : $\BRegex \Leftrightarrow \BRegexAlt$} indicates that
$\Lens$ is a simple symmetric lens between $\LanguageOf{\BRegex}$ and
$\LanguageOf{\BRegexAlt}$. (We will use undecorated variables later for
stochastic regular expressions, so we mark plain REs with overbars.)
We illustrate some of these
combinators by defining lenses on subcomponents of the employee data formats.

The simplest combinator is the identity lens \IdentityLens, which takes as an
argument a regular expression $\BRegex$ and propagates data unchanged
in both directions.
%
\begin{lstlisting}
id(name)  :  name $\Leftrightarrow$ name
\end{lstlisting}
%
The identity lens moves data back and forth from source to target without
changing it. Both the \CreateR and \CreateL functions are the identity function
($\CreateR \App s = s$), and the put functions merely return the first argument
($\PutROf{\String}{\StringAlt} = \String$).

In contrast, $\DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}$ does not propagate any data at all
from one format to the other.  The \Disconnect lens takes four arguments: two
regular expressions ($\Regex, \RegexAlt$) and two strings ($\String, \StringAlt$). The regular expressions specify the formats
on the two sides, while the strings provide default values. 
%
\begin{lstlisting}
disconnect(salary, "", "unk", "")  :  salary $\Leftrightarrow$ ""
\end{lstlisting}
%
On creates, the input values are thrown away, and default values are
returned ($\CreateLOf{\StringAlt} =
\lstinline{"unk"}$), and on puts, the second argument is used and the first is
thrown away ($\PutROf{\String}{\StringAlt} = \StringAlt$). For 
example, the \lstinline{salary} field is only present in management files,
so the disconnect lens can ensure salary edits do not cause updates to the
HR file.
With the above lens, $\PutL \App \lstinline{""} \App 60000$ will return 60000,
and \PutR will always return \lstinline{""}.

The insert lens \lstinline{ins} and the delete lens \lstinline{del} are
syntactic sugar for uses of the disconnect lens in which a string
constant is omitted entirely from the source or target format.
\begin{lstlisting}
 ins($t$) = disconnect("", $t$, "", $t$)
 del($s$) = disconnect($s$, "", $s$, "")
\end{lstlisting}
The \lstinline{ins} lens inserts a constant string when going from
left to right, while \lstinline{del} inserts a string when going from right
to left.

Finally, there are a number of combinators that construct
more complex lenses from simpler ones. These include concatenation
($\ConcatLensOf{\Lens_1}{\Lens_2}$, often written $\Lens_1 . \Lens_2$), variation
($\OrLensOf{\Lens_1}{\Lens_2}$), and iteration ($\IterateLensOf{\Lens}$).
For example, we could use the lens
%
\begin{lstlisting}
id(name) . id(" ") . id(name) . del(": ") . ins(",")
\end{lstlisting}
%
to transform ``\lstinline{Jane Doe: }'' to ``\lstinline{Jane Doe,}'' in
the left-to-right direction.

% concat(ins(header),employees_lens) : emp_salaries $\Leftrightarrow$ emp_insurance
%
%\ksf{I don't think this example is necessary.}
%Data can also appear in multiple forms. For example,
%a list of employees with insurance information can either be empty or
%be a sequence of employee/insurance records: \ksf{This example is
%vacuous as you could eliminate the or in favor of the *.  Do somethign
%else to introduce or?}
%
%\begin{lstlisting}
%or(id(""),employees_lens) : emp_salaries $\Leftrightarrow$ "" | ("\n" emp_ins) . ("\n" emp_ins)*
%\end{lstlisting}
The \IterateLens lens is useful for synchronizing a series of items or rows in a
table. For example given a
lens \lstinline{employee_lens} that synchronizes data for a single employee, the
lens
%
\begin{lstlisting}
iterate(id("\n") . employee_lens)  :  ("\n" . emp_salary)$^*$ $\Leftrightarrow$ ("\n" . emp_ins)$^*$
\end{lstlisting}
%
transforms a list of employees in employees in the Management format to a list
of employees in the HR format and vice versa. These combinators
are combined in figure~\ref{fig:example_lens} to construct a complete lens
between the employee formats.

\begin{figure}
\begin{lstlisting}
let name_lens = id(name) . id(" ") . id(name) . del(": ") . ins(",") in
let employee_lens = name_lens . disconnect(salary,"","unk","") 
                                                    . disconnect("",company,"","UNK") in
let employees_lens = ins("\n") . employee_lens . iterate(id("\n") . employee_lens) in
ins(header) . employees_lens  :  emp_salaries $\Leftrightarrow$ emp_insurance
\end{lstlisting}
%\ksf{I don't think this is necesssary.}
%let emp_lens = or(id(""),employees_lens) in
  \caption{A lens that synchronizes management and HR employee files}
  \label{fig:example_lens}
\end{figure}

% Using these combinators, we can build up a lens that synchronizes
% management and HR employee files. 

Lenses are typed by pairs of regular expressions and only a handful of
rules result in a given type.
Many of these rules provide tight relationships between terms and types, for example, the type of a
\ConcatLens lens is the concatenation of the regular expressions of the sub-lenses.
\[
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \ConcatLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_1 \Concat \BRegexAlt_2
  }
\]
The typing  rules for maintain structural similarity
between regular expression types and lens terms, with one exception: The
type equivalence rule permits a well-typed lens to be well-typed among any
equivalent regular expression pair.
%
\[
  \centering
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \BRegex \SSREquiv \BRegex'\\
    \BRegexAlt \SSREquiv \BRegexAlt'
  }
  {
    \Lens \OfType \BRegex' \Leftrightarrow \BRegexAlt'
  }
\]
%
This rule is needed for lenses like the final one in
Figure~\ref{fig:example_lens} to be well-typed.


%%\ksf{Do we need to use
%%type equivalence to type the employee example?  If so, perhaps we
%%should explain her}
%%
%%This lens uses one typing rule not previously
%%mentioned: type equivalence. While \lstinline{scheduled_job} is a equivalent to
%%a regular expression with an outermost disjunction, it is not syntactically
%%equivalent to one. Without type equivalence, the provided lens wouldn't actually
%%be well-typed, but type equivalence states that if a lens is typed between a
%%pair of regular expressions, it is also typed between an equivalent pair.


\subsection{Ranking Simple Symmetric Lenses}

For larger and more complex formats, it can become quite difficult to
write lenses by hand, as we did above.  Instead, we would like to synthesize
them from types and examples.  
That is, given a pair of regular expressions and a set of input-output
examples, we want 
to find a simple symmetric lens that is typed by the regular expression pair and
satisfies all the input/output examples. We call this a \emph{satisfying
  lens}. For our running example, suppose we wish to synthesize a lens between
\lstinline{emp_salaries} and \lstinline{emp_insurance}, using as sole
input-output example the data in Figure~\ref{fig:minimized-representations}.

One challenge is that the simple symmetric lens combinators permit many
well-typed lenses
between a given pair of regular expressions. For example, 
Figure~\ref{fig:example_lens} gives one possible lens between regular
expressions  \lstinline{emp_salaries} and \lstinline{emp_insurance},
but 
%
\begin{lstlisting}
disconnect(emp_salaries, emp_insurance, $s$, $t$)
\end{lstlisting}
%
is another well-typed lens that satisfies the example in
Figure~\ref{fig:minimized-representations} (where $s$ and $t$ represent
the provided example strings). In general, {\em many} examples
may be 
required to rule out all possible occurrences of \Disconnect lenses,
particularly in complex formats.
%\ksf{I don't understand the following.  We shouldn't explain the issue in
%terms of \PutR and \PutL as we are focused on the combinators rather
%than the raw functions.}
%The default strings given to \Disconnect merely need to be the strings
%in the input-output examples, and the lens will still satisfy the
%specification.  While the disconnect lens is prohibited by two
%examples, or by a carefully chosen input-output example on \PutR
%or \PutL, this problem continues presenting itself for the sublenses,
%and is highlighted even more on larger formats.
Instead of merely finding
\emph{any} satisfying lens, we wish to synthesize a satisfying lens that is
likely to please the user.

How can we identify such a ``likely'' lens? We propose the following heuristic:
A satisfying lens is ``more likely'' if it uses more data from one format to
construct the other.  For example, the
identity lens (which uses all the data) is more likely than the disconnect
lens (which uses none). Formally, we define the {\em likelihood} of a
satisfying lens as the 
expected number of bits required to recover data in one format from 
data in the other; higher likelihoods correspond to fewer bits. Two
strings $s$ and $t$ are \emph{synchronized according to lens
  $\Lens$} if $\Lens.\PutR\
s\ t = t$ and $\Lens.\PutL\ t\ s = s$. We can \emph{recover} $s$ from 
$t$ using bits $b$ and lens $\Lens$ if we can reconstruct $s$ from $t$, $b$, and
$\Lens$. For example, given the \IdentityLens{} lens, we can recover $s$ from $t$
using no bits because, in this case, $s$ is just $t$. In contrast, given the
\Disconnect{} lens, we need enough bits to fully encode $s$ in order to recover
it from $t$ because all the information in $t$ gets thrown away. Thus, if both
\IdentityLens{} and \Disconnect{} are satisfying lenses for a particular pair of
formats, \IdentityLens{} will be more likely.

The expected number of bits required to recover a piece of data corresponds to
the well-known information-theoretic concept of
\emph{entropy}~\cite{Shannon1948}. Calculating entropy requires a probability
distribution over the space of possible values for the data. Specifically, given
a set $S$ and a probability distribution $P \OfType S \rightarrow \Reals$ over
$S$, the entropy $\EntropyOf{S,P}$ is $-\Sigma_{s\in S}P(s)\Log_2P(s)$. In
information theory, the \emph{information content} of each element of $s \in
S$ is 
the number of bits required to specify $s$ in a perfect encoding scheme
($-\Log_2P(s)$). The entropy of $S$ is the expected number of bits
required to specify an element drawn from $S$---the
probability of each element times its information content. Entropy captures
the intuition that, if a data source contains many possible elements and
none have 
significantly higher probability than others, it will have high entropy. Data
sources with just a few high probability elements have low
entropy. When $P$ is clear from context, we will
often use the shorthand of $\EntropyOf{S}$ for $\EntropyOf{S,P}$.

In the present setting, we already have a way of expressing sets of data:
regular 
expressions. To calculate entropy, what we need is a way to express probability
distributions over those sets. To that end, we adopt \emph{stochastic regular
  expressions}~\cite{stoch-def,stoch-rnn} (SREs), which are regular expressions
in which each operator is annotated with a probability (see \S\ref{sec:sre}). A
stochastic regular expression thus specifies both a set of strings at the
same time as a probability distribution over that set.

We use entropy to gauge the relative likelihood of lenses in our synthesis
algorithm (see \S\ref{subsec:lenscosts}). For any lens $\Lens$, we can calculate
the expected number of bits required to recover a string $t$ in
$\LanguageOf{\RegexAlt}$ from a synchronized string $s$ in
$\LanguageOf{\Regex}$. This expectation is the \emph{conditional entropy of
  $\Regex$ given $\RegexAlt$ and $\Lens$}, formally $\sum_{s \in
  \Regex}\ProbabilityOf{\Regex}{s}\cdot\EntropyOf{\SetOf{t \SuchThat
    \Lens.\PutROf{s}{t} = t}}$. The likelihood we assign to $\Lens$ is the sum
of the conditional entropy of $\Regex$ given $\RegexAlt$ and $\Lens$ and the
conditional entropy of $\RegexAlt$ given $\Regex$ and $\Lens$. This metric
assigns higher entropy (or likelihood) to lenses where knowing the string on one side 
provides little information about the string on the other side. It assigns zero
entropy to bijections because given a string $s \in \Regex$, the bijection
exactly determines the corresponding string in $\RegexAlt$.

%%As a further example, consider the trivial lens
%%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%%the disconnect lens, the cost of each side is the entropy of the data format, so
%%the total cost is $\EntropyOf{\lstinline{emp_salary} } +
%%\EntropyOf{\lstinline{emp_row}}$. The lens \lstinline{emp_salary} contains strictly more
%%information than $\EntropyOf{\lstinline{": " . salary}}$, and
%%\lstinline{emp_row} contains strictly more information than
%%\EntropyOf{\lstinline{": " . salary}}, so by our metric
%%\lstinline{single_emp_map} is preferable to the disconnect lens.

To obtain SREs from the plain regular expressions that users write, 
we use a default heuristic that attempts to assign probability annotations
giving
each string in the language equal probability (not prioritizing one piece of
information over another).

Sometimes users already know that certain data should or should not be
used to construct the other format. We introduce relevance annotations to SREs
that enable users to specify whether a piece of data should be used to construct
the other format (with \SRequire) or not (with \Skip). In our example,
\lstinline{salary} and \lstinline{company} could safely be skipped (as they are
disconnected), where \lstinline{name} in \lstinline{emp_salary} and
\lstinline{emp_ins} could be annotated as required (as they are converted with the
identity lens). Doing so both constrains the problem (as \lstinline{name}s must
be synchronized) and makes it easier (as the algorithm does not waste time
looking for \lstinline{salary} information in the insurance format). In this
way, users can tweak the
lens likelihoods with their external knowledge.

\subsection{Searching for Likely Lenses}
Now that we have a way to calculate likelihood, we need a way to search for
likely lenses. Previous work~\cite{augustsson-2004, osera+:pldi15,
  feser-pldi-2015, frankle+:popl16} has shown that types can be used to
dramatically restrict the search space and improve the effectiveness of
synthesis. In our setting, types are pairs of stochastic regular
expressions, and the fact that each regular expression is semantically
equivalent to infinitely many others complicates the problem.

Following existing work on bidirectional program
synthesis~\cite{maina+:quotient-synthesis}, we 
split our algorithm into two communicating
search procedures. The first,
\Expand, navigates the space of semantically equivalent regular expressions
by applying rewrite rules that preserve both semantics and
probability distributions. This
algorithm ranks pairs of stochastic regular expressions by the number of
rewrite rule applications required to obtain each pair from the one given as
input. It passes the pairs off to the second 
search procedure, \GreedySynth, in rank order with the smallest first.

\GreedySynth looks for highest-likelihood lenses between a given
pair of stochastic regular expressions $\Regex$ and $\RegexAlt$ by performing a
type-directed search. It first converts the stochastic
regular expressions provided by \Expand into \emph{stochastic DNF regular
  expressions}---a constrained representation of stochastic regular expressions
with disjunctions distributed over concatenations and with concatenations and
disjunctions normalized to operating over lists.
Then it uses the syntax of these n-ary DNF regular expressions to find
normalized lenses in a form we call \emph{simple symmetric n-ary DNF lenses}.
These involve neither a composition operator nor a type equivalence rule.
These restrictions mean that there are comparatively few simple symmetric n-ary DNF
lenses that are well typed between a given pair of stochastic n-ary DNF regular
expressions, so \GreedySynth's search space for a given pair of regular
expressions is finite. Finally, \GreedySynth yields a simple symmetric lens by
converting the n-ary syntax back to the binary forms provided in the surface
language.

This architecture of communicating synthesizers gives us a way to enumerate
pairs of stochastic regular expressions of increasing rank and to efficiently
search through them, but it poses a problem: when should \Expand stop proposing
new SRE pairs? We might have found a promising lens between a pair of stochastic
regular expressions, but a different pair we haven't yet discovered may give
rise to an even better lens. The search algorithm must resolve a tension between
the quality of the inferred lens and the amount of time it takes to return a
result. For example, if the algorithm has already found the lens in
Figure~\ref{fig:example_lens}, we don't want to spend a lot of time searching
for an even better lens. To resolve this tension, the algorithm uses heuristics
to judge whether to return the current best satisfying lens to the user or to
pass the next set of equivalent SREs to \GreedySynth. The heuristics favor stopping
if the current best satisfying lens is very likely, indicating the lens is very
promising (for example, if the satisfying lens loses no information, the
algorithm should terminate for no other lens will be more likely). The
heuristics also favor stopping if \Expand has delivered to \GreedySynth all
pairs of stochastic regular expressions at a given rank and there is a large
number of pairs at the next rank, because searching through all such pairs will
take a long time (\IE, if a satisfying lens loses only a little
information
and searching for a better one will take a long time, the discovered lens is
returned).
With this approach, the algorithm can quickly return a
satisfying lens with relatively high likelihood. If the user is unhappy with the
result, they can either refine the search by supplying additional examples,
which serve both to rule out previously proposed lenses and to reduce the
size of the search space by cutting down on the number of satisfying lenses, or
they can supply annotations on the source and target SREs indicating that
certain information either must be retained or must be discarded by the lens
(see \S\ref{subsec:relevanceannotations}).

%Consider the trivial lens
%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%the disconnect lens, the cost of each side is the entropy of the data format, so
%the total cost is $\EntropyOf{\lstinline{emp_salary}} +
%\EntropyOf{\lstinline{emp_row}}}$. \lstinline{emp_salary} contains strictly more
%imformation than \EntropyOf{\lstinline{": " . salary}}, and \lstinline{emp_row}
%contains strictly more information than \EntropyOf{\lstinline{": " . salary}},
%so by our metric \lstinline{single_emp_map} is preferable to the disconnect
%lens.

%Not sure we need this level of detail after all.
%\afm{calculations for cost of various lenses between \lstinline{emp_salary} and
%  \lstinline{emp_row}} Consider the lens \lstinline{single_emp_map} between
%\lstinline{emp_salary} and \lstinline{emp_row}. Given this lens, the expected
%entropy of recovering the left format from the right
%($\EntropyOf{\lstinline{emp_salary} \Given \lstinline{emp_row},
%  \lstinline{single_emp_map} }$) is the sum of the expected entropy of
%recovering each of its subcomponents, $\EntropyOf{\lstinline{emp_salary} \Given
%  \lstinline{emp_row}, \lstinline{single_emp_map} } = \EntropyOf{\lstinline{name
%    . " " . name} \Given \lstinline{name . "," . name}, \lstinline{name_map}
%}$\\ + $\EntropyOf{\lstinline{": " . salary} \Given
%  \lstinline{"," . company}, \lstinline{disc(salary,company,"UNSET","UNSET")}
%}$.
%
%The entropy of the identity lens is zero. As the two formats are in bijective
%correspondence, we know exactly which string is present in the left-hand format.
%The entropy of the disconnect lens is just the entropy of
%\lstinline{": " . salary}.  Knowing which string is present in the right-hand
%format tells us nothing about what string is present in the left-hand format. So
%$\EntropyOf{\lstinline{emp_salary} \Given \lstinline{emp_row},
%  \lstinline{single_emp_map} } = \EntropyOf{\lstinline{": " . salary} }$
%
%Analogously, $\EntropyOf{\lstinline{emp_row} \Given \lstinline{emp_salary},
%  \lstinline{single_emp_map} }$ is just $\EntropyOf{\lstinline{"," . company}
%}$, so the total cost of the lens is $\EntropyOf{\lstinline{": " . salary}} +
%\EntropyOf{\lstinline{"," . company}}$

%Consider the trivial lens
%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%the disconnect lens, the cost of each side is the entropy of the data format, so
%the total cost is $\EntropyOf{\lstinline{emp_salary}} +
%\EntropyOf{\lstinline{emp_row}}$. \lstinline{emp_salary} contains strictly more
%imformation than \EntropyOf{\lstinline{": " . salary}}, and \lstinline{emp_row}
%contains strictly more information than \EntropyOf{\lstinline{": " . salary}},
%so by our metric \lstinline{single_emp_map} is preferable to the disconnect
%lens.
% end overview

% begin stoch-rx
% end stoch-rx

\section{Stochastic Regular Expressions}
\label{sec:sre}
To characterize likely lenses, we must compute the expected number of bits
needed to recover a string in one data source from a synchronized string in the
other data source. To do this, we first develop a probabilistic 
model for our language using \emph{stochastic regular
  expressions} (SREs)---regular expressions annotated with probability
information~\cite{stoch-rnn,stoch-def}---that
jointly express a language and a probability distribution over that language. 
$$\Regex{},\RegexAlt{} \quad\GEq{}\quad  \String  \quad|\quad \emptyset \quad|\quad \PRegexStar{\Regex}{p} \quad|\quad \RegexConcat{\Regex_1}{\Regex_2} \quad|\quad \PRegexOr{\Regex_1}{\Regex_2}{p}$$
(Lowercase $\String$ ranges over constant strings and $\Probability$ ranges
over real numbers between 0 and 1, exclusive.)
The semantics of an SRE $S$ is a probability distribution $P_S$ defined as
follows.
\begin{center}
  \begin{tabular}{rcl}
    $\ProbabilityOf{\String}{\String''}$
    & =
    & $\begin{cases*}1 & if $\String = \String''$\\ 0 & otherwise\end{cases*}$ \\
     
    $\ProbabilityOf{\emptyset}{\String}$
    & =
    & $0$ \\
    
    $\ProbabilityOf{\RegexConcat{\Regex_1}{\Regex_2}}{s}$

    & =
    & $\Sigma_{\String = \String_1\String_2}\ProbabilityOf{\Regex_1}{\String_1}\ProbabilityOf{\Regex_2}{\String_2}$ \\
    
    $\ProbabilityOf{\PRegexOr{\Regex_1}{\Regex_2}{\Probability}}{\String}$
    & =
    & $\Probability\ProbabilityOf{\Regex_1}{\String} +
      (1-\Probability)\ProbabilityOf{\Regex_2}{\String}$\\
    
    $\ProbabilityOf{\PRegexStar{\Regex}{\Probability}}{\String}$
    & =
    & $\Sigma_n \Sigma_{\String = \String_1 \ldots \String_n}\Probability^n(1-\Probability)\Pi_{i=1}^n\ProbabilityOf{\Regex}{\String_i}$\\
  \end{tabular}
\end{center}
One may think of SREs as string generators. Under this interpretation, the
constant SRE $\String$ always generates the string $\String$ and never any other
string. The SRE $\PRegexOr{\Regex_1}{\Regex_2}{\Probability}$ generates a string
from $\Regex_1$ with probability $\Probability$ and generates a string from
$\Regex_2$ with probability $1-\Probability$. The SRE
$\PRegexStar{\lstinline{"c"}}{\Probability}$ generates the empty string with
probability $1-\Probability$, and generates any other string in the language with
probability $\Probability$. More generally,
$\PRegexStar{\Regex}{\Probability}$ generates strings in $\Regex^n$ with
probability $\Probability^n(1-\Probability)$.

\begin{figure}
  \begin{tabular}{@{}r@{\hspace{1em}}c@{\hspace{1em}}l@{}r@{\hspace*{3em}}r@{\hspace{1em}}c@{\hspace{1em}}l@{}r}
    $\RegexConcat{\emptyset}{\Regex}$ & $\SSREquiv$ & $\emptyset$ & \EmptyProjectionLeftRule{} &
    $\RegexConcat{\Regex}{\emptyset}$ & $\SSREquiv$ & $\emptyset$ & \EmptyProjectionRightRule{} \\
    \RegexConcat{\EmptyString{}}{\Regex{}} & $\SSREquiv$ & \Regex{} & \ConcatIdentityLeftRule{} &
    \RegexConcat{\Regex{}}{\EmptyString{}} & $\SSREquiv$ & \Regex{} & \ConcatIdentityRightRule{} \\
    \PRegexOr{\Regex}{\emptyset}{1} & $\SSREquiv$ & \Regex{} & \OrIdentityRule{} &
    \PRegexOr{\Regex{}}{\RegexAlt{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\RegexAlt{}}{\Regex{}}{1-\Probability} & \OrCommutativityRule{}\\
    \RegexConcat{\Regex{}}{(\PRegexOr{\Regex{}'}{\Regex{}''}{\Probability})} & $\SSREquiv$ & \PRegexOr{(\RegexConcat{\Regex{}}{\Regex{}'})}{(\RegexConcat{\Regex{}}{\Regex{}''})}{\Probability} & \DistributivityLeftRule{} &
    \RegexConcat{(\PRegexOr{\Regex{}'}{\Regex{}''}{\Probability})}{\Regex{}} & $\SSREquiv$ & \PRegexOr{(\RegexConcat{\Regex{}'}{\Regex{}})}{(\RegexConcat{\Regex{}''}{\Regex{}})}{\Probability} & \DistributivityRightRule{} \\
    \PRegexStar{\Regex{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\EmptyString{}}{(\RegexConcat{\Regex{}}{\PRegexStar{\Regex{}}{\Probability}})}{1-\Probability} & \UnrollstarLeftRule{} &
    \PRegexStar{\Regex{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\EmptyString{}}{(\RegexConcat{\PRegexStar{{\Regex{}}}{\Probability}}{\Regex{}})}{1-\Probability} & \UnrollstarRightRule{} 
  \end{tabular}
  \begin{tabular}{@{}r@{\hspace{1em}}c@{\hspace{1em}}l@{\hspace{1em}}r@{}}
    \RegexConcat{(\RegexConcat{\Regex{}}{\Regex'})}{\Regex''} & $\SSREquiv$ & \RegexConcat{\Regex{}}{(\RegexConcat{\Regex'}{\Regex''})} & \ConcatAssocRule{}  \\
    \PRegexOr{(\PRegexOr{\Regex}{\Regex'}{\Probability_1})}{\Regex''}{\Probability_2} & $\SSREquiv$ & \PRegexOr{\Regex}{(\PRegexOr{\Regex'}{\Regex''}{\frac{(1-\Probability_1)\Probability_2}{1 - \Probability_1\Probability_2}})}{\Probability_1\Probability_2} & \OrAssociativityRule{}  \\
  \end{tabular}
  \caption{Stochastic Regular Expression Star-Semiring Equivalence}
  \label{fig:ssr-sre}
\end{figure}

\subsection{Stochastic Regular Expression Equivalences}
The $\Expand$ algorithm enumerates SREs that are
``equivalent'' to a given one. However, existing work does not define any notion
of stochastic regular expression equivalence. Figure~\ref{fig:ssr-sre} shows how
we to extend the \emph{star-semiring}~\cite{starsemiring} equivalences (a
\emph{finer} notion of equivalence than semantic equivalence) to
SREs.  

\begin{theorem}
  If $\Regex \SSREquiv \RegexAlt$ then $\ProbabilityOf{\Regex}{\String} =
  \ProbabilityOf{\RegexAlt}{\String}$, for all strings $\String \in \LanguageOf{\Regex}$.
\end{theorem}

(For the proof, see the appendix \ifappendices
Theorem~\ref{thm:semantics-correctness} \else{} included with the
supplemental material\fi.)  This theorem will come in handy as we traverse
(with \Expand) or normalize across (as part of \GreedySynth) star-semiring
equivalences.

\subsection{Stochastic Regular Expression Entropy}
The entropy of a data source $S$ is the expected number of bits required to
describe an element drawn from $S$ (formally $-\Sigma_{s\in S}\,P(s)\cdot
\Log_2P(s)$). The entropy of a SRE can be computed directly from its syntax,
when each string is uniquely parsable (\IE{} the SRE is unambiguous) and contains
no empty subcomponents.
\begin{center}
  \begin{tabular}{rcl}
    $\EntropyOf{s}$
    & =
    & 0\\
    
    $\EntropyOf{\PRegexStar{\Regex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}(\EntropyOf{\Regex} - \Log_2\Probability)
      - \Log_2(1-\Probability)$\\
    
    $\EntropyOf{\PRegexConcat{\Regex}{\RegexAlt}}$
    & =
    & \EntropyOf{\Regex} + \EntropyOf{\RegexAlt}\\
    
    $\EntropyOf{\PRegexOr{\Regex}{\RegexAlt}{\Probability}}$
    & =
    & $\Probability(\EntropyOf{\Regex} - \Log_2(\Probability)) + (1-\Probability)(\EntropyOf{\RegexAlt} - \Log_2(1-\Probability))$\\
  \end{tabular}
\end{center}

For example, the entropy of $\Regex =
\PRegexOr{\lstinline{"a"}}{\lstinline{"b"}}{.5}$ is 1. The best encoding of a
stream of elements from $\Regex$ will use, on average, 1 bit per element to
determine whether that element is \lstinline{"a"} or \lstinline{"b"}. As an
additional example, a fixed string has no information content, and so has no
entropy.

\begin{theorem}
  \label{thm:correct_entropy}
  If $\Regex$ is unambiguous and does not contain $\emptyset$ as a subterm,
  $\EntropyOf{\Regex}$ is the entropy of $\Regex$.
\end{theorem}

To understand the difficulties caused by ambiguity, consider the SRE
$\PRegexOr{\lstinline{"a"}}{\lstinline{"a"}}{.5}$. The formula above defines the
entropy to be 1, but the true entropy is 0 (\IE, no bits are needed to know the
generated string will be \lstinline{"a"}). Similar issues occur when trying to
find the entropy when $\emptyset$ is a subterm (what should the entropy of
$\PRegexStar{\emptyset}{.5}$ be?), so we do not define entropy on~$\emptyset$.

Fortunately, we already require unambiguous regular expressions as input to
our synthesis procedure for other reasons, and we can easily preprocess
empty subexpressions out of SREs that are themselves nonempty using the
star-semiring equivalences (\EG, $\PRegexOr{\emptyset}{\lstinline{"s"}}{.5}
\SSREquiv \lstinline{"s"}$).

% \caption{Regular Expression Equivalences}
% \label{fig:regex-equivalence-rules}

%%%%%%%%%%%%%%  BCP: stopped reading carefully here...

\section{Simple Symmetric String Lenses}
\label{sec:ssl}
Simple symmetric string lenses are bidirectional programs that convert string
data between formats. These lenses operate over regular expressions, not SREs.
If $\Regex$ is a stochastic regular expression, $\BRegex$ is the regular
expression obtained by removing probability annotations.

\begin{align*}
\ell ::= &\IdentityLensOf{\BRegex} \; | \; \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt} \; | \; \IterateLensOf{\Lens} \; | \; \ConcatLensOf{\Lens_1}{\Lens_2} \; | \; \SwapLensOf{\Lens_1}{\Lens_2} \; | \; \OrLensOf{\Lens_1}{\Lens_2} \; | \; \ComposeLensOf{\Lens_1}{\Lens_2} \; |\\
&\MergeROf{\Lens_1}{\Lens_2} \; | \; \MergeLOf{\Lens_1}{\Lens_2} \; | \; \InvertOf{\Lens}
\end{align*}

We have already described a number of these combinators in \S\ref{sec:overview}.
Briefly (full definitions are below), the lens $\Lens_1 ; \Lens_2$
composes two lenses sequentially, it 
transforms from one data format to the other by first transforming to an
intermediate format, shared as the target of $\Lens_1$ and the source of
$\Lens_2$. The \MergeR lens combines two sublenses that operate on disjoint
source formats and share the same target.
The lens that gets used depends on what data is in the left-hand format, if the data is
in the domain of $\Lens_1$ then $\Lens_1$ gets used, and similarly for
$\Lens_2$.  The \MergeL lens is symmetric to \MergeR, the two sublenses must
share the same source. Finally, $\InvertOf{\Lens}$ inverts a lens, \CreateR
becomes \CreateL and \PutR becomes \PutL, and vice-versa.

We now give typing rules and semantics for (some of) these combinators. We write
$\Lens \OfType \BRegex \Leftrightarrow \BRegexAlt$ to indicate that $\Lens$ is a
well typed lens between the language of \BRegex and the language of \BRegexAlt.
We present just \CreateR and \PutR in cases where \CreateL and \PutL are
symmetric; full details can be found in an appendix\ifappendices
\S\ref{sec:appendixlenses} \else{} (in the supplemental materials)\fi. For
simplicity of presentation, we use unambiguous regular expressions everywhere,
even though the identity and disconnect lenses can actually be defined over
ambiguous regular expressions; relaxing this restriction is not problematic.

\begin{centermath}
  \begin{tabular}{m{1cm}@{\hspace*{6em}}m{1cm}@{\hspace*{3em}}}
    $
  \inferrule*
  {
  }
  {
    \IdentityLensOf{\BRegex} \OfType \BRegex \Leftrightarrow \BRegex
  }$
&
$\begin{array}[b]{r@{\ }c@{\ }l}
    \CreateR{} \App s & = & s\\
    \PutR{} \App s \App t & = & s
  \end{array}$
\end{tabular}
\end{centermath}
Note that the identity lens ignores the second argument in the put functions.
Because the two formats are fully synchronized, no knowledge of the prior data
is needed.

\begin{centermath}
  \begin{tabular}{m{5cm}m{2cm}}
    $
    \inferrule*
    {
    \String \in \LanguageOf{\BRegex}\\
    \StringAlt \in \LanguageOf{\BRegexAlt}
    }
    {
    \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt}
    \OfType \BRegex \Leftrightarrow \BRegexAlt
    }$
    &
      $
  \begin{array}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String'$ & = & $\StringAlt$\\
    $\PutR{} \App \String' \App \StringAlt'$ & = & $\StringAlt'$
  \end{array}$
\end{tabular}
\end{centermath}

Just as the identity lens ignores the second argument in puts, disconnect lenses
ignore the first argument in both puts and creates.  The data is unsynchronized in these
two formats, information from one format doesn't impact the other.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \ConcatLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_1 \Concat \BRegexAlt_2
  }
$
&
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \SwapLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_2 \Concat \BRegexAlt_1
  }
$
\end{tabular}
\end{centermath}
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1 \String_2$ & = & $(\Lens_1.\CreateROf{\String_1})(\Lens_2.\CreateROf{\String_2})$\\
%    $\CreateL{} \App \StringAlt_1 \StringAlt_2$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
%    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_1\StringAlt_2)$ & = & $(\Lens_1.\PutROf{\String_1}{\StringAlt_1})(\Lens_2.\PutROf{\String_2}{\StringAlt_2})$\\
%    $\PutL{} \App (\StringAlt_1\StringAlt_2) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
%  \end{tabular}
%\end{center}

Concat is similar to concatenation in existing string lens languages like
Boomerang.  For such terms, we do not provide the semantics, and merely refer readers to existing work. The swap combinator is similar to concat, though the second regular expression
is swapped.
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1\String_2$ & = & $(\Lens_2.\CreateROf{\String_2})(\Lens_1.\CreateROf{\String_1})$\\
%    $\CreateL{} \App \StringAlt_2\StringAlt_1$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
%    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_2\StringAlt_1)$ & = & $(\Lens_2.\PutROf{\String_2}{\StringAlt_2})(\Lens_1.\PutROf{\String_1}{\StringAlt_1})$\\
%    $\PutL{} \App (\StringAlt_2\StringAlt_1) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
%  \end{tabular}
%\end{center}
\begin{centermath}
  \begin{tabular}{m{5cm}m{7cm}}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \OrLensOf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
  $
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
        \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \OrLens lens deals with data that can come in one form or another. If the
data gets changed from one format to the other, information in the old format is
lost. This differs from the \OrLens lens of classical symmetric
lenses, as those can retain such information in the complement (see
\S\ref{sec:related}).
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1\ldots\String_n$
%    & =
%    & $(\Lens.\CreateROf{\String_1})\ldots(\Lens.\CreateROf{\String_n})$\\
%    
%    $\CreateL{} \App \StringAlt_1\ldots\StringAlt_n$
%    & =
%    & $(\Lens.\CreateLOf{\StringAlt_1})\ldots(\Lens.\CreateLOf{\StringAlt_n})$\\
%    
%    $\PutR{} \App (\String_1\ldots\String_n) \App (\StringAlt_1\ldots\StringAlt_m)$
%    & =
%    & $\StringAlt_1'\ldots\StringAlt_n'$ where $\StringAlt_i' =
%      \begin{cases*}
%        \Lens.\PutROf{\String_i}{\StringAlt_i} & if $i \leq m$\\
%        \Lens.\CreateROf{\String_i} & otherwise
%      \end{cases*}$\\
%    $\PutL{} \App (\StringAlt_1\ldots\StringAlt_m) \App (\String_1\ldots\String_n)$
%    & =
%    & $\String_1'\ldots\String_n'$ where $\String_i' =
%      \begin{cases*}
%        \Lens.\PutROf{\StringAlt_i}{\String_i} & if $i \leq n$\\
%        \Lens.\CreateROf{\StringAlt_i} & otherwise
%      \end{cases*}$
%  \end{tabular}
%\end{center}
\begin{centermath}
  \begin{tabular}{m{5cm}m{6cm}}
$
  \centering
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt
  }
  {
    \MergeROf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \BRegexAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\Lens_1.\CreateLOf{\StringAlt}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}

The \MergeR lens is interesting because it merges data where one data can be in
two formats, and one data has only one format. In previous
work~\cite{boomerang}, this was combined into \OrLens{}, where
\OrLens{} could have ambiguous types, but we find it more clear to have explicit
merge operators: it is easier to see what lens the synthesis algorithm is
creating.

\begin{centermath}
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex \Leftrightarrow \BRegexAlt_2
  }
  {
    \MergeLOf{\Lens_1}{\Lens_2} \OfType
    \BRegex
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
\end{centermath}
The \MergeL lens is symmetric to \MergeR.

\begin{centermath}
  \begin{tabular}{m{5cm}m{6cm}}
  $
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegexAlt \Leftrightarrow \BRegexAltAlt\\
  }
  {
    \ComposeLensOf{\Lens_1}{\Lens_2} \OfType
    \BRegex \Leftrightarrow \BRegexAltAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$ & = & $\Lens_2.\CreateROf{(\Lens_1.\CreateROf{\String})}$\\
    $\CreateL{} \App \StringAlt$ & = & $\Lens_1.\CreateLOf{(\Lens_2.\CreateLOf{\StringAlt})}$\\
    $\PutR{} \App \String \App \StringAltAlt$ & = & $\Lens_2.\PutROf{(\Lens_1.\PutROf{\String}{(\Lens_2.\CreateLOf{\StringAltAlt})})}{\StringAltAlt}$\\
    $\PutL{} \App \StringAltAlt \App \String$ & = & $\Lens_1.\PutLOf{(\Lens_2.\PutLOf{\StringAltAlt}{(\Lens_2.\CreateROf{\String})})}{\String}$
  \end{tabular}
\end{tabular}
\end{centermath}
Composing is interesting in the put functions. Because puts require intermediary
data, we recreate that intermediary data with creates.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
\inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \IterateLensOf{\Lens} \OfType
    \StarOf{\BRegex}
    \Leftrightarrow
    \StarOf{\BRegexAlt}
  }
  $
  &
  $
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \InvertOf{\Lens} \OfType \BRegexAlt \Leftrightarrow \BRegex
  }
  $
\end{tabular}
\end{centermath}
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
%    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
%    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
%    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
%  \end{tabular}
%\end{center}
The \IterateLens lens deals with iterated data, while inverting reverses the direction of a lens: creating on the right becomes creating on the left and vice versa, and putting on the right becomes putting on the left and vice versa. The invert combinator is particularly useful when chaining many compositions together, as it can be used to align the central types.
\[
  \centering
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \BRegex \SSREquiv \BRegex'\\
    \BRegexAlt \SSREquiv \BRegexAlt'
  }
  {
    \Lens \OfType \BRegex' \Leftrightarrow \BRegexAlt'
  }
\]

Type equivalence enables a lens of type $S \Leftrightarrow T$ to be used as a
lens of type $S' \Leftrightarrow T'$ if $S$ is equivalent to $S'$ and $T$ is
equivalent to $T'$. Type equivalence is useful both for addressing type
annotations, and for making well-typed compositions.

\subsection{Lens Likelihoods}
\label{subsec:lenscosts}
Our likelihood metric is based on the expected amount of information required to
recover a string in one data format from the other. We use the function
$\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ to calculate bounds on the
expected amount of information required to recover a string in $\RegexAlt$ from
a string in $\Regex$, synchronized by $\Lens$. Similarly, we use the function
$\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ to calculate bounds on the
expected amount of information required to recover a string in $\Regex$ from a
string in $\RegexAlt$, synchronized by $\Lens$. We write $a(b,c)$ to
mean $(a*b,a*c)$, and $(a,b)+(c,d)$ to mean $(a+c,b+d)$.
\begin{center}
  \begin{tabular}{rcl}
    $\REntropyOf{\RegexAlt \Given \IdentityLensOf{\RegexAlt}, \RegexAlt}$
    & =
    & [0,0]\\
    
    $\REntropyOf{\RegexAlt \Given \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}, \Regex}$
    & =
    & [\EntropyOf{\RegexAlt},\EntropyOf{\RegexAlt}]\\

    $\REntropyOf{\PRegexStar{\RegexAlt}{\ProbabilityAlt} \Given \IterateLensOf{\Lens}, \PRegexStar{\Regex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}\REntropyOf{\RegexAlt \Given \Lens, \Regex}$\\
    
    $\REntropyOf{\RegexAlt_1 \Concat \RegexAlt_2 \Given \ConcatLensOf{\Lens_1}{\Lens_2}, \Regex_1 \Concat \Regex_2}$
    & =
    & $\REntropyOf{\RegexAlt_1 \Given \Lens_1, \Regex_1} + \REntropyOf{\RegexAlt_2 \Given \Lens_2, \Regex_2}$\\
    
    $\REntropyOf{\RegexAlt_2 \Concat \RegexAlt_1 \Given \SwapLensOf{\Lens_1}{\Lens_2}, \Regex_1 \Concat \Regex_2}$
    & =
    & $\REntropyOf{\RegexAlt_2 \Given \Lens_1, \Regex_2} + \REntropyOf{\RegexAlt_1 \Given \Lens_1, \Regex_1}$\\
    
    $\REntropyOf{\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt} \Given \OrLensOf{\Lens_1}{\Lens_2}, \PRegexOr{\Regex_1}{\Regex_2}{\Probability}}$
    & =
    & $\Probability\REntropyOf{\Regex_1 \Given \Lens_1, \RegexAlt_1} + (1-\Probability)\REntropyOf{\Regex_2 \Given \Lens_2, \RegexAlt_2}$\\
    
    $\REntropyOf{\RegexAlt \Given \MergeROf{\Lens_1}{\Lens_2}, \PRegexOr{\Regex_1}{\Regex_2}{\Probability}}$
    & =
    & $\Probability\REntropyOf{\RegexAlt \Given \Lens_1, \Regex_1} + (1-\Probability)\REntropyOf{\RegexAlt \Given \Lens_2, \Regex_2}$\\
    
    $\REntropyOf{\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt} \Given \MergeLOf{\Lens_1}{\Lens_2}, \Regex}$
    & =
    & $(0,\REntropyOf{\RegexAlt_1 \Given \Lens_1, \Regex}+\REntropyOf{\RegexAlt_2 \Given \Lens_2, \Regex}+1)$\\
    
    $\REntropyOf{\Regex \Given \InvertOf{\Lens}, \RegexAlt}$
    & =
    & $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$\\
  \end{tabular}
\end{center}
$\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ is defined symmetrically. These
functions bound the expected number of bits to recover one data format from a
synchronized string in the other format. Note that we would be able to exactly
calculate the conditional entropy, were it not for \MergeL and \MergeR. If
$\MergeLOf{\Lens_1}{\Lens_2} \OfType \Regex \Leftrightarrow
\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt}$, given a string in $s$, we
need to determine if the synchronized string is in $\RegexAlt_1$ or $\RegexAlt_2$.
However, this information content is dependent on the how likely the
synchronized string is to be in $\RegexAlt_1$ or $\RegexAlt_2$. Nevertheless, we
typically calculate the conditional entropy exactly, as merges are relatively
uncommon in practice; only 2 of the lenses synthesized in our benchmarks
include merges.

The likelihood of a lens is the negative of its \emph{cost}. The cost of a lens
between two SREs $cost(\Lens, \Regex, \RegexAlt) = \MaxOf{\LEntropyOf{\Regex
    \Given \Lens, \RegexAlt}} + \MaxOf{\REntropyOf{\RegexAlt \Given \Lens,
    \Regex}}$ is the sum of the maximum expected number of bits to recover the
left format from the right, and the right from the left. We have proven theorems
demonstrating the calculated entropy corresponds to the actual conditional
entropy to recover the data.

\begin{theorem}
  Let $\Lens \OfType \Regex \Leftrightarrow \RegexAlt$, where $\Lens$ does not
  include composition, $\Regex$ and $\RegexAlt$ are unambiguous, and neither
  $\Regex$ nor $\RegexAlt$ contain any empty subcomponents.
  \begin{enumerate}
  \item $\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ bounds the entropy of
    $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt}}$, given $\SetOf{s
      \SuchThat s \in \LanguageOf{\Regex} \BooleanAnd \Lens.\PutROf{s}{t} = t}$
  \item $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ bounds the entropy of
    $\SetOf{s \SuchThat s \in \LanguageOf{\Regex}}$, given $\SetOf{t \SuchThat t
      \in \LanguageOf{\RegexAlt} \BooleanAnd \Lens.\PutLOf{t}{s} = s}$
  \end{enumerate}
\end{theorem}

% SAZ: This looks like a bad merge, since the paragraph below is better
% Note we have not defined entropy for lens compositions. Consider the lens
% $\Lens_1 ; \Lens_2$, where both $\Lens_1$ and $\Lens_2$ are non-bijective.
% However, their composition could actually be bijective, for example if the
% intermediary format contains information not present in either the source nor
% the target. While this composition may be a bijection (and should have zero
% cost), it is difficult to see this looking merely at the syntax.

Note that our definition of $\Entropy^\rightarrow$ contains no case for sequential
composition $\Lens_1 ; \Lens_2$ and our theorem excludes lenses that contain
such compositions.  Defining the entropy of lenses involving
composition is challenging because $\Lens_1$ might, for instance, add some
information that is subsequently projected away in $\Lens_2$. Such operations
can cancel, leaving a zero-entropy bijection composed from two non-zero entropy
transformations. However, detecting such cancellations directly is complicated and
this property is difficult to determine merely from syntax. Fortunately, we are able to
sidestep such considerations by synthesizing \emph{DNF lenses}---simple symmetric
lenses that inhabit a disjunctive normal form that does not include
composition.

%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
%    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
%    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
%    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
%  \end{tabular}
%\end{center}
% end ssl

% begin synthesis
\section{Synthesis}
\label{sec:synthesis}
Algorithm~\ref{alg:synth-sym-lens} presents our synthesis algorithm at a high
level of abstraction. This algorithm searches for likely lenses in priority
order one ``class'' at a time using a \GreedySynth subroutine. Each class is the
set of lenses that can by typed by a pair of regular expressions, modulo a set
of simple axioms such as associativity, commutativity, and distributivity. The
\Expand subroutine generates new classes using the star-unrolling axioms
(\UnrollstarLeftRule{} and \UnrollstarRightRule).

To summarize, the input regular
expressions are first converted into stochastic regular expressions with
\ToStochastic. This pair of SREs is used to initialize a priority queue ($pq$).
The priority of a SRE pair is the number of rewrites needed to derive the pair
from the originals. Next, $\PCF{SynthSymLens}$ enters a loop that searches for
likely lenses. The loop terminates when the algorithm believes it is unlikely to
find a better lens than the best one it has found so far (a termination
condition defined by $\PCF{\Continue}$). Within each iteration of the loop, it:
\begin{itemize}
\item pops the next class ($S$, $T$) of lenses to
search off of the priority queue ($\PCF{\PQ.Pop}$),
\item executes $\GreedySynth$ to find a best lens in that class if
one exists ($\Lens$),
using the examples $\Examples$ to filter out potential lenses that do not satisfy
the specification,
\item replaces $best$ with $\Lens$, if $\Lens$ is more likely according
to our information-theoretic metric, and
\item adds the SREs derived from rewriting $S$ and $T$ ($\Expand(S,T)$)
  to the priority queue.
\end{itemize}
When the loop terminates, the search returns the globally best lens found
($best$).  Each subroutine of this algorithm will be explained in
further depth in the following subsections.


\begin{algorithm}[t]
  \caption{\SynthSymLens}
  \label{alg:synth-sym-lens}
  \begin{algorithmic}[1]
    \Function{SynthSymLens}{$\BRegex,\BRegexAlt,\Examples$}
    \State $\Regex \gets \Call{\ToStochastic}{\BRegex}$
    \State $\RegexAlt \gets \Call{\ToStochastic}{\BRegexAlt}$
    \State $\RXSearchState \gets \Call{\PQ.Create}{\Regex,\RegexAlt}$
    \State $\Best \gets \None$
    \While{$\Call{\Continue}{\RXSearchState,\Best}$}
    \State $(\Regex,\RegexAlt) \gets \Call{\PQ.Pop}{\RXSearchState}$
    \State $\Lens \gets \Call{\GreedySynth}{\Examples,\Regex,\RegexAlt}$
    \If{$\Call{Cost}{\Lens} < \Call{Cost}{\Best}$}
    \State $\Best \gets \Lens$
    \EndIf
    \State $\Call{\PQ.Push}{\RXSearchState,\Expand(\Regex,\RegexAlt)}$
    \EndWhile
    \State \ReturnVal{best}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%In this work, we aim to quickly find a good lens between two regular expressions
%that satisfies the input-output examples. To this end, we develop an information
%theoretic metric for how much data is synchronized. Information theoretic
%metrics require a notion of probability distributions \emph{how are probability
%  distributions being used, are certain things weighted more etc, assign weights
%  to different subcomponents and parts of the data}. We annotate the regular
%expressions with a reasonable probability distribution, making them
%\emph{stochastic regular expressions}. Armed with probability distributions over
%the languages, we have the capabilities to define information theoretic metrics
%over these probability distributions.
%
%Our overall synthesis algorithm utilizes two synthesizers shown in
%Figure~\ref{fig:high-level-algorithm}. There are an infinite number of possible
%lenses between two regular expressions that can be searched through. Instead of
%searching through all possible lenses, the lenses are grouped into classes of
%lenses based on the syntax of the regular expressions they synchronize. Two
%lenses are in the same class if they can be typed by the same regular
%expressions, using no star equivalences. This works well for synthesis, as
%finding a good lens within these classes permits an efficient synthesis
%procedure.
%
%However, proposing these classes is complicated by stochastic regular
%expressions. While the equivalences on regular expressions are well studied, the
%equivalences on stochastic regular expressions are not. We want to propose
%equivalent stochastic regular expressions, but both the languages and
%probability distributions must be maintained. If the probability distributions
%are not maintained, then the metric by which we compare our lenses changes for
%each class of lenses, we can't compare lenses between classes. To alleviate
%this, we describe the \emph{star-semiring} equivalences on stochastic regular
%expressions, and prove they are sound with respect to language and probability
%distributions. Our \RXSearch proposes stochastic regular expressions by
%traversing a subset of these equivalences, so \RXSearch only proposes regular
%expression pairs equivalent to the originals.
%
%The second algorithm, \GreedySynth, searches within a class for the lowest cost
%lens.  It is a greedy algorithm, and not guaranteed to find the lowest cost
%lens.  However, we haven't found any instances in which \GreedySynth doesn't find
%the optimal lens, due to the partial backtracking we implemented. \GreedySynth
%works by searching, not through symmetric lenses, but through an alternative
%language of Symmetric DNF lenses. After finding such a symmetric DNF lens, that
%symmetric DNF lens is converted into a simple symmetric lens.

\subsection{Searching for $(\Regex,\RegexAlt)$ Candidate Classes}
The first phase of the synthesis algorithm looks for pairs of SREs
$(\Regex,\RegexAlt)$ to drive the \GreedySynth algorithm.  These pairs are
generated using the star unrolling axioms:
\begin{center}
  \begin{tabular}{rcl}
    $\PRegexStar{\Regex}{\Probability}$
    & \Rewrite
    & \PRegexOr{\EmptyString{}}{(\RegexConcat{\Regex{}}{\PRegexStar{\Regex{}}{\Probability}})}{1-\Probability}\\

    $\PRegexStar{\Regex}{\Probability}$
    & \Rewrite
    & \PRegexOr{\EmptyString{}}{(\RegexConcat{\PRegexStar{\Regex{}}{\Probability}}{\Regex{}})}{1-\Probability}
  \end{tabular}
\end{center}
as well as the congruence rules that allow these rewrites to be applied on
subexpressions.
The priority queue yields stochastic regular expressions generated using fewer
rewrites first. Only when there are no more proposed regular expressions derived
from $n$ rewrites will \PCF{\PQ.Pop} propose regular expressions derived from
$n+1$ rewrites.

The procedure \PCF{\Continue} terminates the loop based on the how long the
search has been going, and how hard it expects the next class of problems to be.
In particular, if $\PCF{PQ.Peek}(pq) = (\Regex,\RegexAlt)$, that RE pair is at
distance $d$, the number of pairs in $pq$ at distance $d$ is $n$, and the
current best lens has cost $c$, then $\Call{Continue}{pq}$ continues the loop
while $c < d + \Log_2(n)$. This termination condition is based around two
primary principles: do not search overly deep ($d$), and do not tackle a
frontier that would take too long to process ($\Log_2(n)$). The log of the
frontier is included because the frontier grows much faster than lens costs
grow. Lens cost grows with the log of the expected number of choices in a given
lens (due to its information theoretic basis), so the frontier calculation does
too.

When $\Call{Continue}{pq}$ terminates the loop, the algorithm stops proposing
regular expression pairs, and instead returns to the user the best lens found
thus far. If the algorithm finds a bijective lens, which
has zero cost, it will immediately return.
%
\subsection{Stochastic DNF Regular Expressions}
\label{subsec:sdnfre}
The \GreedySynth subroutine converts input SREs into a temporary pseudo-normal
form, \emph{Stochastic DNF regular expressions} (\SDNFREabbrev{}s).
\SDNFREabbrev{}s normalize across many of the star-semiring equivalences -- if
two regular expressions are equal modulo differences in associativity,
commutativity, or distributivity, their corresponding SREs are syntactically
equal.

Syntactically, stochastic DNF regular expressions (\DNFRegex, \DNFRegexAlt) are
lists of stochastic sequences. Stochastic sequences (\Sequence, \SequenceAlt)
themselves are lists of interleaved strings and stochastic atoms. Stochastic
atoms (\Atom,\AtomAlt) are iterated stochastic DNF regular expressions.

\begin{center}
  \begin{tabular}{l@{\ }c@{\ }l@{\ }>{\itshape\/}r}
    % DNF_REGEX
    \Atom{},\AtomAlt{} & \GEq{} & \PRegexStar{\DNFRegex{}}{\Probability}
% & \StarAtomType{}
\\
    \Sequence{},\SequenceAlt{} & \GEq{} &
                                                       $\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n}$ 
%& \MultiConcatSequenceType{} 
\\
    \DNFRegex{},\DNFRegexAlt{} & \GEq{} & $\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}$ %& \MultiOrDNFRegexType{} 
  \end{tabular}
\end{center}

Intuitively, stochastic DNF regular expressions are stochastic
regular expressions with all concatenations fully distributed over all
disjunctions. As such, the language of a stochastic DNF regular expression is a
union of its subcomponents, the language of a stochastic sequence is the
concatenation of its subcomponents, and the language of a stochastic atom is the
iteration of its subcomponent. For
$\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}$
to be a valid stochastic DNF regular expression, the probabilities must sum to
one ($\sum_{i=0}^n\Probability_i = 1$).

\begin{trivlist}
  \centering
\item 
  % \begin{center}
  \begin{tabular}{@{\ }v@{\ }q}
    \LanguageOf{\PRegexStar{\DNFRegex{}}{\Probability}} \ =\  &
                                            \{\String_1\Concat\ldots\Concat\String_n
                                            \SuchThat \forall i,  \String_i\in\LanguageOf{\DNFRegex}\}\\
    \LanguageOf{\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n}}\ =\  & 
    % \\
    % \multicolumn{2}{L}{\ \ \ \ 
    \{\String_0\Concat\StringAlt_1\cdots\StringAlt_n\Concat\String_n \SuchThat \StringAlt_i\in\LanguageOf{\Atom_i}\}
    % }
    \\
    \LanguageOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}\ =\  &
    % \\
    % \multicolumn{2}{L}{\ \ \ \ 
    \{\String \SuchThat \String \in \LanguageOf{\Sequence_i} \text{\ and $i\in\RangeIncInc{1}{n}$}\}
    % }
  \end{tabular}
  % \end{center}
\end{trivlist}

As these DNF regular expressions are \emph{stochastic}, they are annotated with
probabilities to express a probability distribution, in addition to a
language.
\begin{center}
  \begin{tabular}{rcl}
    $\ProbabilityOf{\PRegexStar{\DNFRegex}{\Probability}}{\String}$
    & =
    & $\Sigma_n \Sigma_{\String = \String_1 \ldots \String_n}\Probability^n(1-\Probability)\Pi_{i=1}^n\ProbabilityOf{\DNFRegex}{\String_i}$\\
    
    $\ProbabilityOf{\SequenceOf{\String_0 \SeqSep \Atom_1 \SeqSep \ldots \SeqSep \Atom_n \SeqSep \String_n}}{\String'}$
    & =
    & $\Sigma_{\String' = \String_0\String_1'\ldots\String_n'\String_n}\Pi_{i = 1}^n\ProbabilityOf{\Atom_i}{\String_i'}$ \\
    
    $\ProbabilityOf{\DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_n,\Probability_n)}}{\String}$
    & =
    & $\Sigma_{i=1}^n\Probability_i\ProbabilityOf{\Sequence_i}{\String}$\\
  \end{tabular}
\end{center}

\begin{figure}
  \raggedright
  $\ConcatSequence{} \OfType{} \ArrowTypeOf{\SequenceType{}}{\ArrowTypeOf{\SequenceType{}}{\SequenceType{}}}$\\
  $\ConcatSequenceOf{[\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n]}{[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]}=
  [\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$\\

  \medskip
  
  $\ConcatDNF{} \OfType{} \ArrowTypeOf{\DNFRegexType{}}{\ArrowTypeOf{\DNFRegexType{}}{\DNFRegexType{}}}$\\
  $\ConcatDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}=$\\
      $\DNFLeft (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_1},\Probability_1\ProbabilityAlt_1)\DNFSep \ldots
      \DNFSep
      (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_m},\Probability_1\ProbabilityAlt_m)\DNFSep
      \ldots$\\
      $\DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_1},\Probability_n\ProbabilityAlt_1)\DNFSep
      \ldots \DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_m},\Probability_n\ProbabilityAlt_m) \DNFRight$
  
  \medskip
  
  $\OrDNF{}_{\Probability} \OfType{}
  \ArrowTypeOf{\DNFRegexType{}}{\ArrowTypeOf{\DNFRegexType{}}{\DNFRegexType{}}
  }$ \\
  $\OrDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}{\Probability} =$\\
  $\DNFOf{(\Sequence_1,\Probability_1\Probability)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n\Probability)\DNFSep(\SequenceAlt_1,\ProbabilityAlt_1(1-\Probability))\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m(1-\Probability))}$
  
  \medskip
  
  \AtomToDNF{} \OfType
  \ArrowTypeOf{\AtomType{}}{\DNFRegexType{}}\\
  $\AtomToDNFOf{\Atom} = \DNFOf{(\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep
      \EmptyString},1)}$
  \caption{Stochastic DNF Regular Expression Functions}
  \label{fig:dnf-regex-functions}
\end{figure}

The algorithm for converting a stochastic regular expressions $\Regex$ into its
corresponding \SDNFREabbrev form, written
$\ToDNFRegexOf{\Regex}$, is defined below. This conversion relies on operators
defined in Figure~\ref{fig:dnf-regex-functions}.
\[
  \begin{array}{rcl@{\hspace*{3em}}rcl}
    \ToDNFRegexOf{\String} 
    & = 
    & \DNFOf{(\SequenceOf{\String},1)}

    & \ToDNFRegexOf{(\RegexConcat{\Regex_1}{\Regex_2})} 
    & = 
    & \ToDNFRegexOf{\Regex_1} \ConcatDNF \ToDNFRegexOf{\Regex_2} \\

    \ToDNFRegexOf{\emptyset} 
    & = 
    & \DNFOf{}

    & \ToDNFRegexOf{(\PRegexOr{\Regex_1}{\Regex_2}{\Probability})} 
    & = 
    & \ToDNFRegexOf{\Regex_1} \OrDNF_{\Probability} \ToDNFRegexOf{\Regex_2} \\

    \ToDNFRegexOf{(\PRegexStar{\Regex}{\Probability})} & = & \AtomToDNFOf{\PRegexStar{(\ToDNFRegexOf{\Regex})}{\Probability}}\\
    
  \end{array}
\]
After this syntactic conversion has taken place, the sequences are ordered
(normalizing commutativity differences). This conversion respects languages and
probability distributions.

\begin{theorem}
  $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$ and $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$.
\end{theorem}

\paragraph*{Entropy}
We have developed a syntactic means for finding the entropy of a stochastic DNF
regular expression, like we have for stochastic regular expressions. This
enables us to efficiently find the entropy without first converting a \SDNFREabbrev to
a stochastic regular expression.

\begin{center}
  \begin{tabular}{rcl}
    $\EntropyOf{\PRegexStar{\DNFRegex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}(\EntropyOf{\DNFRegex} - \Log_2\Probability)
      - \Log_2(1-\Probability)
      $\\
    
    $\EntropyOf{\SequenceOf{\String_0 \SeqSep \Atom_1 \SeqSep \ldots \SeqSep \Atom_n \SeqSep \String_n}}$
    & =
    & $\Sigma_{i = 1}^n\EntropyOf{\Atom_i}$ \\
    
    $\EntropyOf{\DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_n,\Probability_n)}}$
    & =
    & $\Sigma_{i=1}^n\Probability_i(\EntropyOf{\Sequence_i}+\Log_2\Probability_i)$\\
  \end{tabular}
\end{center}

\begin{theorem}
  $\EntropyOf{\DNFRegex}$ is the entropy of $P_{\DNFRegex}$.
\end{theorem}

\paragraph*{\ToStochastic} With stochastic DNF regular expressions and
\ToDNFRegex defined, it is easier to explain \ToStochastic, the function that
converts regular expressions into stochastic regular expressions. If $\Regex$ is
a stochastic regular expression generated by \ToStochastic, then when put into
\SDNFREabbrev form, $\ToDNFRegexOf{\Regex} = \DNFOf{(\Sequence_1,\frac{1}{n})
  \DNFSep \ldots \DNFSep (\Sequence_n,\frac{1}{n})}$ for some sequences
$\Sequence_1\ldots\Sequence_n$, and every stochastic atom generated by
\ToStochastic is $\PRegexStar{\DNFRegex}{.8}$. In particular, $\ToDNFRegex$
generates regular expressions whose DNF form gives equal probability to all
sequence subcomponents of the \SDNFREabbrevs, and gives a .8 chance for
stars to continue iterating. In our experience generating random strings from regular
expressions, these probabilities provide good distributions of strings---stars
are iterated 4 times on average, and no individual choice in a series of
disjunctions is chosen disproportionately often.

\subsection{Relevance Annotations}
\label{subsec:relevanceannotations}

Even though our generated probability distribution works well in most
situations, it is not perfect. Consider synthesizing a lens between the formats
shown in Figure~\ref{fig:minimized-representations}. Because salary information is
present in \lstinline{emp_salaries}, but not in \lstinline{emp_insurance}, the
algorithm might spend a long time (fruitlessly) trying to construct lenses that
transform the salary to information present in \lstinline{emp_insurance} even
though that is impossible. In a similar but more elaborate example, such wasted
processing effort may cause synthesis to fail to terminate in any reasonable
amount of time.

One solution would be to cut off the search early. However, then one runs into
the opposite problem: In other scenarios, salary information may be present in
the other format, but it may take quite a bit of work to find a
transformation that connects the salary in \lstinline{emp_salaries} to the
salary in the second format. Hence, early termination
may cut off synthesis before the right lens is found.

We can solve both problems by allowing users to augment the specifications with
\emph{relevance annotations}. Sometimes, users have external knowledge that certain
information appears exclusively in one format or the other, or they may know the
information is present both formats. By communicating this knowledge to the synthesis algorithm
through relevance annotations, users can force the synthesis of lenses that
discard or retain certain information.
The first annotation, $\SkipOf{\Regex}$, says the information of
$\Regex$ appears only in $\Regex$, and can safely be
projected. The second annotation, $\SRequireOf{\Regex}$, says the information of
$\Regex$ appears in the other format and cannot be discarded.

For example, users can easily recognize that salary information is not present
in \lstinline{emp_insurance}. By annotating the \lstinline{salary} field as
\lstinline{skip(salary)}, users can add this knowledge to the specification to
optimize the search. In practice, we define the information content of
$\Skip(\Regex)$ to be zero.
\begin{gather*}
  \EntropyOf{\Skip(\Regex)} = 0
\end{gather*}

Similarly, users can recognize that employee names are present in both files. By
annotating instances of \lstinline{name} as \lstinline{require(name)}, users can
add this knowledge to the specification to optimize the search and force the
generated lens to retain \lstinline{name} information. In practice, we
make any lens that loses ``required'' information infinitely unlikely.
%
\begin{center}
  \begin{tabular}{rcl}
    $\REntropyOf{\SRequireOf{\RegexAlt} \Given \Lens, \Regex}$
    & =
    & $\begin{cases}
      \infty & \text{if }\REntropyOf{\SRequireOf{\RegexAlt} \Given \Lens, \Regex}
      \neq 0\\
    0 & \text{otherwise}
  \end{cases}$\\
    
    $\REntropyOf{\RegexAlt \Given \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}, \Regex}$
    & =
    & $\begin{cases}
      \infty & \vspace*{-.3em}\text{if $\RegexAlt$ contains $\SRequireOf{\RegexAlt'}$ as a}\\
      & \text{subexpression, where $\EntropyOf{\RegexAlt'} \neq 0$}\\
    [\EntropyOf{\RegexAlt},\EntropyOf{\RegexAlt}] & \text{otherwise}
  \end{cases}$\\
  \end{tabular}
\end{center}

\subsection{Symmetric DNF Lenses}
Symmetric DNF lenses are an intermediate synthesis target for \GreedySynth.
There are many fewer symmetric DNF lenses than symmetric regular lenses. In
fact, if one does not use the star-unrolling axioms, there are only finitely
many DNF lenses of a given type (though there are still many more symmetric DNF
lenses than DNF bijective lenses).

The structure of symmetric DNF lenses mirrors that of SDNF REs. A symmetric DNF
lens ($sdl$) is a union of symmetric sequence lenses, a symmetric sequence
lens ($ssql$) is a concatenation of symmetric atom lenses, and a
symmetric atom lens ($sal$) is an iteration of a symmetric DNF lens.

Just as we analyzed the information content of ordinary regular expressions, we
can analyze the information content of DNF regular expressions. As before, we
use $\REntropyOf{\DNFRegexAlt \Given \SDNFLens, \DNFRegex}$ to calculate bounds
on the expected amount of information required to recover a string in
$\DNFRegexAlt$ from a string in $\DNFRegex$, synchronized by $\SDNFLens$. We use
the function $\LEntropyOf{\DNFRegex \Given \SDNFLens, \DNFRegexAlt}$ to
calculate bounds on the expected amount of information required to recover a
string in $\DNFRegex$ from a string in $\DNFRegexAlt$, synchronized by
$\SDNFLens$.

The details of these definitions are syntactically tedious, but not
intellectually difficult. We elide them here but include them in the
appendix \ifappendices \S\ref{sec:appendixdnf}.  \else{} (in the supplemental
materials).\fi

\subsection{\GreedySynth}
\label{subsec:greedy-synth}
The synthesis procedure comprises three algorithms: one that greedily finds
symmetric DNF lenses (\GreedySynth), one that greedily finds symmetric sequence
lenses (\GreedySeqSynth), and one that finds symmetric atom lenses
(\AtomSynth{}). These three algorithms are hierarchically structured:
\GreedySynth relies on \GreedySeqSynth, \GreedySeqSynth relies on \AtomSynth,
and \AtomSynth relies on \GreedySynth. The structure of the algorithms mirrors
the structure of symmetric DNF lenses and \SDNFREabbrevs.

\begin{algorithm}[t]
  \caption{\GreedySynth}
  \label{alg:greedysynth}
  \begin{algorithmic}[1]
    \Function{GreedySynth}{$\Examples,\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)},\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}$}
    \If{$\Call{CannotMap}{\Examples,\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)},\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}$}
    \State $\ReturnVal{\None}$
    \EndIf
    \State $\SLS \gets
    \Call{\CartesianMap}{\GreedySeqSynth(\Examples),\ListOf{\Sequence_1;\ldots;\Sequence_n},\ListOf{\SequenceAlt_1;\ldots;\SequenceAlt_m}}$
    \State $\GreedyState \gets \Call{PQ.Create}{\SLS}$
    \State $\LensBuilder \gets \Call{LensBuilder.Empty}{}$
    \While{$\Call{PQ.IsNonempty}{\GreedyState}$}
    \State $\SSQLens \gets
    \Call{PQ.Pop}{\GreedyState}$
    \If{$\Call{LensBuilder.UsefulAdd}{\LensBuilder,\SSQLens,\Examples}$}
    \State $\LensBuilder \gets \Call{LensBuilder.AddSeq}{\LensBuilder,\SSQLens}$
    \EndIf
    \EndWhile
    \State \ReturnVal{\Call{LensBuilder.ToDNFLens}{\GreedyState}}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\paragraph*{Symmetric DNF Lenses} Algorithm~\ref{alg:greedysynth} presents
\GreedySynth, which synthesizes symmetric DNF lenses. Its inputs 
are a suite of input-output examples and a pair of stochastic DNF regular expressions.
%
First, \PCF{CannotMap} determines whether there is no lens satisfying the
examples, and if so, \GreedySynth returns \None immediately. Otherwise, \GreedySynth finds
the best lenses (given the examples that match them) between all sequence pairs
$(SQ_i, TQ_j)$ drawn from the left and right DNF regular expressions. (The
function \CartesianMap maps its argument across the cross product of the input
lists). A priority queue containing these sequence lenses, ordered by likelihood, is
then initialized with $\PCF{PQ.Create}$. The symmetric lens is then built up
iteratively from these sequence lenses, where the state of the partially
constructed lens is tracked in the lens builder, \LensBuilder.

\GreedySynth loops until there are no more sequence lenses in the priority
queue. Within this loop, a sequence lens is popped from the queue and, if it is
``useful,'' is included in the final DNF lens. The lens is considered to be
useful when its source (or target) is \textit{not} already the source (or
target) of an included sequence lens. If examples require that two
sequences have a lens between them, such lenses are considered useful. The
priorities of the sequence lenses update as the algorithm proceeds: if two
sequence lenses have the same source, the second one to be popped gets a higher
cost than it originally had; information must now be stored for including that
source of non-bijectivity.

As an example, consider searching for a lens between \lstinline{"" | name.name$^*$} and \lstinline{"" | name}. \GreedySynth might first pop the
sequence pair \lstinline{""} and \lstinline{""}, because there is a bijective
sequence lens between them. As neither \lstinline{""} is involved in a sequence
lens, this lens is considered useful. Next, the sequence lens between
\lstinline{name.name$^*$} and \lstinline{name} would be popped: while that lens
is not bijective it is still better than the alternatives. As all sequences are
now involved in sequence lenses, and there are no examples to make other lenses
useful, no more sequence lenses would be added to the lens builder.

Finally, after all sequences have been popped, the partial DNF lens \LensBuilder is
converted into a symmetric DNF lens. This is only possible if all sequences are
involved in some sequence lens: if they are not, \PCF{LensBuilder.ToDNFLens}
instead returns \None.

\paragraph*{Symmetric Sequence lenses} Algorithm~\ref{alg:greedyseqsynth}
presents \GreedySeqSynth, which synthesizes symmetric sequence lenses using an
algorithm whose structure is similar to \GreedySynth{}'s.  It calls \PCF{AtomSynth}, 
which synthesizes atom lenses by iterating a DNF lens between
its subcomponents. 

The inputs to \GreedySeqSynth are a suite of input-output examples and a pair of
lists of stochastic atoms. As in \GreedySynth, \GreedySeqSynth returns \None early if
there is no possible lens. Afterward, \GreedySeqSynth finds the best lenses
between each atom pair of the left and right sequences, and organizes them into
a priority queue ordered by likelihood with \PCF{PQ.Create}. The symmetric sequence
lens is built up iteratively from these atom lenses, where the state of the
partially built lens is tracked in the sequence lens builder, \SeqLensBuilder.

\GreedySeqSynth loops until there are no more atom lenses in the priority
queue. In the loop, a popped atom lens is considered 
``useful'' if adding it to the sequence will lower the
cost of the generated sequence lens, or if examples show that one of its atoms
must not be disconnected. Each atom can be part of only one lens at a time, so
the algorithm must sometimes remove a previously chosen atom lens in order to connect 
one that must not be disconnected.
% After all atoms have been popped, the sequence lens is validated and
% returned.
The algorithm succeeds when all atoms that must not be disconnected
are involved in an atom lens; \PCF{SLensBuilder.ToDNFLens}
returns \None otherwise.

\begin{algorithm}[t]
  \caption{\GreedySeqSynth}
  \label{alg:greedyseqsynth}
  \begin{algorithmic}[1]
    \Function{AtomSynth}{$\Examples,\PRegexStar{\DNFRegex}{\Probability},\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}$}
    \If{$\Call{CannotMap}{\Examples,\PRegexStar{\DNFRegex}{\Probability},\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}}$}
    \State $\ReturnVal{\None}$
    \Else
    \State $\ReturnVal{\IterateLensOf{\GreedySynth(\Examples,\DNFRegex,\DNFRegexAlt)}}$
    \EndIf
    \EndFunction

    \Function{GreedySeqSynth}{$\Examples,\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n},\SequenceOf{\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\String_m}$}
    \If{$\Call{CannotMap}{\Examples,\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n},\SequenceOf{\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\String_m}}$}
    \State $\ReturnVal{\None}$
    \EndIf
    \State $\ALS \gets
    \Call{\CartesianMap}{\AtomSynth(\Examples),\ListOf{\Atom_1;\ldots;\Atom_n},\ListOf{\AtomAlt_1;\ldots;\AtomAlt_m}}$
    \State $\GreedyState \gets \Call{PQ.Init}{\ALS}$
    \State $\SeqLensBuilder \gets \Call{SLensBuilder.Empty}{}$
    \While{$\Call{PQ.IsNonempty}{\GreedyState}$}
    \State $\SAtomLens \gets
    \Call{PQ.Pop}{\GreedyState}$
    \If{$\Call{SLensBuilder.UsefulAdd}{\SeqLensBuilder,\SAtomLens,\Examples}$}
    \State $\GreedyState \gets \Call{SLensBuilder.AddAtom}{\GreedyState,\SAtomLens}$
    \EndIf
    \EndWhile
    \State \ReturnVal{\Call{SLensBuilder.ToDNFLens}{\GreedyState}}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Optimizations}
\label{subsec:optimizations}

Our implementation includes a number of optimizations not described above:
annotations that guide DNF conversion; an expansion inference algorithm;
and compositional synthesis. The optimizations
make the system performant enough for interactive use.

\paragraph*{Open and Closed Regular Expressions} While \GreedySynth acts
relatively efficiently, it can suffer from an exponential blowup when converting
SREs to DNF form. This problem can be mitigated by avoiding the conversion
of some SREs to DNF form and by performing the conversion lazily when necessarily.
More specifically, \Expand labels some unconverted SREs as ``closed,'' which means the
type-directed \GreedySynth algorithm treats them as DNF atoms and does not dig into
them recursively.  In other words,
given a pair of closed SREs, \GreedySynth can either construct
the identity lens between them (it will do this if they are the same SRE), or it can
construct a disconnect lens between them.
Regular expressions that are not annotated as closed are considered ``open.''

Distinguishing between open and closed regular expressions improves the
efficiency of \GreedySynth, but forces \Expand to decide which closed
expressions to open. At the start of synthesis, all regular expressions are
closed, and \Expand rewrites selected closed regular expressions to open ones
(thereby triggering DNF normalization).
%is allowed to to
%map closed regular expressions to each other, but only by using the identity
%lens---they must parse the same string components in all examples.
%This change is easy
%to support by adding non-DNF stochastic regular expressions as a new type of
%``closed'' atom. When converted into a DNF regular expression, if $\Regex$ is
%annotated as ``closed'', then $\ToDNFRegexOf{\Regex} = \AtomToDNFOf{\Regex}$.

\paragraph*{Expansion Inference} These additional rewrites make the search
through possible regular expressions harder. Our algorithm identifies when
certain closed regular expressions can \emph{only} be involved in a disconnect
lens (unless opened). Such regular expressions will automatically be opened.

\paragraph*{Compositional Synthesis} Compositional synthesis allows \GreedySynth to use
previously defined (by users or synthesis) lenses. As the synthesizer processes a Boomerang file, it accumulates
lens definitions and types.  It tackles synthesis problems one after another
and there may be many such problems in a given program.
During synthesis, if an existing lens has the right type and agrees with the examples,
\GreedySynth will use it.  If a large synthesis problem cannot be solved all
at once, a user can generate subproblems for parts of a data format, and the
larger problem can subsequently use solutions to those subproblems. For example,
when given the synthesis task:
%
\begin{lstlisting}
let l_1 = synth R <=> S
let l_2 = synth R' <=> S'
\end{lstlisting}
%
the synthesis algorithm use the previously generated \lstinline{l_1} in the
synthesis of \lstinline{l_2}.
In our experience,
this is a very powerful tool that allows synthesis to tackle problems of arbitrary
complexity.
% end synthesis

% begin evaluation
\section{Evaluation}
\label{sec:evaluation}
We implemented simple symmetric lenses as an extension to
Boomerang~\cite{boomerang}. In doing so, we reimplemented Boomerang's
asymmetric lens combinators using a combination of the symmetric
combinators presented in this paper and symmetric versions of asymmetric
extensions (like matching lenses~\cite{matchinglenses} and quotient
lenses~\cite{quotientlenses}) already present in Boomerang. We also integrated
our synthesis engine into Boomerang, allowing users to write synthesis tasks
alongside lens combinators, incorporate synthesis results into manually-written
lenses, and reference previously defined lenses during synthesis. All experiments
were performed on a 2.5 GHz Intel Core i7 processor with 16 GB of 1600 MHz DDR3
running macOS Mojave.

In this evaluation, we aim to answer four primary questions:
\begin{enumerate}
\item Can the algorithm (with suitable examples and annotations) find the correct lens?
\item Is the synthesis procedure efficient enough to be used in everyday
  development?
\item How much slower is our tool on bijective lens synthesis benchmarks than
  prior work customized for bijective lenses~\cite{optician}?
\item How effective is the information-theoretic search heuristic and how do our
  annotations affect the results?
\end{enumerate}


\subsection{Benchmark Suite}
Our benchmarks are drawn from three different sources.
\begin{enumerate}
\item We adapted 8 data cleaning benchmarks from Flash Fill~\cite{flashfill}. Flash Fill data
  cleaning tasks are either derived from online help forums or taken from the
  Excel product team. Note that our tool produces bidirectional transformations
  rather than one-way transformers like Flash Fill. We ensure one direction of
  our bidirectional transformers performs the same unidirectional transformation
  as Flash Fill---the other direction is determined from the round-tripping
  laws. None of these benchmarks were bijective.
\item We adapted 29 benchmarks from Augeas~\cite{augeas}. Augeas is a utility
  that bidirectionally converts between Linux configuration files and an
  in-memory dictionaries. In our benchmarks, we synthesize lenses between Linux
  configuration files and serialized versions of Augeas dictionaries. Because
  these benchmarks merely transformed the information into a structured form,
  synthesized lenses were all bijective.
\item We created 11 additional benchmarks 
  derived from real-world examples and/or the bidirectional programming
  literature. These tasks range from synchronizing REST and JSON web resource
  descriptions to synchronizing BibTeX and EndNote citation descriptions. Five
  of these benchmarks were not bijective lenses.
\end{enumerate}

Each task consists of a source and target regular expression and a set of
examples. We are synthesizing transformations between real formats, so these
tasks are can be quite large -- on average, the size of each RE
in the specification is 1637 and the size of the synthesized lens is 3254.

\subsection{Synthesizing Correct Lenses}

To determine whether the system can synthesize desired lenses, we ran it
interactively on all 48 tasks, working with the system to create sufficient
examples and provide useful relevance annotations.  In all cases, the desired lens
was obtained.
%
The majority of the tasks required only a single example and none required
more than three examples to synthesize the desired lens.\footnote{In
  one benchmark, we supplied a fourth example that was later discovered to 
  be unnecessary.}  

Providing relevance annotations was needed in only 8 of the 48 tasks. In
practice, we found that adding such annotations quite easy: if manual inspection
of the lens showed there were too few \IdentityLens{}s, and too many
\Disconnect{}s or merges, we would add \SRequire annotations. If synthesis took
too long, we would add \Skip annotations.
Section~\ref{subsec:effect-of-heuristics} studies the effects of removing such
annotations.

We verified that our default running mode (\SSOpt{}) generated the correct lenses the way programmers often
validate their programs: we manually inspected the code and ran unit tests on
the synthesized code. To determine whether the synthesis procedure generated the
correct lens when running in modes other than \SSOpt{}, we compared generated lens
to the lens synthesized by \SSOpt{}.


%%A realistic benchmarks suite is critical in answering the first research
%%question. To determine whether our algorithm is fast enough to be used in
%%everyday development, we need to evaluate whether we can solve real-world
%%problems efficiently. 


\subsection{Effectiveness of Compositional Synthesis}

Having determined appropriate examples and annotations for the 48
benchmarks, we evaluate the performance of the system by measuring the running
time of our algorithm in two modes:

\begin{tabulary}{\linewidth}{rL}
  \SSOpt{}: & Run the symmetric synthesis algorithm with all optimizations enabled.\\
  \SSNCOpt{}: & Run the symmetric synthesis algorithm, with no compositional synthesis enabled.\\
\end{tabulary}\\

Recall that compositional synthesis allows users to break a benchmark into a
series of smaller synthesis tasks, whose solutions are utilized in more complex
synthesis procedures. Compositional synthesis (\SSOpt{} mode)
allows our system to scale to arbitrarily large and complex formats; measuring
it shows the responsiveness of the system when used as
intended. \SSNCOpt{} mode, which synthesizes a complete lens all at once,
provides a useful experimental stress test for the system.

\begin{figure}
  \includegraphics{generated-graphs/times}
  \vspace{-4ex}
  \caption{Number of
    benchmarks that can be solved by a given algorithm in a 
    given amount of time. \SSOpt{} is the full symmetric synthesis algorithm.
    \SSNCOpt{} is the symmetric synthesis algorithm without using a library of
    existing lenses. The symmetric synthesis algorithm is able to complete all
    benchmarks in under 30 seconds elapsed total time. Without compositional
    synthesis it is able to complete 26. Each benchmark specification includes
    source and target (potentially annotated) regular expressions, and between
    one and three sufficient examples.}
  \label{fig:times}
\end{figure}

For each benchmark in the suite and each mode, we ran the system with a timeout
of 60 seconds, averaging the result over 5 runs. Figure~\ref{fig:times}
summarizes the results of these tests. We find that our algorithm is able to
synthesize all of the benchmarks in under 30 seconds. Without compositional
synthesis, the synthesis algorithm is able to solve 26 out of 48 problem instances.

% Section~\ref{subsec:optimizations} that users may tune the termination metric.
% Success on this set of benchmarks requires we tune that termination condition
% (e.g. for some benchmarks, allowing the system flexibility to spend more time
% considering more of the search space). In

\subsection{Slowdown Compared to Bijective Synthesis}

To compare to the existing bijective synthesis algorithm, we run our symmetric
synthesis algorithm on the original Optician benchmarks, comprised of
39 bijective synthesis tasks.\footnote{We had to slightly alter four of these
benchmarks, either by providing additional examples or by adding in \SRequire annotations.
Without these alterations, symmetric synthesis yielded a lens that fit
the specification but that was undesired.}

To perform this comparison, we synthesized lenses in two modes:

\begin{tabulary}{\linewidth}{rL}
  \BSOpt{}: & The existing bijective synthesis
              algorithm with all optimizations enabled.\\
  \SSOpt{}: & The symmetric synthesis algorithm with all optimizations enabled.\\
\end{tabulary}\\

For each benchmark, we ran it in both modes with a
timeout of 60 seconds and averaged the result over 5 runs.
Figure~\ref{fig:times_bijective} summarizes the results of these tests. On
average, \SSOpt{} took 1.3 times (0.5 seconds) longer to complete than
\BSOpt{}. The slowest completed benchmark for both synthesis algorithms is
\texttt{xml\_to\_augeas.boom}, a benchmark that converts arbitrary XML up to
depth 3 into a serialized version of the structured dictionary representation
used in Augeas. This benchmark takes 18.9 seconds for the symmetric synthesis
algorithm to complete, and 9.3 seconds the bijective synthesis algorithm to
complete. 

\begin{figure}[t]
  \includegraphics{generated-graphs/times_bijective}
  \vspace{-4ex}
  \caption{Number of benchmarks that can be solved by a given algorithm in a
    given amount of time. \SSOpt{} is the full symmetric synthesis algorithm.
    \BSOpt{} is the full bijective lens synthesis algorithm.}
  \label{fig:times_bijective}
\end{figure}

\subsection{The Effects of Heuristics and Relevance Annotations}
\label{subsec:effect-of-heuristics}
We evaluate the usefulness of (1) our information-theoretic metric, (2) our
termination heuristic and (3) our
relevance annotations.  To this end, we run our program in several different modes:\\[1ex]
\begin{tabulary}{\linewidth}{rL}
  \AnyOpt{}: & Ignore the information-theoretic preference metric (\IE, all valid
               lenses have cost 0). \\ 
  \FLOpt{}: &  Return the first highest ranked lens \GreedySynth returns (\IE,
              ignore the termination heuristic). \\
  \CCOpt{}: & Replace our information-theoretic cost metric with one where
              the cost of the lens is the number of disconnects plus the number
              of merges.\\
  \NSOpt{}: & Ignore all \Skip annotations in the SRE specifications. \\
  \NROpt{}: & Ignore all \SRequire annotations in the SRE specifications. \\
\end{tabulary}


We experimented with the \CCOpt{} mode to determine whether the
complexity of the information-theoretic measure was really
needed. Related work on string transformations has often used simpler
measures such as ``avoid constants'' that align with, but are simpler
than our measures. The \CCOpt{} mode is an example of such a simple
measure---it operates by counting disconnects, which put a complete
stop to information transfer, and merges, which
eliminate the information in a union. 

\begin{figure}[t]
  \includegraphics{generated-graphs/metrics_importance}
  \vspace{-4ex}
  \caption{Number of benchmarks that synthesize the correct lens by a given
    algorithm. \AnyOpt{} provides no notion of cost, and merely returns the
    first lens it finds that satisfies the specification. \FLOpt{} provides a
    notion of cost to \GreedySynth, but once a satisfying lens is greedily
    found, that lens is returned. \CCOpt{} synthesizes lenses, where the cost of
    a lens is the number of disconnects plus the number of merges. \NSOpt
    ignores all \Skip annotations while running the algorithm. \NROpt ignores
    all \SRequire annotations while running the algorithm.}
  \label{fig:metric}
\end{figure}

Figure~\ref{fig:metric} summarizes the result of these experiments. The data
reveal that the information-theoretic metric is critical for finding the correct
lens: Only 10 of the benchmarks succeeded when running in \CCOpt{} mode. The
termination condition is also quite important. When running in \FLOpt{} mode,
the algorithm only discovers 5 lenses, which shows that the first class that
contains a satisfying lens is rarely the correct class. However, our algorithm
is not perfect and fails when either it is very difficult to find the desired
lens (necessitating \SRequire) or when a large amount of data is projected
(necessitating \Skip). Without any annotations, our algorithm finds the correct
lens for 40 of our 48 benchmarks; eight required relevance annotations to find
the correct lens.
% end evaluation

% begin related-work
\section{Related Work}
\label{sec:related}

In this paper, we have designed and implemented a new, pragmatic
formulation of symmetric lenses as well as new program synthesis
techniques.  In this section, we analyze the relationship
between our simple symmetric
lenses and two previous lens languages:  classical symmetric lenses
and asymmetric lenses. Proofs about these relationships are included in
the appendix \ifappendices  \S\ref{sec:appendixforget}. \else{}included with the supplemental
material.  \fi We also comment on related
program synthesis techniques.

\subsection{Relationship with Classical Lens Languages}
\label{sec:relationship}
%\paragraph*{Formalization}
%We have reformulated the problem addressed by classical
%symmetric lenses with simple symmetric lenses.

\paragraph*{Symmetric Lenses}
A classical symmetric lens\cite{symmetric-lenses} $\Lens$ between $X$ and $Y$ consists of 4 components:
a complement $C$, a designated element $init \in C$, and two functions,
$\PutRSym \OfType X \times C \rightarrow Y \times C$ and $\PutLSym \OfType Y
\times C \rightarrow X \times C$, that propagate changes in one format to the
other.

In this formulation, data unique to each side are stored in the complement. When
one format is edited, the \PutR or \PutL function stitches together the edited
data with data stored in the complement. The $init$ element is the initial value
of $C$ and specifies default behavior when data is missing. For instance, to
implement the scenario in Figure~\ref{fig:minimized-representations}, the
complement would consist of a list of pairs of salary and company name.
Classical symmetric lenses satisfy the following equational laws.
\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
  \begin{mathprooftree}
    \AxiomC{$\PutRSymOf{(x,c)} = (y,c')$}
    \UnaryInfC{$\PutLSymOf{(y,c')} = (x,c')$}
  \end{mathprooftree}
&
  \begin{mathprooftree}
    \AxiomC{$\PutLSymOf{(y,c)} = (x,c')$}
    \UnaryInfC{$\PutRSymOf{(x,c')} = (y,c')$}
  \end{mathprooftree}
\end{array}
\end{centermath}

Two classical symmetric lenses are equivalent if they output the same formats
given any sequence of edits. Formally, given a lens $\Lens$ between $X$ and $Y$, an \emph{edit} for $\Lens$ is a member of $X + Y$. Consider the function
$apply$, which, given a lens and an element of that lens's complement, is a
function from sequences of edits to sequences of edits. If $apply(\Lens,c,es) =
es'$, then given complement $c$ and edit $es_i$, the lens $\Lens$ generates
$es'_i$.
\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule
  {
  }
  {
    apply(\Lens,c,[]) = []
  }
$
&
$
  \inferrule
  {
    \Lens.putr(x,c) = (y,c')\\
    apply(\Lens,c',es) = es'
  }
  {
    apply(\Lens,c,(\InLOf{x})::es) = (\InROf{y})::es'
  }
$
\end{tabular}
\end{centermath}
\[
  \inferrule
  {
    \Lens.putl(y,c) = (x,c')\\
    apply(\Lens,c',es) = es'
  }
  {
    apply(\Lens,c,(\InROf{y})::es) = (\InLOf{x})::es'
  }
\]
\noindent
Two lenses, $\Lens_1$ and $\Lens_2$, are equivalent if
$apply(\Lens_1,\Lens_1.init,es) = apply(\Lens_2,\Lens_2.init,es)$ for all $es$.

%% By describing our lenses in this complement style, we can express an incredibly
%% wide class\bcp{where is the evidence that this class of lenses is {\em
%%     usefully} wider than simple symmetric lenses?} of lenses, as these complements permit storing any amount of
%% information in them.  However, they pose problems when implementing them in
%% real-world systems and in synthesizing them.

%\paragraph*{Issues with Classical Symmetric Lenses}
%\iffalse Using symmetric lenses for synchronization forces us to maintain not
%just two files that we aim to sycnrhonize, but three. \bcp{I don't find it
%  unintuitive, and I think we should be careful not to oversell the difficulty
%  of storing the complements. It requires more engineering, but it's not rocket
%  science.}This is unintuitive, and creates many problems in practice. For
%example, consider the situation where I am synchronizing a crontab and job
%manager file. I am synchronizing across computers, so I must either maintain a
%copy of the complement on each computer, and keep them synchronized, or figure
%out a computer to hold the complement, and make sure all edits go through that
%complement. Furthermore, if I want to change the synchronization to a different
%computer, I don't need to merely make sure that my files are moved to the
%computer, I also have to make sure that I correctly move the complement, and
%hook up that complement to be used for that synchronization task. This is a huge
%divergence from other synchronization utilities\bcp{No. For example, Unison
%  maintains a database on each replica recording, for each file, what its hash
%  was after the last time the two replicas were synchronized.}, where all that
%needs to be done is maintain the files. Using those for synchronization, edits
%can be sent over the wire, and the appropriate function can stitch together
%those edits, no additional state needed. \fi

Simple symmetric lenses are a strict subset of classical symmetric lenses, but
quite a useful one. For instance, all asymmetric lenses are expressible as
simple symmetric lenses. The primary loss is the loss of ``memory'' within the
complement. In classical symmetric lenses, disjunctive (\OrLens) lenses retain information
about both possible formats. If a user edits a format from one disjuncted format
to the other, the information contained in that first disjunct is retained
within the complement. Simple symmetric lenses have no such complement, so they
mimic the forgetful disjunctive lens of classical symmetric lenses.

Though classical symmetric lenses are more expressive, they introduce drawbacks
for synthesis: because each lens has a
custom complement, one can no longer specify the put functions through
input/output examples alone. One alternative would be to enrich specifications
with edit sequences; another would be to specify the structure of complements
explicitly (though the latter would be somewhat akin to specifying the internal
state of a program). In either case, the complexity of the specifications
increases.
%% addition, users would have to specify some auxilary 
%% to specify the behavior through the observable behavior of edit sequences.
%% Second, there are lenses that require arbitrarily long edit sequences to
%% differentiate between: consider the lens that keeps two formats equal for the
%% first $k$ non-identity edits, then keeps them completely unsynchronized for all
%% future edits.  This requires an edit sequence of $k$ edits to differentiate
%% between this lens and the identity lens.  Simple symmetric lenses avoid this
%% problem by disallowing such lenses: we can't keep track of the number of
%% non-identity edits performed unless there are explicit fields in the data
%% formats keeping track of them.  While we are reducing the expressivity of our
%% lenses with this restriction, we feel the benefits outweigh the costs.

\paragraph*{Symmetric Lenses vs.{} Simple Symmetric Lenses} To compare classical and simple
symmetric lenses, we define an $apply$ function on simple symmetric lenses as well. If
$apply(\Lens,\None,es) = es'$, then starting with no prior data, after edit
$es_i$, the lens \Lens generates $es_i'$ (the right format if $es_i =
\InLOf{x}$, and the left format if $es_i = \InROf{y}$). If
$apply(\Lens,\SomeOf{(x,y)},es) = es'$, then starting with data $x$
and $y$ on the left and right, respectively, after edit $es_i$, the lens \Lens
generates $es_i'$.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule
  {
  }
  {
    apply(\Lens,xyo,[]) = []
  }
$
&
$
  \inferrule
  {
    \Lens.\CreateROf{x} = y\\
    apply(\Lens,\SomeOf{(x,y)},es) = es'
  }
  {
    apply(l,\None,\InLOf{x}::es) = \InROf{y}::es'
  }
$
\end{tabular}
\end{centermath}
\[
  \inferrule
  {
    \Lens.\CreateLOf{y} = x\\
    apply(\Lens,\SomeOf{(x,y)},es) = es'
  }
  {
    apply(l,\None,\InROf{y}::es) = \InLOf{x}::es'
  }
\]
\[
  \inferrule
  {
    \Lens.\PutROf{x'}{y}  = y'\\
    apply(\Lens,\SomeOf{(x',y')},es) = es'
  }
  {
    apply(l,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'
  }
\]
\[
  \inferrule
  {
    \Lens.\PutLOf{y'}{x}  = x'\\
    apply(\Lens,\SomeOf{(x',y')},es) = es'
  }
  {
    apply(l,\SomeOf{(x,y)},\InROf{y'}::es) = \InLOf{x'}::es'
  }
\]

Next, we define \emph{forgetful symmetric
  lenses} to be symmetric lenses that satisfy the following additional laws.
\begin{equation}
  \tag{\ForgetfulRL}
  \begin{mathprooftree}
    \AxiomC{$\Lens.putr(x,c_1) = (\_,c_1')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putr(x,c_2) = (\_,c_2')$}
    \AxiomC{$\Lens.putl(y,c_1') = (\_,c_1'')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putl(y,c_2') = (\_,c_2'')$}
    \def\extraVskip{2pt}
    \singleLine
    \BinaryInfC{$c_1'' = c_2''$}
  \end{mathprooftree}
\end{equation}
\begin{equation}
  \tag{\ForgetfulLR}
  \begin{mathprooftree}
    \AxiomC{$\Lens.putl(y,c_1) = (\_,c_1')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putl(y,c_2) = (\_,c_2')$}
    \AxiomC{$putr(x,c_1') = (\_,c_1'')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putr(x,c_2') = (\_,c_2'')$}
    \def\extraVskip{2pt}
    \singleLine
    \BinaryInfC{$c_1'' = c_2''$}
  \end{mathprooftree}
\end{equation}

Intuitively, these equations state that complements are uniquely determined by
the most recent input $x$ and $y$. Such lenses correspond exactly with simple
symmetric lenses, where all state is maintained by the $x$ and $y$ data.

\begin{theorem}
  Let $\Lens$ be a classical symmetric lens. The lens $\Lens$ is equivalent to a forgetful
  lens if, and only if, there exists a simple symmetric lens $\Lens'$ where
  $apply(\Lens,\Lens.init,es) = apply(\Lens',\None,es)$, for all put sequences $es$.
\end{theorem}

\paragraph*{Asymmetric Lenses}
Formally, an {\em asymmetric lens} $ \ell : S \Leftrightarrow V$ is a triple of functions $\ell.\get : S \longrightarrow V$, $\ell.\pput : V \longrightarrow S \longrightarrow S$ and $\ell.\create : V \longrightarrow S$ satisfying the following laws \cite{Focal2005-long}:
\begin{align*}
\ell.\get \; (\ell.\pput \; s \; v) &= v \tag{PUTGET}\\
\ell.\pput \; s \; (\ell.\get \; s) &= s \tag{GETPUT}\\
\ell.\get \; (\ell.\create \; v) &= v \tag{CREATEGET}
\end{align*}
Simple symmetric lenses are strictly more expressive than classical asymmetric
lenses.

\begin{theorem}
  Let $\Lens$ be an asymmetric lens. $\Lens$ is also a simple symmetric lens,
  where:
  \begin{center}
    \begin{tabular}{rcl@{\hspace*{3em}}rcl}
      $\Lens.\CreateLOf{y}$ & $=$ & $\Lens.create \App y$
      & $\Lens.\CreateROf{x}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\PutLOf{y}{x}$ & $=$ & $\Lens.put \App y \App x$
      & $\Lens.\PutROf{x}{y}$ & $=$ & $\Lens.get \App x$
    \end{tabular}
  \end{center}
\end{theorem}

\paragraph*{Other Lens Formulations}
Bidirectional programming has an extensive literature, with many extensions onto
basic lenses, like quotient lenses~\cite{quotientlenses} and matching
lenses~\cite{matchinglenses}. Readers can consult
\citet{DBLP:conf/icmt/CzarneckiFHLST09} for a survey of lenses
and lens-like structures.

\subsection{Data Transformation Synthesis}
Over the past decade, the programming languages community has explored the
synthesis of programs from a wide variety of angles. One of the key ideas is
typically to narrow the program search space by focusing on a specific domain,
and imposing constraints on syntax~\cite{sygus},
typing~\cite{augustsson-2004,gvero-pldi-2013,osera+:pldi15,feser-pldi-2015,scherer-icfp-2015,frankle+:popl16},
or both.
%, and as has been advocated
%more generally under the rubric of syntax-guided synthesis~\cite{sygus}.

Automation of string transformations, in particular, has been the focus
of much prior attention.  For example, Gulwani and others work on FlashFill
generates one-way spreadsheet transformations from input/output
examples~\cite{flashfill,le-pldi-2014}.  On the one hand,
FlashFill is easier to use because one need not specify the type of
the data being transformed.  On the other hand, this type information
makes it possible to transform more complex formats. For example, Flash Fill
does not synthesize programs with nested loops~\cite{flashfill},
and hence is incapable of synthesizing the majority of our
benchmarks, even in one direction.
%% Flashfill, designed
%% for transformation of the cells of spreadsheets, does not scale to
%% more complex formats
%% While this provides an easier
%% interaction model with the user than this work, it requires the algorithm to
%% learn the data formats from the examples. This makes the task much more
%% difficult for the synthesis algorithm, particularly in addressing iterations and
%% disjunctions. Prior work has shown that learning from examples and data format
%% descriptions enables synthesis of much more complex transformations than are
%% permitted by examples alone. Recent work has gone into making these algorithms
%% more robust by delaying the selection of program until seeing what further
%% inputs the program is run on~\cite{?}. By doing this, the synthesis algorithm
%% can learn additional information about the formats from the use of the program.

All pragmatic synthesis algorithms use heuristics of one kind or another. One of
the goals of the current paper is to try to ground those heuristics in a broader
theory, information theory, with the hope that this theory may inform future
design decisions and help us understand heuristics crafted in other tools and
possibly in other domains. For instance, we speculate that some of the
heuristics used in FlashFill (to take one well-documented example) may be
connected to some of the principles laid out here. For instance, Flash Fill
prioritizes the substring constructor over the constant string constructor when
ranking possible programs. Such a choice is consistent with our
information-theoretic viewpoint as the constant function throws away a great
deal of information about the source string being transformed. Likewise, Flash
Fill prefers ``wider'' character classes over ``narrower'' ones. Again such a
choice is implied by information theory---the wider class preserves more
information during translation. More broadly, we hope our information-theoretic
analysis provides a basis for understanding the heuristic choices made in
related work.

%% In many of these synthesis algorithms the correct transformation is chosen by
%% principals like ``minimize constants''~\cite{?,?,?} and ``most specific
%% generalization''~\cite{?,?,?}. We are the first work to our knowledge to use an
%% information-theoretic measure for finding the correct transformation. However,
%% much of our metrics are compatible with existing metrics: avoiding \Disconnect
%% lenses minimizes constants and creates more specfic transformations (\Disconnect
%% lenses permit more synchronized data).

As discussed in the introduction,
the Optician tool~\cite{optician,maina+:quotient-synthesis} was a building block for
our work.  Optician synthesized bijective transformations~\cite{optician} and
bijections modulo quotients~\cite{maina+:quotient-synthesis}, but could
not synthesize more complex bidirectional transformations where one format contains
important information not present in the other---a common situation in the real
world.  From a technical perspective, the first key novelty in our work involves the definition, theory,
analysis, and implementation of a new class of simple symmetric lenses, designed
for synthesis.  The second key technical innovation involves the use of stochastic
regular expressions and information theory to guide the search for program transformations.
As mentioned earlier, we believe such information-theoretic techniques may have broad utility
in helping us understand how to formulate a search for a data transformation function.
%% The central contributions
%% only synchronized transformations between formats in
%% bijective correspondence, but few formats satisfy that constraint. Recent
%% enhancements have permitted synthesis of more expressive lenses, quotient
%% bijective lenses. These enhancements were made by strengthening the
%% specifications from regular expressions to QREs, regular expressions annotated
%% with information on normal forms of the language. This enhancement permits
%% synthesizing transformations between formats whose normal forms are in bijective
%% correspondence. While we have not integrated our system to permit QRE
%% specifications, we see no reason the two systems cannot be integrated.

While our tool uses types and examples to specify invertible transformations, other
tools have been shown to synthesize a backwards transformation from ordinary code designed
to implement the forwards transformation.  For instance, \citet{program-inversion-symbolic-transducers} show how to invert transformations
using symbolic finite automata, and
\citet{bidirectionalization-for-free} demonstrates how to
construct reverse transformations from forwards transformations
by exploiting parametricity properties.  These kinds of tools are very useful, but in different
circumstances from ours (namely, when one already has the code to implement one direction of
the transformation).

More broadly, information theory and probabilistic languages are common tools in
natural language understanding, machine translation, information retrieval, data
extraction and grammatical inference (see \citet{pereira:info-theory},
for an introduction). Indeed, our work was inspired, in part, by the PADS format
inference tool~\cite{pads:synthesis}, which was in turn inspired by earlier work
on probabilistic grammatical inference and information
extraction~\cite{kushmerick-thesis,arasu:extracting}. PADS did not synthesize
data transformers, and we are not aware of the use of information-theoretic
principles in type-directed or syntax-guided synthesis of DSL programs.

%% Other work synthesizing invertible transformations was done by inverting a
%% previously defined transformation.  This has been done by exploiting
%% parametricity to invert transformations~\cite{}, and by inverting symbolic
%% finite automata~\cite{?}.

%% \subsection{Type-Directed Synthesis}

%% Type-directed synthesis uses type information to tighten specifications and
%% reduce the number of possible programs. Typically, type-directed synthesis
%% techniques use the types to orient the search space.  Our work interestingly
%% deals with types with many semantic equivalences on them. InSynth~\cite{?}
%% deals with the same problem when trying to synthesize transformations involving
%% library functions. InSynth addresses this in a similar manner to this work: by
%% normalizing the types we don't need to search through the equivalences on those
%% types.

% end related-work

% begin conclusion
\section{Conclusion}
\label{sec:conc}
We described a synthesis algorithm for synthesizing synchronization
functions between data formats that may not be in bijective correspondence.
We identified a subset of symmetric lenses, simple symmetric lenses, 
develop new combinators for them, and show how to synthesize them from regular
expression specifications. In order to guide the search for ``likely'' lenses,
we introduce new search principles based on information theory and allow users
to control this search via relevance annotations. To evaluate the effectiveness
of these ideas, we designed and implemented a new tool for symmetric lens
synthesis and integrated it into the Boomerang lens programming framework. Our
experiments on 48 benchmarks demonstrate that we can synthesize complex lenses for
real-life formats in under 30 seconds.

% end conclusion

% begin acknowledgements
\begin{acks}
\end{acks}
% end acknowledgements

\ifanon\else
\fi

% We recommend abbrvnat bibliography style.

% The bibliography should be embedded for final submission.

\bibliography{local,bcp}

\ifappendices
\appendix


\onecolumn

\section{Symmetric Lenses full Detail}
\label{sec:appendixlenses}

Here we provide fullly detailed information on symmetric lenses -- full typing
rules and full semantics.

\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
\begin{array}[b]{c}
\quad\\
  \inferrule*
  {
  }
  {
    \IdentityLensOf{\BRegex} \OfType \BRegex \Leftrightarrow \BRegex
  }
  \\
  \quad
  \end{array}
&
\begin{array}[b]{r@{\ }c@{\ }l}
    \CreateR{} \App s & = & s\\
    \CreateL{} \App s & = & s\\
    \PutR{} \App s \App t & = & s\\
    \PutL{} \App s \App t & = & s\\
  \end{array}
\end{array}
\end{centermath}
Note that the identity lens ignores the second argument in the put functions.
Because the two formats are fully synchronized, no knowledge of the prior data
is needed.

\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
  \inferrule*
  {
    \String \in \LanguageOf{\BRegex}\\
    \StringAlt \in \LanguageOf{\BRegexAlt}
  }
  {
    \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt}
    \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
&
  \begin{array}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String''''$ & = & $\StringAlt$\\
    $\CreateL{} \App \StringAlt'''''$ & = & $\String$\\
    $\PutR{} \App \String''' \App \StringAlt'$ & = & $\StringAlt'$\\
    $\PutL{} \App \StringAlt' \App \String'$ & = & $\String'$
  \end{array}
\end{array}
\end{centermath}

Just as the identity lens ignores the second argument in puts, disconnect lenses
ignore the first in both puts and creates.  The data is unsynchronized in these
two formats, information from one format doesn't impact the other.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \ConcatLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_1 \Concat \BRegexAlt_2
  }
$
&
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \SwapLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_2 \Concat \BRegexAlt_1
  }
$
\end{tabular}
\end{centermath}
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1 \String_2$ & = & $(\Lens_1.\CreateROf{\String_1})(\Lens_2.\CreateROf{\String_2})$\\
    $\CreateL{} \App \StringAlt_1 \StringAlt_2$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_1\StringAlt_2)$ & = & $(\Lens_1.\PutROf{\String_1}{\StringAlt_1})(\Lens_2.\PutROf{\String_2}{\StringAlt_2})$\\
    $\PutL{} \App (\StringAlt_1\StringAlt_2) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
  \end{tabular}
\end{center}

Concat is similar to concatenation in existing string lens languages like
Boomerang.  For such terms, we do not provide the semantics, and merely refer readers to existing work. The swap combinator is similar to concat, though the second regular expression
is swapped.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1\String_2$ & = & $(\Lens_2.\CreateROf{\String_2})(\Lens_1.\CreateROf{\String_1})$\\
    $\CreateL{} \App \StringAlt_2\StringAlt_1$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_2\StringAlt_1)$ & = & $(\Lens_2.\PutROf{\String_2}{\StringAlt_2})(\Lens_1.\PutROf{\String_1}{\StringAlt_1})$\\
    $\PutL{} \App (\StringAlt_2\StringAlt_1) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
  \end{tabular}
\end{center}
\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \OrLensOf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
  $
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
        \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$
      \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1} \BooleanAnd \String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2} \BooleanAnd \String\in\LanguageOf{\BRegex_2}$\\
        \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1} \BooleanAnd \String\in\LanguageOf{\BRegex_2}$\\
        \Lens_2.\CreateLOf{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2} \BooleanAnd \String\in\LanguageOf{\BRegex_1}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \OrLens lens deals with data that can come in one form or another. If the
data gets changed from one format to the other, information in the old format is
lost.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1\ldots\String_n$
    & =
    & $(\Lens.\CreateROf{\String_1})\ldots(\Lens.\CreateROf{\String_n})$\\
    
    $\CreateL{} \App \StringAlt_1\ldots\StringAlt_n$
    & =
    & $(\Lens.\CreateLOf{\StringAlt_1})\ldots(\Lens.\CreateLOf{\StringAlt_n})$\\
    
    $\PutR{} \App (\String_1\ldots\String_n) \App (\StringAlt_1\ldots\StringAlt_m)$
    & =
    & $\StringAlt_1'\ldots\StringAlt_n'$ where $\StringAlt_i' =
      \begin{cases*}
        \Lens.\PutROf{\String_i}{\StringAlt_i} & if $i \leq m$\\
        \Lens.\CreateROf{\String_i} & otherwise
      \end{cases*}$\\
    $\PutL{} \App (\StringAlt_1\ldots\StringAlt_m) \App (\String_1\ldots\String_n)$
    & =
    & $\String_1'\ldots\String_n'$ where $\String_i' =
      \begin{cases*}
        \Lens.\PutROf{\StringAlt_i}{\String_i} & if $i \leq n$\\
        \Lens.\CreateROf{\StringAlt_i} & otherwise
      \end{cases*}$
  \end{tabular}
\end{center}
\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \centering
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt
  }
  {
    \MergeROf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \BRegexAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\Lens_1.\CreateLOf{\StringAlt}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}

The \MergeR lens is interesting because it merges data where one data can be in
two formats, and one data has only one format. In previous
work~\cite{boomerang}, this was combined into \OrLens{}, where
\OrLens{} could have ambiguous types, but we find it more clear to have explicit
merge operators: it is easier to see what lens the synthesis algorithm is
creating.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex \Leftrightarrow \BRegexAlt_2
  }
  {
    \MergeLOf{\Lens_1}{\Lens_2} \OfType
    \BRegex
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\Lens_1.\CreateROf{\String}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \MergeL lens is symmetric to \MergeR.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
  $
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegexAlt \Leftrightarrow \BRegexAltAlt\\
  }
  {
    \ComposeLensOf{\Lens_1}{\Lens_2} \OfType
    \BRegex \Leftrightarrow \BRegexAltAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$ & = & $\Lens_2.\CreateROf{(\Lens_1.\CreateROf{\String})}$\\
    $\CreateL{} \App \StringAlt$ & = & $\Lens_1.\CreateLOf{(\Lens_2.\CreateLOf{\StringAlt})}$\\
    $\PutR{} \App \String \App \StringAltAlt$ & = & $\Lens_2.\PutROf{(\Lens_1.\PutROf{\String}{(\Lens_2.\CreateLOf{\StringAltAlt})})}{\StringAltAlt}$\\
    $\PutL{} \App \StringAltAlt \App \String$ & = & $\Lens_1.\PutLOf{(\Lens_2.\PutLOf{\StringAltAlt}{(\Lens_2.\CreateROf{\String})})}{\String}$
  \end{tabular}
\end{tabular}
\end{centermath}
Composing is interesting in the put functions. Because puts require intermediary
data, we recreate that intermediary data with creates.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
\inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \IterateLensOf{\Lens} \OfType
    \StarOf{\BRegex}
    \Leftrightarrow
    \StarOf{\BRegexAlt}
  }
  $
  &
  $
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \InvertOf{\Lens} \OfType \BRegexAlt \Leftrightarrow \BRegex
  }
  $
\end{tabular}
\end{centermath}
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
  \end{tabular}
\end{center}
The \IterateLens lens deals with iterated data, while inverting reverses the direction of a lens: creating on the right becomes creating on the left and vice versa, and putting on the right becomes putting on the left and vice versa. The invert combonator is particularly useful when chaining many compositions together, as it can be used to align the central types.
\[
  \centering
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \BRegex \SSREquiv \BRegex'\\
    \BRegexAlt \SSREquiv \BRegexAlt'
  }
  {
    \Lens \OfType \BRegex' \Leftrightarrow \BRegexAlt'
  }
\]

Type equivalence enables a lens of type $S \Leftrightarrow T$ to be used as a
lens of type $S' \Leftrightarrow T'$ if $S$ equivalent to $S'$ and $T$ is
equivalent to $T'$. Type equivalence is useful both for addressing type
annotations, and for making well-typed compositions.

\section{Symmetric DNF Lenses: Syntax, Cost, Typing, and Semantics}
\label{sec:appendixdnf}

Here we give full details on symmetric DNF lenses, including syntax, cost,
typing, and semantics.

\paragraph*{Syntax}
Roughly speaking, symmetric DNF lenses are an n-ary union of symmetric sequence
lenses, which are, in turn, an n-ary sequence of atomic lenses. Atomic lenses
are iterations of symmetric DNF lenses. In the following syntax, the
nonterminals $i$, $j$, $p$, $q$, $r$, $c$, and $d$ all represent natural
numbers. The nonterminals $\String$ and $\StringAlt$ represent strings.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{}l@{}}
    % REGEX
    \SAtomLens{} & \GEq{} & $\StarOf{\SDNFLens}$ \\
    \SSQLens{} & \GEq{} & $(\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep
                          \ldots\SeqLSep
                          (i_p,j_p,\SAtomLens_p)}
                          ,\ListOf{(\String_1,\Atom_1);\ldots;(\String_q,\Atom_q)}
                          ,\ListOf{(\StringAlt_1,\AtomAlt_1);\ldots;(\StringAlt_r,\AtomAlt_r)})$ \\
    \SDNFLens{} & \GEq{} & $(\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
                           \ldots\DNFLSep
                           (i_p,j_p,\SSQLens_p)}
                           ,\ListOf{c_1;\ldots;c_q}
                           ,\ListOf{d_1;\ldots;d_r})$ \\
  \end{tabular}
\end{center}

\paragraph*{Information-Theoretic Cost Metric}
Much like we defined a syntactic means to find the expected number of bits to
recover string from a synchronized string in another format for simple symmetric
string lenses, we do the same for symmetric DNF lenses. Unlike simple symmetric
string lenses, DNF lenses do not have composition, so the entropy can be defined
over all terms. $\LEntropyOf{\DNFRegex \Given \SDNFLens, \DNFRegexAlt}$ is the
expected number of bits required to recover a string in $\DNFRegex$ from a
synchronized string in $\DNFRegexAlt$.

\[
  \begin{array}{rl}
    & \LEntropyOf{\DNFOf{\Sequence_1 \DNFSep \ldots \DNFSep \Sequence_n}\\
    & \hspace*{1.21em}\Given
      (\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
      \ldots\DNFLSep
      (i_p,j_p,\SSQLens_p)}
      ,\ListOf{c_1;\ldots;c_q}
      ,\ListOf{d_1;\ldots;d_r})\\
    & \hspace*{1.21em},~\DNFOf{\SequenceAlt_1 \DNFSep \ldots \DNFSep \SequenceAlt_m}}\\
    = & \frac{\Sigma_{j=1}^m(H_j)}{m}\\
    & \text{where } H_j = (0,\Sigma_{\SetOf{k\SuchThat j_k = j}}
      \LEntropyOf{\Sequence_{i_k}\Given\SequenceLens_k,\SequenceAlt_j})
  \end{array}
\]

This entropy calculation for symmetric DNF lenses requires a similar entropy
calculation for symmetric sequence lenses and symmetric atom lenses.

\[
  \begin{array}{rl}
      & \REntropyOf{
        \SequenceOf{\String_0,\Atom_1,\ldots,\Atom_n,\String_n}\\
      & \hspace*{1em}\Given
        (\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep
        \ldots\SeqLSep
        (i_p,j_p,\SAtomLens_p)}
        ,\ListOf{(k_1,\String_1);\ldots;(k_q,\String_q)}
        ,\ListOf{(l_1,\StringAlt_1);\ldots;(l_r,\StringAlt_r)})\\
      & \hspace*{1.21em},~
        \SequenceOf{\StringAlt_0,\AtomAlt_1,\ldots,\AtomAlt_m,\StringAlt_m}}\\
      =
      & \Sigma_{x=1}^p\REntropyOf{\Atom_{i_x} \Given \AtomAlt_{i_x},\AtomLens_x} +
        \Sigma_{x=1}^q\REntropyOf{\Atom_{k_x}}
  \end{array}
\]

The entropy calculation for symmetric sequence lenses requires a similar entropy
calculation for symmetric atom lenses, which in turn relies on the entropy
calculation for symmetric DNF lenses.

\[\begin{array}{rl}
      & \REntropyOf{\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt} \Given \PRegexStar{\DNFRegex}{\Probability},\StarOf{\SDNFLens}}\\
      =
      & \frac{\Probability}{1-\Probability}\REntropyOf{\DNFRegexAlt\Given\DNFRegex,\SDNFLens}
  \end{array}
\]
The expected number of bits required to recover a string in $\DNFRegexAlt$ from
a synchronized string in $\DNFRegex$, $\REntropyOf{\DNFRegexAlt \Given
  \SDNFLens, \DNFRegex}$ is defined symmetrically.


The typing judgment is a 3-ary relation over a single DNF lens, and two DNF
regular expressions. If $\SDNFLens \OfType \DNFRegex \Leftrightarrow
\DNFRegexAlt$, then the $\SDNFLens.\CreateR$, $\SDNFLens.\CreateL$,
$\SDNFLens.\PutR$, and $\SDNFLens.\PutL$ functions form a symmetric lens.

The typing judgement has 3 components. The first is the sublens components,
confirming that the sequence lenses the DNF lens is comprised of are all
well-typed. The second guarantees that if each sequence on the left has a
sequence lens that can be used for \CreateR{}s and \PutR{}s. The last guarantees
the same for sequences on the right, with \CreateL{} and \PutL{}.

\[
  \inferrule*
  {
    \SSQLens_1 \OfType \Sequence_{i_1} \Leftrightarrow \SequenceAlt_{j_1}\\
    \ldots\\
    \SSQLens_p \OfType \Sequence_{i_p} \Leftrightarrow \SequenceAlt_{j_p}\\\\
    i_{c_1} = 1\\
    \ldots\\
    i_{c_q} = q\\\\
    j_{d_1} = 1\\
    \ldots\\
    j_{d_r} = r
  }
  {
    (\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
      \ldots\DNFLSep
      (i_p,j_p,\SSQLens_p)}
    ,\ListOf{c_1;\ldots;c_q}
    ,\ListOf{d_1;\ldots;d_r})
    \OfType\\\\
    \DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_q,\Probability_q)}
    \Leftrightarrow
    \DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1) \DNFSep \ldots \DNFSep (\SequenceAlt_r,\ProbabilityAlt_q)}
  }
\]

The \CreateR{} function looks for the sequence the provided string matches. If
the string matches sequence $\Sequence_x$, then the lens will look in the create
list at position $x$ to find which sequence lens to use. Then, the sequence lens
transforms the given string using that sequence lens.

The \PutR{} function finds what pairs sequences the input source and view
strings match.  If there that pair of sequences have a sequence lens between
them, then the DNF lens merely performs that sequence lens on the provided
strings.  If there isn't a pair of sequence lenses between them, then \CreateR{}
is performed on the source, with the view forgotten.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App s$ & = & $\SSQLens_{c_x}.\CreateR{} \App s$ if $s \in \Sequence_x$\\
  $\CreateL{} \App v$ & = & $\SSQLens_{d_y}.\CreateL{} \App v$ if $v \in \SequenceAlt_y$\\
  $\PutR{} \App s \App v$ & = &
                               $\begin{cases*}
                                 \SSQLens_x.\PutR{} \App s \App v & if $s \in \Sequence_{i_x}$ and $v \in \SequenceAlt_{j_x}$\\
                                 \CreateR{} \App s & if $\nexists x.$ $s \in \Sequence_{i_x}$ and $v \in \SequenceAlt_{j_x}$
                               \end{cases*}$\\
  $\PutL{} \App v \App s$ & = &
                               $\begin{cases*}
                                 \SSQLens_y.\PutL{} \App v \App s & if $v \in \SequenceAlt_{j_y}$ and $s \in \Sequence_{i_y}$\\
                                 \CreateL{} \App v & if $\nexists y.$ $v \in \SequenceAlt_{j_y}$ and $s \in \Sequence_{i_y}$
                               \end{cases*}$
\end{tabular}

\paragraph*{Symmetric Sequence Lenses: Typing and Semantics}
The typing judgment is a 3-ary relation over a single Sequence lens, and two
sequences. If $\SSQLens \OfType \Sequence \Leftrightarrow \SequenceAlt$, then
the $\SSQLens.\CreateR$, $\SSQLens.\CreateL$, $\SSQLens.\PutR$, and
$\SSQLens.\PutL$ functions form a symmetric lens.

The typing judgement has 4 components. The first is the sublens components,
confirming that the atom lenses the sequence lens is comprised of all are
well-typed. The second guarantees that if each string that will be used for
\CreateR{}s are members of the correct atoms.  The third guarantees
the same for strings and atoms on the right, with \CreateL.  The last guarantees
that each atom is mapped by at most one atom lens.

\[
  \inferrule* {
    \SAtomLens_1 \OfType \Atom_{i_1} \Leftrightarrow \AtomAlt_{j_1}\\
    \ldots\\
    \SAtomLens_p \OfType \Atom_{i_p} \Leftrightarrow \AtomAlt_{j_p}\\\\
    \String_{c_1} \in \Atom_{c_1}\\
    \ldots\\
    \String_{c_{q'}} \in \Atom_{c_{q'}}\\\\
    \StringAlt_{d_1} \in \AtomAlt_{d_1}\\
    \ldots\\
    \StringAlt_{d_{r'}} \in \AtomAlt_{d_{r'}}\\\\
    i_x = i_y \BooleanImplies x = y\\
    j_x = j_y \BooleanImplies x = y } {
    (\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep \ldots\SeqLSep
      (i_p,j_p,\SAtomLens_p)}
    ,\ListOf{(\String_{c_1},\Atom_{c_1});\ldots;(\String_{c_{q'}},\Atom_{c_{q'}})}
    ,\ListOf{(\StringAlt_{d_1},\Atom_{d_1});\ldots;(\StringAlt_{d_r},\Atom_{d_r})})\\
    \OfType \SequenceOf{\String_0'''' \SeqSep \Atom_1 \SeqSep \ldots \SeqSep
      \Atom_{q'} \SeqSep \String_{q}'} \Leftrightarrow \SequenceOf{\StringAlt_0'
      \SeqSep \AtomAlt_1 \SeqSep \ldots \SeqSep \AtomAlt_r \SeqSep
      \StringAlt_{r}'} }
\]

For each component of the string matching an atom, the \CreateR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the sequence lens puts the provided string into the
default string for the target atom. If there is no such atom lens, then the
sequence lens merely uses the default string.

For each component of the string matching an atom, the \PutR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the atom lens puts the provided string of the source atom into the
string of the target atom. If there is no such atom lens, then the
sequence lens merely recovers the target's string.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App \String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q'$
  & = 
  & $\StringAlt_0' \Concat \StringAlt_1'' \Concat \ldots \Concat
    \StringAlt_r'' \Concat \StringAlt_r'$\\
  & & where $\StringAlt_y'' =
    \begin{cases*}
      \SAtomLens_k.\PutROf{\String_{i_k}''}{\StringAlt_y} & if $j_k = y$\\
      \StringAlt_y & if $\nexists k. j_k = y$\\
    \end{cases*}$\\
  $\CreateL{} \App \StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q''
  \Concat \StringAlt_q'$
  & = 
  & $\String_0' \Concat \String_1'' \Concat \ldots \Concat
    \String_r'' \Concat \String_r'$\\
  & & where $\String_x'' =
    \begin{cases*}
      \SAtomLens_k.\PutROf{\StringAlt_{j_k}''}{\String_x} & if $i_k = x$\\
      \String_x & if $\nexists k. i_k = x$\\
    \end{cases*}$\\
  $\PutR{} \App (\String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q') \App (\StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q'' \Concat \StringAlt_q')$
  & =
  & $\StringAlt_0'\Concat \StringAlt_1''' \Concat \ldots \Concat \StringAlt_q''' \Concat \StringAlt_q'$\\
  & & where
      $t_y''' =
      \begin{cases*}
        \SAtomLens_k.\PutROf{\String_{i_k}''}{\StringAlt_{y}''} & if $j_k = y$\\
        \StringAlt_y'' & if $\nexists k. j_k = y$\\
      \end{cases*}$\\
  $\PutL{} \App (\StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q'') \Concat (\StringAlt_q' \App \String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q')$
  & =
  & $\String_0'\Concat \String_1''' \Concat \ldots \Concat \String_r''' \Concat \String_r'$\\
  & & where
      $s_x''' =
      \begin{cases*}
        \SAtomLens_k.\PutLOf{\StringAlt_{j_k}''}{\String_{x}''} & if $i_k = x$\\
        \String_x'' & if $\nexists k. i_k = x$\\
      \end{cases*}$\\
\end{tabular}

\paragraph*{Symmetric Atom Lenses: Typing and Semantics}
The typing judgment is a 3-ary relation over a single atom lens, and two
atoms. If $\SAtomLens \OfType \Atom \Leftrightarrow \AtomAlt$, then
the $\SAtomLens.\CreateR$, $\SAtomLens.\CreateL$, $\SAtomLens.\PutR$, and
$\SAtomLens.\PutL$ functions form a symmetric lens.

The typing judgement just confirms that the DNF lens that comprises the
sequence lens is also well typed.

\[
  \inferrule*
  {
    \SDNFLens \OfType \DNFRegex \Leftrightarrow \DNFRegexAlt
  }
  {
    \StarOf{\SDNFLens}
    \OfType \PRegexStar{\DNFRegex}{\Probability}
    \Leftrightarrow \PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}
  }
\]

For each component of the string matching an atom, the \CreateR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the sequence lens puts the provided string into the
default string for the target atom. If there is no such atom lens, then the
sequence lens merely uses the default string.

For each component of the string matching an atom, the \PutR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the atom lens puts the provided string of the source atom into the
string of the target atom. If there is no such atom lens, then the
sequence lens merely recovers the target's string.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App \String_0 \Concat \ldots \Concat \String_n$
  & = 
  & $\StringAlt_1 \Concat \ldots \Concat \StringAlt_n$
  where $\StringAlt_i = \SDNFLens.\CreateR \App \String_i$\\
  $\CreateL{} \App \StringAlt_0 \Concat \ldots \Concat \StringAlt_m$
  & = 
  & $\String_1 \Concat \ldots \Concat \String_m$
  where $\String_i = \SDNFLens.\CreateL \App \StringAlt_i$\\
  $\PutR{} \App (\String_0 \Concat \ldots \Concat \String_n) \App
  (\StringAlt_1 \Concat \ldots \Concat \StringAlt_m)$
  & = 
  & $\StringAlt_1' \Concat \ldots \Concat \StringAlt_n'$
    where $\StringAlt_i' =
    \begin{cases*}
      \SDNFLens.\PutR \App \String_i \App \StringAlt_i & if $i \leq m$\\
      \SDNFLens.\CreateR \App \String_i & otherwise
    \end{cases*}$\\
  $\PutL{} \App (\StringAlt_1 \Concat \ldots \Concat \StringAlt_m) \App
  (\String_0 \Concat \ldots \Concat \String_n)$
  & = 
  & $\String_1' \Concat \ldots \Concat \String_m'$
    where $\String_i' =
    \begin{cases*}
      \SDNFLens.\PutL \App \StringAlt_i \App \String_i & if $i \leq n$\\
      \SDNFLens.\CreateL \App \StringAlt_i & otherwise
    \end{cases*}$\\
\end{tabular}


\section{Forgetful Symmetric Lenses}
\label{sec:appendixforget}

\begin{property}[Starting Forgetfulness RL]
  \label{prop:forget-rl}
  Let $\Lens$ be a forgetful symmetric lens.  If $(x_1',c_1') = \Lens.\PutL \App$
  $(y,\Snd \App (\Lens.\PutR \App (x,c_1)))$, and
  $(x_2',c_2') = \Lens.\PutL \App
  (y,\Snd \App (\Lens.\PutR \App (x,c_2)))$, then $x_1' = x_2'$.
\end{property}
\begin{proof}
  By \ForgetfulRL, $c_1' = c_2'$. We know $(y,c_1') = \Lens.\PutR \App
  (x_1',c_1')$ and $(y,c_1') = \Lens.\PutR \App (x_2',c_1')$ by \PutLR. By
  \PutRL, we know $(x_1' = \Lens.\PutL \App (y,c_1'))$ and $(x_2' = \Lens.\PutL
  \App (y,c_1')))$. Therefore, by transitivity of equality, $x_1' = x_2'$.
\end{proof}

\begin{property}[Starting Forgetfulness LR]
  \label{prop:forget-lr}
  Let $\Lens$ be a forgetful symmetric lens.  If $(y_1',c_1') = \Lens.\PutR \App$
  $(x,\Snd \App (\Lens.\PutL \App (y,c_1)))$, and
  $(x_2',c_2') = \Lens.\PutL \App
  (x,\Snd \App (\Lens.\PutR \App (y,c_2)))$,
  then $x_1' = x_2'$.
\end{property}
\begin{proof}
  Symmetric to Starting Forgetfulness RL.
\end{proof}

\begin{definition}[S]
  Let $\Lens$ be a forgetful lens.

  Consider the following four functions $S(\Lens)$, that we wish to satisfy the
  simple symmetric lens laws.

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
      $\CreateR{} \App s$
      & =
      & $\Fst \App (\Lens.\PutR{} \App (s,\Lens.init))$\\
      
      $\CreateL{} \App v$
      & =
      & $\Fst \App (\Lens.\PutL{} \App (v,\Lens.init))$\\
      
      $\PutR{} \App s \App v$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (v,\Lens.init)}$\\
      &
      & $\LetIn{(s',\_)}{\Lens.\PutR \App (s,c)}$\\
      &
      & $s'$\\
      
      $\PutL{} \App v \App s$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutR \App (s,\Lens.init)}$\\
      &
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (v,c)}$\\
      &
      & $y'$\\
    \end{tabular}
  \end{centering}
\end{definition}

\begin{mylemma}
  If $\Lens$ is a forgetful symmetric lens, then $S(\Lens)$ is a simple symmetric
  lens.
\end{mylemma}
\begin{proof}
  
  \CreatePutRL{}:
  
  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
      $S(\Lens).\PutLOf{(S(\Lens).\CreateROf{x})}{x}$
      & =
      & $S(\Lens).\PutLOf{(\Fst \App (\Lens.\PutR{(x,\Lens.init)}))}{x}$
      & By unfolding definitions
      \\
      
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutR \App (x,\Lens.init)}$\\
      &
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (\Fst \App (\Lens.\PutR{(x,\Lens.init)}),c)}$\\
      &
      & $y'$
      & By unfolding definitions\\
      
      & =
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (\Lens.\PutR \App (x,\Lens.init))}$\\
      &
      & $y'$
      & By tuple harmony \\
      
      & =
      & $x$
      & By \PutRL \\
    \end{tabular}
  \end{centering}

  \CreatePutLR{}:  Symmetric to \CreatePutRL{}

  \PutRL{}:

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
      $S(\Lens).\PutLOf{(S(\Lens).\PutROf{x}{y})}{x}$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (y,\Lens.init)}$\\
      & & $\LetIn{(y',c')}{\Lens.\PutR \App (x,c)}$\\
      & & $S(\Lens).\PutLOf{y'}{x}$
      & By unfolding definitions
      \\
      
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (y,\Lens.init)}$\\
      & & $\LetIn{(y',c')}{\Lens.\PutR \App (x,c)}$\\
      & & $\LetIn{(\_,c'')}{\Lens.\PutR \App (x,\Lens.init)}$\\
      & & $\LetIn{(x',c''')}{\Lens.\PutL \App (y',c'')}$\\
      & & $x'$
      & By unfolding definitions
    \end{tabular}
  \end{centering}

  At this point, we know from \PutRL that $(x,c') = \Lens.\PutL \App (y',c')$.
  By Property~\ref{prop:forget-rl}, this means that $x' = x$, as desired.

  \PutLR{}:  Symmetric to \PutRL{}
\end{proof}

\begin{definition}
  Fix a symmetric lens $\Lens$ beteween $X$ and $Y$. Consider the
  function, $\SingleApp_{\Lens} \OfType (X + Y) \times \Lens.C
  \rightarrow ((X + Y) \times \Lens.C)$, defined as:

  \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
    $\SingleApp_{\Lens}(\InLOf{x},c)$
    & =
    & $\LetIn{(y,c')}{\Lens.\PutRSymOf{(x,c)}}$\\
    &
    & $(\InROf{y},c')$\\
    
    $\SingleApp_{\Lens}(\InROf{y},c)$
    & =
    & $\LetIn{(x,c')}{\Lens.\PutLSymOf{(y,c)}}$\\
    &
    & $(\InLOf{x},\SomeOf{(x,y)})$
  \end{tabular}
\end{definition}

\begin{definition}
  Fix a simple symmetric lens $\Lens$ beteween $X$ and $Y$. Consider the
  function, $\SingleApp_{\Lens} \OfType ((X + Y) \times \OptionOf{(X \times Y)})
  \rightarrow ((X + Y) \times \OptionOf{(X \times Y)})$, defined as:

  \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
    $\SingleApp_{\Lens}(\InLOf{x},\None)$
    & =
    & $\LetIn{y}{\Lens.\CreateROf{x}}$\\
    &
    & $(\InROf{y},\SomeOf{(x,y)})$\\
    
    $\SingleApp_{\Lens}(\InROf{y},\None)$
    & =
    & $\LetIn{x}{\Lens.\CreateLOf{y}}$\\
    &
    & $(\InLOf{x},\SomeOf{(x,y)})$\\
    
    $\SingleApp_{\Lens}(\InLOf{x'},\SomeOf{(x,y)})$
    & =
    & $\LetIn{y'}{\Lens.\PutROf{x'}{y}}$\\
    &
    & $(\InROf{y'},\SomeOf{(x',y')})$\\
    
    $\SingleApp_{\Lens}(\InROf{y'},\SomeOf{(x,y)})$
    & =
    & $\LetIn{x'}{\Lens.\PutLOf{y'}{x}}$\\
    &
    & $(\InROf{x'},\SomeOf{(x',y')})$\\
  \end{tabular}
\end{definition}

\begin{definition}
  Fix a symmetric lens \Lens over $X$ and $Y$. We define the relation $R_\Lens$
  over $\Lens.C$ and $\OptionOf{(X \times Y)}$ as the largest relation such
  that:
  \begin{enumerate}
  \item $R_\Lens(c,None) \BooleanImplies c = \Lens.init$
  \item $R_\Lens(c,Some (x,y)) \BooleanImplies
    \Lens.\PutRSymOf{(x,c)} = (y,c) \BooleanAnd
    \Lens.\PutLSymOf{(y,c)} = (x,c)$
  \end{enumerate}
\end{definition}

\begin{mylemma}
  \label{lem:s-equiv}
  Let $\Lens$ be a symmetric lens.  Let $c \in \Lens.C$ be a complement, and
  $xyo \in \OptionOf{(X \times Y)}$.  If $R_{\Lens}(c,xyo)$, then
  $apply(\Lens,c,es) = apply(S(\Lens),xyo,es)$.
\end{mylemma}
\begin{proof}
  By induction on the derivation the application of $apply(S(\Lens),xyo,es)$
  \begin{case}[empty list]
    So by the case, $apply(S(\Lens),xyo,[]) = []$. Furthermore,
    $apply(\Lens,c,[]) = []$, as desired.
  \end{case}
  \begin{case}[first edit is a create right]
    So by the case, $apply(S(l),\None,\InLOf{x}::es) = \InROf{y}::es'$, where
    $S(\Lens).\CreateROf{x} = y$ and $apply(S(\Lens),\SomeOf{(x,y)},es) = es'$.

    As $R_{\Lens}(None,c)$, $c = \Lens.init$. So, performing $apply$ on
    $\Lens.init$, we get $apply(\Lens,\Lens.init,(\InLOf{x})::es) =
    (\InROf{y'})::es''$ where $\Lens.putr(x,c) = (y',c')$ and $apply(\Lens,c',es)
    = es'$.

    So, by definition, $S(\Lens).\CreateROf{x} = \Fst \App (\Lens.\PutRSymOf{(x,\Lens.init)})$, so $y = y'$.

    Furthermore, by \PutRL, $\Lens.\PutLSymOf{(y,c')} = (x,c')$, and by another
    application of \PutLR, $\Lens.\PutRSymOf{(x,c')} = (y,c')$.  This means
    that $R_{\Lens}(c',Some (x,y))$.

    So, by induction assumption, $apply(\Lens,c',es) = apply(S(\Lens),xyo,es)$, so
    $es' = es''$.  This means, $apply(S(l),\None,\InLOf{x}::es) =
    \InROf{y}::es'$ and $apply(\Lens,\Lens.init,(\InLOf{x})::es) =
    (\InROf{y})::es'$, so they are equal, as desired.
  \end{case}
  \begin{case}[first edit is a create left]
    Symmetric to previous case
  \end{case}
  \begin{case}[first edit is a put right]
    So by the case, $apply(S(\Lens),\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$, where
    $S(\Lens).\PutROf{x}{y} = y'$ and $apply(S(\Lens),\SomeOf{(x',y')},es) = es'$.

    Performing $apply$ on $c$, we get $apply(\Lens,c,(\InLOf{x'})::es) =
    (\InROf{y'})::es''$ where $\Lens.\PutRSymOf{(x',c)} = (y',c')$ and
    $apply(\Lens,c',es) = es''$.

    So, by definition, $S(\Lens).\PutROf{x}{y} = \Fst \App (\Lens.\PutRSymOf{(x,c'')})$, where $c'' = \Snd \App (\Lens.\PutLSymOf{(y,\Lens.init)})$.

    By assumption, $R_{\Lens}(c,\SomeOf{(x,y)})$, so $\Lens.\PutLSymOf{(y,c)}
    = (x,c)$.  So, by Property~\ref{prop:forget-lr}, we know $y' = y''$.

    Furthermore, by \PutRL, $\Lens.\PutLSymOf{(y',c')} = (x',c')$, and by another
    application of \PutLR, $\Lens.\PutRSymOf{(x',c')} = (y',c')$.  This means
    that $R_{\Lens}(c',Some (x',y'))$.

    So, by induction assumption, $apply(\Lens,c',es) = apply(S(\Lens),xyo,es)$, so
    $es' = es''$.  This means, $apply(S(l),\SomeOf{(x,y)},\InLOf{x'}::es) =
    \InROf{y'}::es'$ and $apply(\Lens,c,(\InLOf{x'})::es) =
    (\InROf{y'})::es'$, so they are equal, as desired.
  \end{case}
  \begin{case}[first edit is a put left]
    Symmetric to previous case
  \end{case}
\end{proof}

\begin{definition}[F]
  Let $\Lens$ be a simple symmetric lens between $X$ and $Y$.

  Consider the following set $C$, distinguished element of that set, $init$, and
  pair of functions $\PutRSym$ and $\PutLSym$, that we wish to satisfy the
  symmetric lens laws, and that we also wish to be forgetful.

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
      $C$
      & =
      & $\OptionOf{(X \times Y)}$\\
      
      $init$
      & =
      & $\None$\\
      
      $\PutRSymOf{(x,c)}$
      & =
      & $(y,\SomeOf{(x,y)})$ where $y = \begin{cases*}
        \Lens.\CreateROf{x} & if $c = \None$\\
        \Lens.\PutROf{x}{y'} & if $c = \SomeOf{(x',y')}$\\
        \end{cases*}$\\
      
      $\PutLSymOf{(y,c)}$
      & =
      & $(x,\SomeOf{(x,y)})$ where $x = \begin{cases*}
        \Lens.\CreateLOf{y} & if $c = \None$\\
        \Lens.\PutLOf{y}{x'} & if $c = \Some{(x',y')}$\\
        \end{cases*}$\\
    \end{tabular}
  \end{centering}
\end{definition}

\begin{mylemma}
  \label{lem:f-sym}
  If $\Lens$ is a simple symmetric lens, then $F(\Lens)$ is a symmetric lens.
\end{mylemma}
\begin{proof}
  \PutRL: There are two cases, $c = \None$, and $c = \SomeOf{(x,y)}$.

  \begin{case}[c = \None]
    Let $(y',c') = F(\Lens).\PutRSymOf{(x',\None)}$. This means that $y' =
    \Lens.\CreateROf{x'}$, and $c' = \SomeOf{(x',y')}$.
    
    Now, consider $(x'',c'') = F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$. By
    unfolding definitions, $x'' = \Lens.\PutLOf{y'}{x'}$. By \CreatePutRL, $x''
    = x'$, meaning $c'' = \SomeOf{(x',y')}$. This means $(x',c') =
    F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$, as desired.
  \end{case}

  \begin{case}[c = \SomeOf{(x,y)}]
    Let $(y',c') = F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})}$. This means that $y' =
    \Lens.\PutROf{x'}{y}$, and $c' = \SomeOf{(x',y')}$.
    
    Now, consider $(x'',c'') = F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$. By
    unfolding definitions, $x'' = \Lens.\PutLOf{y'}{x'}$. By \PutRL, $x''
    = x'$, meaning $c'' = \SomeOf{(x',y')}$. This means $(x',c') =
    F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$, as desired.
  \end{case}

  The second requirement, \PutLR, is symmetric.
\end{proof}


\begin{mylemma}
  If $\Lens$ is a simple symmetric lens, then $F(\Lens)$ is a forgetful symmetric lens.
\end{mylemma}
\begin{proof}
  By Lemma~\ref{lem:f-sym}, we know $F(\Lens)$ is symmetric, so we merely need
  to show it is forgetful.  We will tackle merely \ForgetfulRL, as the proof for
  \ForgetfulLR is symmetric.

  Let $c_1$ and $c_2$ be two arbitrary complements, and $x$ and $y$ two
  arbitrary values of $X$ and $Y$, respectively.
  
  We know that $c_1' = \Snd \App (F(\Lens).\PutRSymOf{(x,c_1)})$ and $c_2' =
  \Snd \App (F(\Lens).\PutRSymOf{(x,c_2)})$.  Now, by inversion on
  $F(\Lens).\PutRSym$, we know that both $c_1' = Some(x,y_1')$ and $c_2' =
  Some(x,y_2')$ for some values of $y_1$ and $y_2$ (though we don't actually
  care about the values of $y_1$ and $y_2$).

  Now by unfolding definitions we know, $\Snd \App
  (F(\Lens).\PutLSymOf{(y,\SomeOf{(x,y_1')})}) =
  \SomeOf(\Lens.\PutLOf{x}{y},y) = c_1''$. Similarly, we know $\Snd \App
  (F(\Lens).\PutLSymOf{(y,\SomeOf{(x,y_2')})}) =
  \SomeOf(\Lens.\PutLOf{x}{y},y) = c_2''$, so $c_1'' = c_2''$, as intended.
\end{proof}

\begin{mylemma}
\label{lem:f-equiv}
  If $\Lens$ be a simple symmetric lens, then $apply(\Lens,xyo,es) =
  apply(F(\Lens),xyo,es)$.
\end{mylemma}
\begin{proof}
  By induction on the derivation of $apply$ on $\Lens$!

  \begin{case}[empty list]
    So by the case, $apply(S(\Lens),xyo,[]) = []$. Furthermore,
    $apply(\Lens,xyo,[]) = []$, as desired.
  \end{case}

  \begin{case}[first edit is a create right]
    So by the case, $apply(\Lens,\None,\InLOf{x}::es) = \InROf{y}::es'$, where
    $\Lens.\CreateROf{x} = y$ and $apply(\Lens,\SomeOf{(x,y)},es) = es'$.

    Performing $apply$ on
    $\None$, we get $apply(F(\Lens),\None,(\InLOf{x})::es) =
    (\InROf{y'})::es''$ where $F(\Lens).putr(x,\None) = (y',c)$ and $apply(\Lens,c,es)
    = es'$.

    Unfolding definitions, $F(\Lens).putr(x,\None) = \Lens.\CreateROf{x} =
    (y,\SomeOf{(x,y)})$, so $c = \SomeOf{(x,y)}$ and $y = y'$

    So, by induction assumption, $apply(\Lens,\SomeOf{(x,y)},es) = apply(F(\Lens),\SomeOf{(x,y)},es)$, so
    $es' = es''$.  This means, $apply(\Lens,\None,\InLOf{x}::es) =
    \InROf{y}::es'$ and $apply(F(\Lens),\None,(\InLOf{x})::es) =
    (\InROf{y})::es'$, so they are equal, as desired.
  \end{case}

  \begin{case}[first edit is a create left]
    Symmetric to previous case
  \end{case}

  \begin{case}[first edit is a put right]
    So by the case, $apply(\Lens,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$, where
    $\Lens.\PutROf{x}{y} = y'$ and $apply(\Lens,\SomeOf{(x',y')},es) = es'$.

    Performing $apply$ on $F(\Lens)$, we get
    $apply(F(\Lens),\SomeOf{(x,y)},(\InLOf{x'})::es) = (\InROf{y'})::es''$ where
    $F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})} = (y'',\SomeOf{(x',y'')})$ and
    $apply(\Lens,c',es) = es''$.
    
    So, by definition, $\Fst \App (F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})})
    = \Lens.PutROf{x'}{y'}$, so also by definition, $c' = \SomeOf{(x',y')}$.

    So, by induction assumption, $apply(\Lens,\SomeOf{(x',y')},es) =
    apply(F(\Lens),\SomeOf{(x',y')},es)$, so $es' = es''$. This means,
    $apply(\Lens,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$ and
    $apply(F(\Lens),\SomeOf{(x,y)},(\InLOf{x'})::es) = (\InROf{y'})::es'$, so
    they are equal, as desired.
  \end{case}

  \begin{case}[first edit is a put left]
    Symmetric to previous case
  \end{case}
\end{proof}

\begin{theorem}
  Let $\Lens$ be a symmetric lens. The lens $\Lens$ is equivalent to a forgetful
  lens if, and only if, there exists a simple symmetric lens $\Lens'$ where
  $apply(\Lens,\Lens.init,es) = apply(\Lens',\None,es)$, for all put sequences
  $es$.
\end{theorem}

\begin{proof}
  \begin{case}[$\Rightarrow$]
    Let $\Lens$ be equivalent to a forgetful lens $\Lens'$.  Consider the
    simple symmetric lens, $S(\Lens')$.  By Lemma~\ref{lem:s-equiv},
    $apply(\Lens',\Lens'.init,es) = apply(S(\Lens'),\None,es)$.  As $\Lens$ is
    equivalent to $\Lens'$, $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\Lens'.init,es)$.  So, by transitivity,
    $apply(\Lens,\Lens.init,es) = apply(S(\Lens),\None,es)$.
  \end{case}

  \begin{case}[$\Leftarrow$]
    Let $\Lens'$ be a simple symmetric lens where $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\None,es)$, for all put sequences $es$.

    Consider $F(\Lens')$, a forgetful symmetric lens where $apply(\Lens',\None,es) =
    apply(F(\Lens'),\Lens'.init,es)$, for all put sequences $es$, as
    $\Lens'.init = \None$, by Lemma~\ref{lem:f-equiv}.  By transitivity, $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\Lens'.init,es)$, so $\Lens$ and $\Lens'$ are equivalent.
  \end{case}
    
\end{proof}

\section{SREs and Information Theory}
\begin{theorem}
  \label{thm:semantics-correctness}
  If $\Regex \SSREquiv \RegexAlt$ then $\ProbabilityOf{\Regex}{\String} =
  \ProbabilityOf{\RegexAlt}{\String}$, for all strings $\String \in \LanguageOf{\Regex}$.
\end{theorem}
The following lemma is
\begin{proof}
\begin{enumerate}

\item
($S \; |_1 \; \varnothing \equiv^S S$)

For all $s \in \mathcal{L}(S \; | \; \varnothing)$, then $P_{S \; |_1 \; \varnothing} = 1 * P_S(s) = P_S(s)$.
\item
($S \cdot \varnothing \equiv^S \varnothing$)

For all $s \in \mathcal{L}(S \cdot \varnothing)$, the $P_{S \cdot \varnothing}(s) = \sum_{s_1 \cdot s_2}P_S(s_1) * P_{\varnothing}(s_2)$, but this sum is empty, hence $P_{S \cdot \varnothing}(s) = 0 = P_{\varnothing}(s)$.
\item
($\varnothing \cdot S \equiv^S \varnothing$)

Similar to the previous case.
\item
($(S \cdot S') \cdot S'' \equiv^S S \cdot (S' \cdot S'')$). Let $s \in \mathcal{L}(S \cdot S' \cdot S'')$

Then
\begin{align*}
P_{(S \cdot S') \cdot S''}(s) &= \sum_{s=s_4 \cdot s_3}P_{S \cdot S'}(s_4) * P_{S''}(s_3)\\
&= \sum_{s=s_4 \cdot s_3}\left(\sum_{s_4=s_1 \cdot s_2} P_{S}(s_1) * P_{S'}(s_2)\right)* P_{S''}(s_3)\\
&= \sum_{s=s_1\cdot s_2 \cdot s_3} P_{S}(s_1) * P_{S'}(s_2) * P_{S''}(s_3)\\
P_{S \cdot (S' \cdot S'')}(s) &= \sum_{s=s_1\cdot s_4} P_{S}(s) * \left(\sum_{s_4=s_2\cdot s_3}P_{S'}(s_2) * P_{S''}(s_3)\right)
\end{align*}
\item
($(S \; |_{p_1} \; S') \; |_{p_2} \; S'' \equiv^S S \; |_{p_1 * p_2} \; (S' \; |_{\frac{(1-p_1)*p_2}{1-p_1*p_2}} \; S'')$)

Let $s \in \mathcal{L}(S \; |\; S' \; | \; S'')$. Then
\begin{align*}
P_{(S \; |_{p_1} \; S') \; |_{p_2} \; S''}(s) &= p_2 * P_{S \; |_{p_1} \; S'}(s) + (1-p_2)P_{S''}(s)\\
&= (p_2 * (p_1 * P_S(s) + (1-p_1) * P_{S'}(s))) + (1-p_2)P_{S''}(s)\\
&= (p_2 * (p_1 * P_S(s) + P_{S'}(s)-p_1* P_{S'}(s))) + (1-p_2)P_{S''}(s)\\
&= p_2*p_1 * P_S(s) + p_2*P_{S'}(s)-p_2*p_1* P_{S'}(s) + (1-p_2)P_{S''}(s)\\
&= p_2*p_1 * P_S(s) + (1-p_1) * p_2 * P_{S'}(s)+ (1-p_2)P_{S''}(s)\\
S \; |_{p_1 * p_2} \; (S' \; |_{\frac{(1-p_1)*p_2}{1-p_1*p_2}} \; S'') &= (p_1p_2)  P_S(s) + (1-p_1p_2)  \left(\frac{(1-p_1)p_2}{1-p_1p_2}  P_{S'}(s) + \left(1-\frac{(1-p_1)p_2}{1-p_1p_2}\right)P_{S''}(s)\right)
\end{align*}
\item
($S \; |_p \; T \equiv^S T \; |_{1-p} \; S$)

For all $s \in \mathcal{L}(S \; | \; T)$, we have
$$P_{S \; |_p \; T}(s) = p*P_S(s) + (1-p)*P_T(s) = (1-p) * P_T(s) + (1-(1-p))*P_s(s) = P_{T \; |_{1-p} \; S}(s)$$
\item
($S \cdot (S' \; |_p \; S'' ) \equiv^S (S \cdot S') \; |_p \; (S \cdot S'')$)

For all $s \in \mathcal{L}(S \cdot (S' \sep S''))$ we have
\begin{align*}
P_{S \cdot (S' \; |_p \; S'' )} &= \sum_{s_1 \cdot s_2 = s}P_S(s_1) * P_{S' \; |_p \; S''}(s)\\
&= \sum_{s_1 \cdot s_2 = s}P_S(s_1) * (p * P_{S'}(s_2) + (1-p) * P_{S''}(s_2))\\
&= \sum_{s_1 \cdot s_2 = s}p * P_S(s_1) * P_{S'}(s_2) + \sum_{s_1 \cdot s_2 = s}(1-p) * P_S(s_1) * P_{S''}(s_2)\\
P_{(S \cdot S') \; |_p \; (S \cdot S'')}(s) &= p*P_{S \cdot S'}(s) + (1-p)*P_{S \cdot S''}(s)
\end{align*}
\item
$((S' \; |_p \; S'') \cdot S \equiv^S (S' \cdot S) \; |_p \; (S'' \cdot S))$

For all $s \in \mathcal{L}((S' \; | \; S'') \cdot S)$,  we have
\begin{align*}
P_{(S' \; |_p \; S'') \cdot S}(s) &= \sum_{s_1 \cdot s_2 = s}P_{S' \; |_p \; S''}(s_1) * P_S(s_2)\\
&= \sum_{s_1 \cdot s_2 = s}(p * P_{S'}(s_1) + (1-p) * P_{S''}(s_1))* P_S(s_2)\\
&= \sum_{s_1 \cdot s_2=s}p*P_{S'}(s_1) * P_S(s_2) + \sum_{s_1 \cdot s_2 = s}(1-p) * P_{S''}(s_1) * P_S(s_2)\\
P_{(S' \cdot S) \; |_p \; (S'' \cdot S)}&= p * P_{S' \cdot S}(s) + (1-p) * P_{S'' \cdot S}(s)
\end{align*}
\item
($\varepsilon \cdot S \equiv^S S$)

For all $s \in \mathcal{L}(S)$, we have
$$P_{\epsilon \cdot S}(s) = \sum_{s_1 \cdot s_2 = s}P_{\epsilon}(s_1) * P_S(s_2) = P_{\epsilon}(\epsilon) * P_S(s_2) = P_S(s)$$
since $s_2 = s$ in the computation above.
\item
($S \cdot \epsilon \equiv^S S$)

Similar to the previous case.
\item
($S^{*p} \equiv^S \epsilon \; |_{(1-p)} \; (S^{*p} \cdot S)$)

Let $s \in \mathcal{L}(S^*)$, in which case we have
\begin{align*}
P_{\epsilon \; |_{1-p} \; (S^{*p} \cdot S)}(s) &= (1-p) * P_{\epsilon}(s) + p * P_{S^{*p} \cdot S}(s)\\
&= (1-p) * P_{\epsilon}(s) + p * \sum_{a \cdot b = s}\left(\sum_n \sum_{s_1 \ldots \cdot s_n=a} p^n (1-p) \prod_{i=1}^n P_S(s_i)\right) * P_S(b)\\
&= (1-p) * P_{\epsilon}(s) + \sum_{a \cdot b = s}\left(\sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^{n+1} (1-p) \prod_{i=1}^n P_S(s_i) * P_S(b)\right)\\
&= (1-p) * P_{\epsilon}(s) + \sum_n \sum_{s_1 \cdot \ldots \cdot s_{n+1}=s} p^{n+1} (1-p) \prod_{i=1}^{n+1} P_S(s_i)\\
&= (1-p) * P_{\epsilon}(s) + \left(\sum_n \sum_{s_1 \cdot \ldots \cdot s_n = s} p^n * (1-p) * \prod_{i=1}^n P_S(s_i)\right) - (1-p) * (\mathbbm{1}_{s = \varepsilon})
\end{align*}
Since
$$
P_{S^{*p}}(s) = \sum_n \sum_{s_1 \cdot \ldots \cdot s_n = s} p^n * (1-p) * \prod_{i=1}^n P_S(s_i)
$$
then if $s = \epsilon$, the terms $(1-p) * P_{\epsilon}(s)$ and $(1-p) * \mathbbm{1}_{s=\varepsilon}$ cancel each other out. Otherwise, if $s \neq \epsilon$, then $(1-p) * P_{\epsilon}(s) = 0 = (1-p) * (\mathbbm{1}_{s = \varepsilon})$ from which the result follows.
\item
($S^{*p} \equiv^S \epsilon \; |_{(1-p)} \; (S \cdot S^{*p})$)

Similar to the previous case.
\end{enumerate}
\end{proof}
\begin{mylemma}[Equivalence of \ConcatSequence{} and \Concat{}]
  If $\LanguageOf{\Regex}=\LanguageOf{\Sequence}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\SequenceAlt}$,
  then $\LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}=\LanguageOf{\ConcatSequenceOf{\Sequence}{\SequenceAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\Sequence=\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots
    \SeqSep\Atom_n\SeqSep\String_n}$, and
  let $\SequenceAlt=[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots
  \SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$. Then
  \begin{align*}  
    \LanguageOf{\ConcatSequenceOf{\Sequence}{\SequenceAlt}} & = 
                                                              \LanguageOf{\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots
                                                              \SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep{}
                                                              \AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m}} \\
                                                            & = 
                                                              \{\String_0\Concat\String_1'\Concat\ldots\Concat\String_n'\Concat\String_n
                                                              \Concat\StringAlt_0\Concat\StringAlt_1'\Concat\ldots
                                                              \Concat\StringAlt_m'\Concat\StringAlt_m\SuchThat{} \String_i'\in\LanguageOf{\Atom_i} \BooleanAnd{}
                                                              \StringAlt_i'\in\LanguageOf{\AtomAlt_i}\}\\
                                                            & = 
                                                              \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Sequence}
                                                              \BooleanAnd{} \StringAlt\in\LanguageOf{\SequenceAlt}\}\\
                                                            & =
                                                              \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Regex}
                                                              \BooleanAnd{} \StringAlt\in\LanguageOf{\RegexAlt}\}\\
                                                            & =
                                                              \LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}
\end{align*}
\end{proof}

\begin{mylemma}[Equivalence of \ConcatDNF{} and \Concat{}]
  \label{lem:cdnfeq}
  If $\LanguageOf{\Regex}=\LanguageOf{\DNFRegex}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\DNFRegexAlt}$,
  then $\LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}=
  \LanguageOf{\ConcatDNFOf{\DNFRegex}{\DNFRegexAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\DNFRegex=\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n}$, and
  let $\DNFRegexAlt=\DNFOf{\SequenceAlt_0\DNFSep\ldots\DNFSep\SequenceAlt_m}$
  \begin{align*}
    \LanguageOf{\ConcatDNFOf{\DNFRegex}{\DNFRegexAlt}} & = 
                                                         \LanguageOf{\DNFOf{\ConcatSequenceOf{\Sequence_i}{\SequenceAlt_j}
                                                         \text{ for $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}}} \\
                                                       & = 
                                                         \{\String\SuchThat \String\in\ConcatSequenceOf{\Sequence_i}{\SequenceAlt_j} \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                       & = 
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Sequence_i}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\SequenceAlt_j}\} \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                       & =
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\DNFRegex}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\DNFRegexAlt}\}\\
                                                       & =
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Regex}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\RegexAlt}\}\\
                                                       & =
                                                         \LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}
\end{align*}
\end{proof}

\begin{mylemma}[Equivalence of $\Atom$ and $\AtomToDNFOf{\Atom}$]
  \label{lem:atomtodnfeq}
  $\LanguageOf{\Atom} = \LanguageOf{\AtomToDNFOf{\Atom}}$
\end{mylemma}
\begin{proof}
\begin{align*}
  \LanguageOf{\AtomToDNFOf{\Atom}} &=
  \LanguageOf{\DNFOf{\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep \EmptyString}}}\\
  & =
  \SetOf{\String \SuchThat \String \in
    \LanguageOf{\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep \EmptyString}}} \\
  & =
  \SetOf{\EmptyString\Concat\String\Concat\EmptyString \SuchThat \String \in
    \LanguageOf{\Atom}} \\
   & = \SetOf{\String \SuchThat \String \in
    \LanguageOf{\Atom}} \\
    &= \LanguageOf{\Atom}
    \end{align*}
\end{proof}

\begin{mylemma}[Equivalence of \OrDNF{} and \Or{}]
  \label{lem:odnfeq}
  If $\LanguageOf{\Regex}=\LanguageOf{\DNFRegex}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\DNFRegexAlt}$,
  then $\LanguageOf{\RegexOr{\Regex}{\RegexAlt}}=
  \LanguageOf{\OrDNFOf{\DNFRegex}{\DNFRegexAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\DNFRegex=\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n}$, and
  let $\DNFRegexAlt=\DNFOf{\SequenceAlt_0\DNFSep\ldots\DNFSep\SequenceAlt_m}$
  
  \begin{align*}
    \mathcal{L}(DS \oplus DT)& = 
                                                     \LanguageOf{\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n\DNFSep
                                                     \SequenceAlt_1\DNFSep\ldots\DNFSep\SequenceAlt_m}}\\
                                                   & = 
                                                     \{\String\SuchThat{} \String\in\Sequence_i\vee\String\in\SequenceAlt_j \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                   & = 
                                                     \{\String{} \SuchThat{} \String\in\LanguageOf{\DNFRegex}
                                                     \BooleanOr{} \String\in\LanguageOf{\DNFRegexAlt}\}\\
                                                   & =
                                                     \{\String \SuchThat{} \String\in\LanguageOf{\Regex}
                                                     \BooleanOr{} \String\in\LanguageOf{\RegexAlt}\}\\
                                                   & =
                                                     \LanguageOf{\RegexOr{\Regex}{\RegexAlt}}
  \end{align*}
\end{proof}

\begin{theorem}\label{ConversionPreservesSemantics}
  For all regular expressions \Regex{},
  $\LanguageOf{\ToDNFRegexOf{\Regex}}=\LanguageOf{\Regex{}}$.
\end{theorem}
\begin{proof}
  By structural induction.

  Let $\Regex=\String$.
  $\LanguageOf{\ToDNFRegex(\String)}=\LanguageOf{\DNFOf{\SequenceOf{\String}}}=
  \{\String\}=\LanguageOf{\String}$

  Let $\Regex=\emptyset$.
  $\LanguageOf{\ToDNFRegex(\emptyset)}=\LanguageOf{\DNFOf{}} =
  \{\} = \LanguageOf{\emptyset}$.

  Let $\Regex=\StarOf{\Regex'}$.
  By induction assumption, $\LanguageOf{\ToDNFRegex(\Regex')}=
  \LanguageOf{\Regex'}$.
  \begin{align*}
    \LanguageOf{\ToDNFRegex(\StarOf{\DNFRegex'})} & =
                                                    \LanguageOf{\DNFOf{\SequenceOf{\StarOf{\ToDNFRegex(\Regex')}}}}\\
                                                  & =
                                                    \{\String\SuchThat\String\in
                                                    \LanguageOf{\SequenceOf{\StarOf{\ToDNFRegex(\Regex')}}}\}\\
                                                  & = 
                                                    \{\String\SuchThat{} \String\in\LanguageOf{\StarOf{\ToDNFRegex(\Regex')}}\}\\
                                                  & =
                                                    \{\String_1\Concat\ldots\Concat\String_n\SuchThat{}
                                                    n\in\Nats \BooleanAnd\String_i\in\LanguageOf{\ToDNFRegex(\Regex')}\}\\
                                                  & =
                                                    \{\String_1\Concat\ldots\Concat\String_n\SuchThat{}
                                                    n\in\Nats\BooleanAnd\String_i\in\LanguageOf{\Regex'}\}\\
                                                  & = \LanguageOf{\StarOf{\Regex'}}
  \end{align*}

  Let $\Regex=\RegexConcat{\Regex_1}{\Regex_2}$.
  By induction assumption,
  $\LanguageOf{\ToDNFRegex(\Regex_1)}=\LanguageOf{\Regex_1}$, and
  $\LanguageOf{\ToDNFRegex(\Regex_2)}=\LanguageOf{\Regex_2}$.
  $\ToDNFRegex(\RegexConcat{\Regex_1}{\Regex_2})=
  \ConcatDNFOf{\ToDNFRegex(\Regex_1)}{\ToDNFRegex(\Regex_2)}$.
  By Lemma~\ref{lem:cdnfeq},
  $\RegexConcat{\Regex_1}{\Regex_2}=
  \ConcatDNFOf{\ToDNFRegex(\Regex_1)}{\ToDNFRegex(\Regex_2)}$.


  Let $\Regex=\RegexOr{\Regex_1}{\Regex_2}$.
  By induction assumption,
  $\LanguageOf{\ToDNFRegex(\Regex_1)}=\LanguageOf{\Regex_1}$, and
  $\LanguageOf{\ToDNFRegex(\Regex_2)}=\LanguageOf{\Regex_2}$.

  $\Downarrow(S \; | \; T) = (\Downarrow S) \oplus (\Downarrow T)$. By Lemma~\ref{lem:odnfeq},
  $\mathcal{L}(S \; | \; T) = \mathcal{L}((\Downarrow S) \oplus (\Downarrow T))$.
  
\end{proof}
\begin{theorem*}
  $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$ and $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$
\end{theorem*}
\begin{proof}
By \cref{ConversionPreservesSemantics}, $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$, so we will prove the result $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$.
\begin{enumerate}
\item
$(S = s)$

By definition, $\Downarrow s = \langle ([s],1) \rangle$ and $P_{\langle ([s], 1) \rangle}(s') = 
\begin{cases}
1 & \text{if } s = s'\\
0 & \text{otherwise}
\end{cases}$ hence $P_{\langle ([s],1) \rangle}(s') = P_s(s')$.
\item
$(S = \varnothing)$

By definition, $\Downarrow \varnothing = \langle \rangle$ and $P_{\langle \rangle}(s) = 0 = P_{\varnothing}(s)$
\item
$(S = S^{*p})$

By definition, $\Downarrow (S^{*p}) = \langle [\epsilon \cdot (\Downarrow S)^{*p} \cdot \epsilon] \rangle $. By the induction hypothesis, $P_{(\Downarrow S)} = P_{S}$, hence
\begin{align*}
P_{[\epsilon \cdot (\Downarrow S)^{*p}] \cdot \epsilon}(s) &= P_{(\Downarrow S)^{*p}}(s)\\
&= \sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^n * (1-p) * \prod_{i=1}^n P_{(\Downarrow S)}(s_i)\\
&= \sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^n * (1-p) * \prod_{i=1}^n P_{S}(s_i)\\
&= P_{S^{*p}}(s)
\end{align*}
\item
$(S = S_1 \cdot S_2)$

By definition, $\Downarrow (S_1 \cdot S_2) = (\Downarrow S_1) \odot (\Downarrow S_2)$. By the induction hypothesis, $P_{S_1} = P_{(\Downarrow S_1)}$, and $P_{S_2} = P_{(\Downarrow S_2)}$. Assume that $\Downarrow S_1 = \langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_m, p_n)\rangle$ and $\Downarrow S_2 = \langle (TQ_1,q_1) \; | \; \ldots \; | \; (TQ_n, q_m) \rangle$. Then
\begin{align*}
P_{S_1}(s) &= \sum_{i=1}^n p_i P_{SQ_i}(s)\\
P_{S_1}(s) &= \sum_{j=1}^m q_i P_{TQ_j}(s)\\
\end{align*}
hence
\begin{align*}
P_{S_1 \cdot S_2}(s) &= \sum_{s_1 \cdot s_2 = s} P_{S_1}(s_1)* P_{S_2}(s_2)\\
&= \sum_{s_1 \cdot s_2 = s} \left(\sum_{i=1}^n p_i P_{SQ_i}(s_1)\right)* \left(\sum_{j=1}^m q_i P_{TQ_j}(s_2)\right)\\
&= \sum_{s_1 \cdot s_2 = s} \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j) * (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))\\
&= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))
\end{align*}
By definition,
$\ConcatDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}=$\\
      $\DNFLeft (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_1},\Probability_1*\ProbabilityAlt_1)\DNFSep \ldots
      \DNFSep
      (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_m},\Probability_1*\ProbabilityAlt_m)\DNFSep
      \ldots$\\
      $\DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_1},\Probability_n*\ProbabilityAlt_1)\DNFSep
      \ldots \DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_m},\Probability_n * \ProbabilityAlt_m) \DNFRight$
      
where
$$\ConcatSequenceOf{[\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n]}{[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]}=
  [\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$$
Hence
$$P_{\langle (SQ_1, p_1) \; | \; \ldots \; | \;(SQ_n,p_n)\rangle \odot \langle (TQ_1, q_1) \; | \; \ldots \; | \;(TQ_m,q_m)\rangle}(s) = \sum_{i=1}^n \sum_{j=1}^m(p_i * q_j) * P_{SQ_i \odot_{SQ} TQ_j}(s)$$
Since $P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]}(s) = \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = s} \prod_{i=1}^n P_{A_i}(s'i)$, then
\begin{align*}
P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n] \odot_{SQ} [t_0 \cdot B_1 \cdot \ldots \cdot B_m \cdot t_m]}(s) &= \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n \cdot t_0 \cdot t'_1 \cdot \ldots t'_m \cdot t_m =s } \prod_{i=1}^n P_{A_i}(s'_i) \prod_{j=1}^m P_{B_j}(t'_j)\\
&= \sum_{a \cdot b = s} \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = a} \sum_{t_0 \cdot t'_1 \cdot \ldots \cdot t'_m \cdot t_m = b} \prod_{i=1}^n P_{A_i}(s'_i) \prod_{j=1}^m P_{B_j}(t'_j)\\
& \sum_{a \cdot b = s} \left(\sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = a} \prod_{i=1}^n P_{A_i}(s'_i)\right) \left(\sum_{t_0 \cdot t'_1 \cdot \ldots \cdot t'_m \cdot t_m = b} \prod_{j=1}^m P_{B_j}(t'_j)\right)\\
&= \sum_{a \cdot b = s}P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]}(a) * P_{[t_0 \cdot B_1 \cdot \ldots \cdot B_m \cdot t_m]}(b)
\end{align*}
In other words, $P_{SQ \odot_{SQ} TQ}(s) = \sum_{a \cdot b = s}P_{SQ}(a) * P_{TQ}(b)$. Hence, 
\begin{align*}
P_{S_1 \cdot S_2}(s) &= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))\\
&= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} P_{SQ_i \odot_{SQ} TQ_j}(s)\\
&= P_{\langle (SQ_1, p_1) \; | \; \ldots \; | \;(SQ_n,p_n)\rangle \odot \langle (TQ_1, q_1) \; | \; \ldots \; | \;(TQ_m,q_m)\rangle}(s)\\
&= P_{(\Downarrow S_1) \odot (\Downarrow S_2)}(s)
\end{align*}
which is what we wanted to show.
\item
$(S = S_1 \; |_p \; S_2)$

By definition $\Downarrow (S_1 \; |_p \; S_2) = (\Downarrow S_1) \oplus_p (\Downarrow S_2)$. By the induction hypothesis $P_{S_1} = P_{\Downarrow S_1}$ and $P_{S_2} = P_{\Downarrow S_2}$. Assume that $\Downarrow S_1 = \langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_m, p_n)\rangle$ and $\Downarrow S_2 = \langle (TQ_1,q_1) \; | \; \ldots \; | \; (TQ_n, q_m) \rangle$. By definition, 

  $\OrDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}{\Probability} =$\\
  $\DNFOf{(\Sequence_1,\Probability_1*\Probability)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n*\Probability)\DNFSep(\SequenceAlt_1,\ProbabilityAlt_1*(1-\Probability))\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m*(1-\Probability))}$
  hence
  \begin{align*}
  P_{(\Downarrow S_1) \; |_p \; (\Downarrow S_2)}(s) &= P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle \oplus_p \langle (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s) \\
  &= P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n) \; | \; (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s)\\
  &= \sum_{i=1}^m (p * p_i) P_{SQ_i}(s) + \sum_{j=1}^m ((1-p) * q_j) P_{TQ_j}(s)\\
  &= p * \sum_{i=1}^m p_i P_{SQ_i}(s) + (1-p)* \sum_{j=1}^m q_j * P_{TQ_j}(s)\\
&= p * P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle}(s) + (1-p) * P_{\langle (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s)\\
&= p * P_{\Downarrow S_1}(s) + (1-p) * P_{\Downarrow S_2}(s) 
  \end{align*}
  
  Since $P_{S_1} = P_{\Downarrow S_1}$ and $P_{S_1} = P_{\Downarrow S_1}$, then 
  \begin{align*}
  P_{S_1}(s) &= \sum_{i=1}^n p_i * P_{SQ_i}(s)\\
  P_{S_2}(s) &= \sum_{j=1}^m q_m * P_{TQ_j}(s)
  \end{align*}
  hence
  \begin{align*}
  P_{S_1 \; |_p \; S_2}(s) &= p * (P_{S_1}(s)) + (1-p) * (P_{S_2}(s))\\
  &= p \left(\sum_{i=1}^n p_i * P_{SQ_i}(s)\right) + (1-p)\left(\sum_{j=1}^m q_m * P_{TQ_j}(s)\right)\\
  &= p * P_{\Downarrow S_1}(s) + (1-p) * P_{\Downarrow S_2}(s)\\
  &= P_{(\Downarrow S_1) \; |_p \; (\Downarrow S_2)}(s)
  \end{align*}
  which is what we wanted to show. This completes the proof.
\end{enumerate}
\end{proof}
\begin{theorem}
  \label{CorrectEntropy}
  If $\Regex$ is unambiguous and contains no empty subcomponents,
  $\EntropyOf{\Regex}$ is the entropy of $\mathcal{L}(\Regex)$.
\end{theorem}
\begin{proof}
Given a discrete set $X$ and a probability distribution $P$ on $X$, we define the entropy $H(X)$ of $X$ by
$$H(X) = -\sum_{x \in X}P(x)\log_2{P(x)}$$
We prove the theorem by induction on $S$.
\begin{enumerate}
\item
($S = s$)

Then $\mathbb{H}(s) = 0 = H(\mathcal{L}(s)) = H(\{s\})$
\item
$(S = S^{*p})$

Since $S^{*p}$ is unambiguous, then $S$ is also anambiguous, and for each $s \in \mathcal{L}(S^{*p})$, there exist unique $t_1, \ldots, t_n \in \mathcal{L}(S)$ such that $s = t^s_1 \cdot \ldots \cdot t^s_{n_s}$. By the induction hypothesis, $H(\mathcal{L}(S)) = \mathbb{H}(S)$, thus
\begin{align*}
H(\mathcal{L}(S^{*p})) &= - \sum_{s \in \mathcal{L}(S^{*p})} P_{S^{*p}}(s) \log_2 P_{S^{*p}}(s)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\log_2 \left(p^n * (1 - p) * \prod_{i=1}^n P_S(s_i)\right)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\left(n \log_2 p  + \log_2 (1 - p) + \log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\right)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\left(n \log_2 p  + \log_2 (1 - p) + \log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\right)\\
&= -(1-p) * \log_2 p \sum_n n * p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)
-(1-p) * \log_2 (1 - p) \sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) \\
&-(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-(1-p)\sum_n p^n H(\mathcal{L}(S^n))\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-(1-p)\sum_n p^n n H(\mathcal{L}(S))\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-\frac{p}{(1-p)} * H(\mathcal{L}(S))\\
&= \frac{p}{(1-p)}(H(\mathcal{L}(S)) - \log_2 p) -\log_2 (1 - p)\\
&= \frac{p}{(1-p)}(\mathbb{H}(S) - \log_2 p) -\log_2 (1 - p)
\end{align*}
\item
($S = S_1 \cdot S_2$)

Since $S$ is unambigous, then $S_1$ and $S_2$ are also unambiguous, and for each $s \in \mathcal{L}(S_1 \cdot S_2)$ there exists a unique $s_1 \in \mathcal{L}(S_1)$ and a unique $s_2 \in \mathcal{L}(S_2)$ such that $s = s_1 \cdot s_2$. By the induction hypothesis, $H(\mathcal{L}(S_1)) = \mathbb{H}(S_1)$ and $H(\mathcal{L}(S_2)) = \mathbb{H}(S_2)$, hence
\begin{align*}
H(\mathcal{L}(S_1 \cdot S_2))(s) &= -\sum_{s_1 \in S_1} \sum_{s_2 \in S_2}P_{S_1}(s_1)*P_{s_2}(s_2) \log_2(P_{S_1}(s_1)*P_{S_2}(s_2))\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1)\sum_{s_2 \in S_2}P_{s_2}(s_2) (\log_2(P_{S_1}(s_1) + \log_2 P_{S_2}(s_2)))\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1) \sum_{s_2 \in S_2}P_{S_2}(s_2)\log_2(P_{S_1}(s_1)) + \sum_{s_1 \in S_1} P_{S_1}(s_1)\sum_{s_2 \in S_2} P_{S_2}(s_2)\log_2 P_{S_2}(s_2)\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1) \log_2(P_{S_1}(s_1)) + \sum_{s_2 \in S_2} P_{S_2}(s_2)\log_2 P_{S_2}(s_2)\\
&= H(\mathcal{L}(S_1)) + H(\mathcal{L}(S_2))\\
&= \mathbb{H}(S_1) + \mathbb{H}(S_2)
\end{align*}
\item
($S = S_1 \; |_p \; S_2$)

Since $S$ is unambiguous, it must be that $S_1$ and $S_2$ are also unambiguous, and
every $s \in \mathcal{L}(S_1 \; |_p \; S_2)$ is either in $\mathcal{L}(S_1)$
or in $\mathcal{L}(S_2)$. By the induction hypothesis, $H(\mathcal{L}(S_1))
= \mathbb{H}(S_1)$ and $H(\mathcal{L}(S_2)) =
\mathbb{H}(S_2)$. Then
\begin{align*}
H(\mathcal{L}(S_1 \; |_p \; S_2)) &= -\sum_{s \in \mathcal{L}(S_1)}(p * P_{S_1}(s))\log_2 (p * P_{S_1}(s)) - \sum_{s \in \mathcal{L}(S_2)}((1-p) * P_{S_2}(s))\log_2 ((1-p) * P_{S_2}(s))\\
&=- p\sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s)(\log_2 p + \log_2 P_{S_1}(s)) - (1-p)\sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s)(\log_2 (1-p) + \log_2 P_{S_2}(s))\\
&= p * (\log_2 p +  H(\mathcal{L}(S_1))) + (1-p) * ( \log_2 (1-p) + H(\mathcal{L}(S_2)))\\
&= p * (\log_2 p +  \mathbb{H}(S_1)) + (1-p) * ( \log_2 (1-p) + \mathbb{H}(S_2))\\
\end{align*}
\end{enumerate}
\end{proof}
\begin{theorem*}
  Let $\Lens$ be an asymmetric lens. $\Lens$ is also a simple symmetric lens,
  where
  \begin{center}
    \begin{tabular}{rcl}
      $\Lens.\CreateROf{x}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\CreateLOf{y}$ & $=$ & $\Lens.create \App y$\\
      $\Lens.\PutROf{x}{y}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\PutLOf{y}{x}$ & $=$ & $\Lens.put \App y \App x$
    \end{tabular}
  \end{center}
\end{theorem*}
\begin{proof}
Let $\ell$ be an asymmetric lens. Then $\ell$ satisfies the following laws:
\begin{align*}
\ell.\get \; (\ell.\pput \; v \; s) &= v \tag{PUTGET}\\
\ell.\pput \; (\ell.\get \; s) \; s&= s \tag{GETPUT}\\
\ell.\get \; (\ell.\pput \; v \; s) &= v \tag{CREATGET}
\end{align*}
Define the simple symmetric lens $\lceil \ell \rceil$ by 
\begin{align*}
\lceil \ell \rceil.\CreateROf{s} &= \ell.\get \; s\\
\lceil \ell \rceil.\CreateLOf{v} &= \ell.\create \; v\\
\lceil \ell \rceil.\PutROf{s}{v} &= \ell.\get \; s\\
\lceil \ell \rceil.\PutLOf{v}{s} &= \ell.\pput \; v \; s\\
\end{align*}
We now show that $\lceil \ell \rceil$ satisfies the simple symmetric lens laws:
\begin{align*}
\lceil \ell \rceil.\PutLOf{(\lceil \ell \rceil.\CreateROf{s})}{s} &= \ell.\pput \; (\ell.\get \; s) \; s = s\\
\lceil \ell \rceil.\PutROf{(\lceil \ell \rceil.\CreateLOf{v})}{v} &= \ell.\get \; (\ell.\create \; v) = v\\
\lceil \ell \rceil.\PutLOf{(\lceil \ell \rceil.\PutROf{s}{v})}{s} &= \ell.\pput \; (\ell.\get) \; s = s\\
\lceil \ell \rceil.\PutROf{(\lceil \ell \rceil.\PutLOf{v}{s})}{v} &= \ell.\get \; (\ell.\pput \; v \; s) = v
\end{align*}
\end{proof}

\begin{theorem*}
  Let $\Lens \OfType \Regex \Leftrightarrow \RegexAlt$, where $\Lens$ does not
  include composition, $\Regex$ and $\RegexAlt$ and unambiguous, and neither
  $\Regex$ nor $\RegexAlt$ contain any empty subcomponents.
  \begin{enumerate}
  \item $\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ is an upper bound for the expected
    information content of $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt}}$,
    given $\SetOf{s \SuchThat s \in \LanguageOf{\Regex} \BooleanAnd
      \Lens.\PutROf{s}{t} = t}$
  \item $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ is an upper bound for the expected
    information content of $\SetOf{s \SuchThat s \in \LanguageOf{\Regex}}$,
    given $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt} \BooleanAnd
      \Lens.\PutLOf{t}{s} = s}$
  \end{enumerate}
\end{theorem*}
\begin{proof}
Let $H(T \; | \; \ell, S)$ be the expected information content of $\{t \; | \; t \in \mathcal{L}(T)\}$ given $\{s \; | \; s \in \mathcal{L}(S) \wedge \ell.\PutROf{s}{t} = t\}$. Given $s \in S$, let $V^{\rightarrow}_{\ell}(s) = \{t \in \mathcal{L}(T) \; | \; \ell.\PutROf{s}{t} = t\}$. We want to show that
$$H(T \; | \; \ell, S) = \sum_{s \in \mathcal{L}(S)}P_{\mathcal{L}(S)}(s)H(V^{\rightarrow}_{\ell}(s)) \leq \mathbb{H}^{\rightarrow}(T \; | \; \ell, S)$$
(The proofs for $\mathbb{H}^{\leftarrow}(S \; | \; \ell, T)$ will follow the same pattern). We proceed by induction over $\ell$. 
\begin{enumerate}
\item
($\ell = \IdentityLensOf{S}$)

Observe that $V^{\rightarrow}_{\IdentityLensOf{S}}(s) = \{t \in \mathcal{L}(S) \; | \; \IdentityLensOf{S}.\ell.\PutROf{s}{t} = t\} = \{t \in \mathcal{L}(S) \; | \; t = s\} = \{s\}$.

Consequently, $H(V^{\rightarrow}_{\IdentityLensOf{S}}(s)) = H(\{s\}) = 0$, from which it follows that 
$$\sum_{s \in \mathcal{L}(S)} P_{\mathcal{L}(S)}(s) * H(V^{\rightarrow}_{\IdentityLensOf{S}}(s)) = 0 = \mathbb{H}^{\rightarrow}(S \; | \; \IdentityLensOf{S}, T)$$
\item
($\ell = \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}$)

Observe that 
$$V^{\rightarrow}_{\DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}}(s) = \{t \in \mathcal{L}(T) \; | \; \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}.\PutROf{s}{t} = t\} = \{t \in \mathcal{L}(T) \; | \; t = t\} = \mathcal{L}(T)$$
Consequently
\begin{align*}
\sum_{s \in \mathcal{L}(S)}P_{S}(s)H(V^{\rightarrow}_{\DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}}(s)) &= \sum_{s \in \mathcal{L}(S)}P_{S}(s)H(\mathcal{L}(T))\\
&= H(\mathcal{L}(T))\\
&= \mathbb{H}(T)\\
&= \mathbb{H}^{\rightarrow}(T \; | \; \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}, S)
\end{align*}
\item
($\ell = \IterateLensOf{\Lens} : S^{*p} \Leftrightarrow T^{*q}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{\IterateLensOf{\Lens}}(s_1 \cdot \ldots \cdot s_n) &= \{t_1 \cdot \ldots \cdot t_m \; | \; \IterateLensOf{\Lens}.\PutROf{(s_1 \cdot \ldots \cdot s_n) }{(t_1 \cdot \ldots \cdot t_m)} = t_1 \cdot \ldots \cdot t_m\}\\
&= \{t_1 \cdot \ldots \cdot t_n \; | \; \ell.\PutROf{s_i}{t_i} = t_i \text{ for }1 \leq i \leq n\}\\
&= V^{\rightarrow}_{\ell}(s_1) \cdot \ldots \cdot V^{\rightarrow}_{\ell}(s_n)
\end{align*}
Consequently
\begin{align*}
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n)\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) H(V^{\rightarrow}_{\ell}(s_1) \cdot \ldots \cdot V^{\rightarrow}_{\ell}(s_n))\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n)\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) \left(\sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) \right)\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \sum_{s_n} P_S(s_n) \left(\sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) \right)
\end{align*}
We focus on the term $\sum_{s_n} P_S(s_n) \sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j))$:
\begin{align*}
\sum_{s_n} P_S(s_n) \sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) &= \sum_{s_n} P_S(s_n)H(V^{\rightarrow}_{\ell}(s_n)) + P_S(s_n) \sum_{j=1}^{n-1} H(V^{\rightarrow}_{\ell}(s_j))\\
&= H(T \; | \; \ell, S) + \sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))
\end{align*}
Consequently,
\begin{align*}
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left( H(S \; | \; \ell, T) + \sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1})\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) H(S \; | \; \ell, T)\\
&+(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)\\
&= H(S \; | \; \ell, T) * (1-p)\sum_n p^n \\
&+(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)
\end{align*}
Unrolling the term 
$$\sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)$$ 
$(n-1)$ more times gives
\begin{align*}
H(T^{*q} \; | \; V^{\rightarrow}_{\IterateLensOf{\Lens}}(s), S^{*p}) &=
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))\\
&= H(T \; | \; \ell, S) * (1-p)\sum_n n * p^n \\
&= \frac{p}{1-p} * H(T \; | \; \ell, S)\\
&\leq \frac{p}{1-p} * \mathbb{H}^{\rightarrow}(T \; | \; \ell, S)\\
&= \mathbb{H}(T^{*q} \; | \; V^{\rightarrow}_{\IterateLensOf{\Lens}}(s), S^{*p})
\end{align*}

which is what we wanted to show.
\item
($S = \ConcatLensOf{\Lens_1}{\Lens_2}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{ \ConcatLensOf{\Lens_1}{\Lens_2}}(s_1 \cdot s_2) &= \{t_1 \cdot t_2 \in \mathcal{L}(T_1 \cdot T_2) \; | \;  \ConcatLensOf{\Lens_1}{\Lens_2}.\PutROf{(s_1 \cdot s_2)}{(t_1 \cdot t_2)} = t_1 \cdot t_2\}\\
&= \{t_1 \cdot t_2 \in \mathcal{L}(T_1 \cdot T_2) \; | \;  \ell_1.\PutROf{s_1}{t_1 } = t_1  \text{ and } \ell_2.\PutROf{t_2}{t_2} = t_2\}\\
&= V^{\rightarrow}_{\ell_1}(s_1) \cdot V^{\rightarrow}_{\ell_2}(s_2)
\end{align*}
Consequently,
\begin{align*}
&H(T_1 \cdot T_2 \; | \; \ConcatLensOf{\Lens_1}{\Lens_2}, S_1 \cdot S_2)\\
& =\sum_{s \in \mathcal{L}(S_1 \cdot S_2)}P_{S_1 \cdot S_2}(s) H(V^{\rightarrow}_{\ConcatLensOf{\Lens_1}{\Lens_2}}(s))\\
&= \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)(H(V^{\rightarrow}_{\ell_1}(s_1)) + H(V^{\rightarrow}_{\ell_2}(s_2)))\\
&= \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)H(V^{\rightarrow}_{\ell_1}(s_1)) + \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)H(V^{\rightarrow}_{\ell_2}(s_2))\\
&= H(T_1 \; | \; \ell_1, S_1) + H(T_2 \; | \; \ell_2, S_2)\\
&\leq \mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S_1) + \mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S_2)\\
&= \mathbb{H}(T_1 \cdot T_2 \; | \; \ConcatLensOf{\Lens_1}{\Lens_2}, S_1 \cdot S_2)
\end{align*}
\item
($S = \SwapLensOf{\Lens_1}{\Lens_2}$)

Similar to the previous case.
\item
($S = \OrLensOf{\Lens_1}{\Lens_2}$)

Observe that 
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \OrLensOf{\Lens_1}{\Lens_2}.\ell.\PutROf{s}{t} = t\}
$$
If $s \in \mathcal{L}(S_1)$, then
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_1.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_1}(s)
$$
while if $s \in \mathcal{L}(S_2)$, then
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_2.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_2}(s)
$$
Consequently,
\begin{align*}
H(T_1 \; |_q \; T_2 \; | \; \OrLensOf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) &= \sum_{s \in \mathcal{L}(S_1 \; |_p \; S_2)}P_{S_1 \; |_p \; S_2}(s) H(V^{\rightarrow}_{\OrLensOf{\Lens_1}{\Lens_2}}(s))\\
&= p * \sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s) H(V^{\rightarrow}_{\ell_1}(s)) + (1-p) * \sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s) H(V^{\rightarrow}_{\ell_2}(s))\\
&= p * (H(T_1 \; | \; \ell_1,S_1)) + (1-p) * (H(T_2 \; | \; \ell_2,S_2))\\
&\leq p * (\mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1,S_1)) + (1-p) * (\mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2,S_2))\\
&= \mathbb{H}(T_1 \; |_q \; T_2 \; | \; \OrLensOf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) 
\end{align*}
\item
($S = \MergeROf{\Lens_1}{\Lens_2}$)

Observe that 
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \MergeROf{\Lens_1}{\Lens_2}.\PutROf{s}{t} = t\}
$$
If $s \in \mathcal{L}(S_1)$, then
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \ell_1.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_1}(s)
$$
while if $s \in \mathcal{L}(S_2)$, then
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \ell_2.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_2}(s)
$$
Consequently,
\begin{align*}
H(T \; | \; \MergeROf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) &= \sum_{s \in \mathcal{L}(S_1 \; |_p \; S_2)}P_{S_1 \; |_p \; S_2}(s) H(V^{\rightarrow}_{\MergeROf{\Lens_1}{\Lens_2}}(s))\\
&= p * \sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s) H(V^{\rightarrow}_{\ell_1}(s)) + (1-p) * \sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s) H(V^{\rightarrow}_{\ell_2}(s))\\
&= p * (H(T_1 \; | \; \ell_1, S_1) ) + (1-p) * (H(T_2 \; | \; \ell_2, S_2) )\\
&\leq p * (\mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S_1) ) + (1-p) * (\mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S_2) )\\
&= \mathbb{H}(T \; | \; \MergeROf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) 
\end{align*}
\item
($S = \MergeLOf{\Lens_1}{\Lens_2}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s) &= \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \MergeLOf{\Lens_1}{\Lens_2}.\PutROf{s}{t} = t\}\\
&= \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_1.\PutROf{s}{t} = t \text{ or } \ell_2.\PutROf{s}{t} = t\}\\
&= V^{\rightarrow}_{\ell_1}(s) \cup V^{\rightarrow}_{\ell_2}(s)
\end{align*}
To compute $H(V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s))$, we use the formula 
$$H(P_1, P_2) = H(m(P_1), m(P_2)) + m(P_1)H\left(\frac{P_1}{m(P_1)}\right) + m(P_2)H\left(\frac{P_2}{m(P_2)}\right)$$
if the probability space $P$ is the sum of measure spaces $P_1$ and $P_2$, and $m(P_i)$ is the measure of $P_i$:
\begin{align*}
&H(V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s)) =\\
&H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)\\
&+ \frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)} H(V^{\rightarrow}_{\ell_1}(s)) + \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)} H(V^{\rightarrow}_{\ell_2}(s))
\end{align*}
Consequently,
\begin{align*}
&H(T_1 \; |_q \; T_2 \; | \; \MergeLOf{\Lens_1}{\Lens_2}, S) = \\
&\sum_{s \in \mathcal{L}(S)}H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)\\
&+ \sum_{s \in \mathcal{L}(S)}\left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)H(V^{\rightarrow}_{\ell_1}(s))\\
&+ \sum_{s \in \mathcal{L}(S)}\left(\frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)H(V^{\rightarrow}_{\ell_2}(s))
\end{align*}
Since
\begin{align*}
H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1\\
\left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1\\
\left(\frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1
\end{align*}
Then
\begin{align*}
H(T_1 \; |_q \; T_2 \; | \; \MergeLOf{\Lens_1}{\Lens_2}, S) & \leq \sum_{s \in \mathcal{L}(s)}P_S(s) + \sum_{s \in \mathcal{L}(s)}P_S(s)H(V^{\rightarrow}_{\ell_1}(s)) + \sum_{s \in \mathcal{L}(s)}P_S(s)H(V^{\rightarrow}_{\ell_2})(s)\\
&= H(T_1 \; | \; \ell_1, S) + H(T_2 \; | \; \ell_2, S)\\
&\leq 1 + \mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S) + \mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S)
\end{align*}
\item
($S = \REntropyOf{\Regex \Given \InvertOf{\Lens}, \RegexAlt}$)

Observe that $$V^{\rightarrow}_{\InvertOf{\Lens}}(t) = \{s \in \mathcal{L}(S) \; | \; \InvertOf{\Lens}.\PutROf{s}{t} = t\} = \{s \in \mathcal{L}(S) \; | \; \ell.\PutLOf{t}{s} = s\} = V^{\leftarrow}_{\ell}(t)$$
Consequently
$$
H(S \; | \; \InvertOf{\Lens}, T) = \sum_{t \in \mathcal{L}(T)}P_T(t) H(V^{\rightarrow}_{\InvertOf{\Lens}}(t))
= \sum_{t \in \mathcal{L}(T)}P_T(t) H(V^{\leftarrow}_{\ell}(t))
\leq \mathbb{H}^{\leftarrow}(S\; | \; \ell, T)
$$
\end{enumerate}

\end{proof}
\begin{theorem}
If $DS$ is unambiguous, then $\EntropyOf{\DNFRegex}$ is the entropy of $P_{\DNFRegex}$.
\end{theorem}
\begin{proof}
By mutual induction over $DS$, $SQ$ and $A$ (the computations of the entropies follow the same pattern as the respective computations in \cref{CorrectEntropy}).
\begin{enumerate}
\item
($A = DS^{*p}$)

By the induction hypothesis $H(DS) = \mathbb{H}(DS)$, from which it follows that
$$H(DS^{*p}) = \frac{p}{1-p}(H(DS) - \log_2 p) - \log_2 (1-p) = \mathbb{H}(DS^{*p})$$
\item
($SQ = [s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]$)

By the induction hypothesis, hence by unambiguity $H(A_i) = \mathbb{H}(A_i)$, thus
$$H([s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]) = \sum_{i=1}^n H(A_i) = \sum_{i=1}^n \mathbb{H}(A_i) = \mathbb{H}([s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n])$$
\item
$(DS = \langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)$

By the induction hypothesis, $H(SQ_i, p_i) = \mathbb{H}(SQ_i, p_i)$. Using the formula
$$H(P) = H(m(P_1), \ldots m(P_n)) + \sum_{i=1}^n m(P_i)H(P_i)$$
if $P$ is a measure space satisfying $P = P_1 + \ldots + P_n$, then
\begin{align*}
H(\langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)
&= H(p_1, \ldots, p_n) + \sum_{i=1}^n p_i H(SQ_i, p_i)\\
&= \sum_{i=1}^n p_i \mathbb{H}(SQ_i, p_i) + p_i * \log_2 p_i\\
&= \mathbb{H}(\langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)
\end{align*}
\end{enumerate}
\end{proof}



\fi
\end{document}


% old intro
%\bcp{Not very compelling:}Similar data can come in varieties of formats: scheduled jobs can be stored as
%cron jobs for Linux or as Scheduled Tasks for Windows; web service
%resources can be provided to clients in legacy or modern formats;
%calendar events can be stored in CSV files or ICS files. Oftentimes,
%files should be synchronized across these formats: when I edit a task
%to run more often on my Linux machine, I want this task to run more
%often on my Windows machine; when I update data through a legacy API,
%I want those changes to be reflected when I retrieve it through a
%modern API; when I create a new calendar event in my ICS file, I want
%my CSV calendar files to be updated to reflect this change.
%
%Unfortunately, writing such synchronizers is quite difficult; we must write
%parsers both formats, specify how the parsed data is converted into the other
%format, and specify how to propagate updates from one format to the other.
%Bidirectional languages ease the difficulty of writing such synchronizers,
%because a single, well-typed program expresses a \emph{lens}---a group of
%conversion functions guaranteed to satisfy round-tripping laws. However,
%bidirectional languages are themselves difficult to program in, often requiring
%users to permute data in fiddly ways while satisfying the type system's complex
%unambiguity constraints.
%
%A better approach is to \emph{synthesize} such conversion functions. However,
%prior work on synthesizing lenses assumes a bijection between the source and
%target, which is a severe limitation in practice. Oftentimes, fields present in
%one format are not present in the other: the commands scheduled to run on Linux
%machines are typically different than the commands scheduled to run on Windows
%machines; updated APIs can expose new information, or omit legacy information;
%ICS files contain a URL field that Google Calendar CSV files do not expose.
%
%\emph{Symmetric lenses}~\cite{symmetric-lenses} formalize this richer class of
%non-bijective conversion functions by using additional state, called the
%\emph{complement}, to help with synchronization. While increasing
%expressiveness, the existence of the complement makes symmetric lenses difficult
%to use in real-world synchronization tasks, because lens programs must maintain
%the synchronized files as well as the complements. The complement further
%complicates synthesis, because input-output examples no longer suffice; instead
%edit sequences must be provided.
%
%In this paper, we contrain symmetric lenses to \emph{simple symmetric lenses}.
%These constrained lenses do not use a complement, and only use the files that we
%aim to synchronize as state. We identify a property, \emph{forgetfulness}, that
%identifies the subset of symmetric lenses that can be written as simple
%symmetric lenses. We provide combinators for building simple symmetric lenses on
%string data, and integrate these combinators with Boomerang, a language for
%bidirectional programming on strings. Both Boomerang and our extension type lens
%terms between pairs of regular expressions. The typing judgment $\Lens : \Regex
%\Leftrightarrow \RegexAlt$ means the lens term $\Lens$ encodes synchronizing
%functions between the format described by $\Regex$ and the format described by
%$\RegexAlt$.
%
%We provide a tool for synthesizing simple symmetric lenses when given a suite of
%input-output examples and a pair of regular expressions describing the data
%formats. The synthesis algorithm uses type-directed synthesis
%on the two regular expressions to synthesize a lens that is well-typed between
%the provided regular expressions and satisfies the provided input-output
%examples.
%
%\saz{This paragraph is hard to follow --- maybe introduce $\ell : S
%  \Leftrightarrow T$ and use the names $S$ and $T$?}\bcp{The names make it a
%bit better, but it is all still rather abstract.  Indeed, the whole intro is
%quite abstract---could it not be driven by an example?} A primary difficulty is
%that there are a relatively many well-typed simple symmetric lenses. If we are
%trying to find a lens between $\Regex$ and $\RegexAlt$, there is now a choice:
%do $\Regex$ and $\RegexAlt$ represent the same data, and should be aligned
%(changes to data in the language of $\Regex$ are propagated to synchronized
%strings in the language of $\RegexAlt$), or should it be left unaligned (changes
%to data in $\Regex$ update synchronized strings in $\RegexAlt$). Or instead
%should certain components of $\Regex$ be aligned with certain components of
%$\RegexAlt$, with the other components left unaligned.
%
%Operating under the assumption that users wish to align as much data as
%possible, our algorithm tries to align as much data as the types and examples
%allow. This task gets harder when there are more complex decisions involved. For
%example, if there are two fields in one format, and one in the other, which field
%in the first format should be aligned to the sole field of the second format? Or
%would it be better for the field on the right to be aligneded to a mish-mash
%of subcomponents from each field?\bcp{Wouldn't these questions be answered
%  by examples?} To answer these questions, we develop a cost
%metric for reasoning about which lens aligns the most information.
%
%In particular, the \emph{cost} of a lens is the expected number of bits required to
%recover a string in one format when a synchronized string in the other format is
%provided. In this model, bijective lenses have zero cost, and as more
%information is left unsychronized, the cost is increased.
%
%Our model is based on \emph{stochastic regular expressions}~\cite{?}, which
%represent both a language and a probability distribution over that language
%simultaneously.  We develop a way to syntactically infer the expected
%information content (or \emph{entropy}) of an unambiguous regular
%expression. This entropy is used to calculate the expected information content
%to recover a string, when given a string it is synchronized with.\bcp{I
%know we're going to get to more technical detail later, but at this point I
%am confused: a string matching a RE can in general be arbitrarily long, so
%what kind of sense does it make to talk about its ``expected'' information content?}
%
%\begin{figure}
%  \includegraphics[width=.5\textwidth]{high-level-algorithm.pdf}
%  \caption{Schematic Diagram for \SOptician. Regular expressions \Regex and
%    \RegexAlt, and a set of examples \Examples, are provided as input. \RXSearch
%    searches through stochastic regular expression pairs, equivalent to the
%    originals, and proposes them to \GreedySynth. \GreedySynth finds a lens,
%    typed between the generated equivalent pairs. When \RXSearch determines it
%    has an optimal lens, it returns that lens.}
%  \label{fig:high-level-algorithm}
%\end{figure}
%
%\bcp{It gets rather technical and incomprehensible for the next three
%  paragraphs...} 
%
%We develop an algorithm that synthesizes a low-cost lens, shown in
%Figure~\ref{fig:high-level-algorithm}. This algorithm consists of two
%communicating synthesizers, one that proposes candidate stochastic regular
%expression pairs that it thinks will align well, and one that greedily searches
%for a lens between those two regular expressions that minimizes cost and does
%not traverse star-related equivalences\bcp{???}. When the first algorithm is content with
%the lens it has found, it returns that lens. 
%
%\bcp{Make clear that these algorithms are based on earlier / published ones.}Our first algorithm, \RXSearch, proposes candidate stochastic regular
%expressions. These candidate stochastic regular expressions are generated by
%traversing \emph{star semiring} equivalences on stochastic regular expressions.
%These proposed stochastic regular expression pairs have equivalent languages and
%probability distributions as the original ones: we prove that the star-semiring
%rewrites this synthesizer applies are sound rewrites on stochastic regular
%expressions.
%
%Our second algorithm, \GreedySynth, utilizes alternative languages for
%stochastic regular expressions and lenses, \emph{stochastic DNF regular
%  expressions} and \emph{symmetric DNF lenses}. While these languages are hard
%to read and understand, they are highly normalized and permit an efficient
%type-directed synthesis algorithm. We develop our cost metric on DNF lenses, and
%provide a greedy algorithm that tries to find a symmetric DNF lens of minimal
%cost. The synthesized symmetric DNF lens is then converted to a lens in the
%original simple symmetric lens language.
%
%
%We evaluate our algorithm on a benchmark suite consisting of synchronizing file
%formats from configuration files, application-specific data storage files, and
%data cleaning tasks. We find that our algorithm is able to synthesize each of
%these lenses in under 20 seconds.
%
%In summary, our contributions are:
%\begin{enumerate}
%\item We develop \emph{simple symmetric lenses} a new formulation for
%  bidirectional programs that can project data from both sides~(\S\ref{sec:overview}),
%  and describe a language that expresses such lenses on string
%  data~(\S\ref{sec:ssl}).  \bcp{A new language, or a variant of
%    Hofmann/Pierce/Wagner?} 
%\item We develop a means to traverse stochastic regular expression equivalences,
%  while preserving probability distributions and
%  languages~(\S\ref{subsec:stoch-rx}).
%\item We develop stochastic DNF regular expressions and DNF
%  lenses~(\S\ref{subsec:greedy-synth}). We develop a sound algorithm for
%  converting stochastic regular expressions to stochastic DNF regular
%  expressions and a information-theoretic cost metric on DNF lenses.
%\item We extended Boomerang with our simple symmetric lens combinators, and
%  integrated our algorithm with the Optician synthesis system within Boomerang,
%  allowing synthesis tasks as Boomerang
%  expressions~(\S\ref{sec:implementation}).
%\item We evaluate our algorithm on a benchmark suite consisting of synchronizing
%  file formats from configuration files, application-specific data storage
%  files, and data cleaning tasks (\S\ref{sec:evaluation}).  \bcp{... and
%    conclude what?}
%  \end{enumerate}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:

%  LocalWords:  SREs SRE emp
